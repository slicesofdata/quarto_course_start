[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Nothing to see here"
  },
  {
    "objectID": "homework/homework.html",
    "href": "homework/homework.html",
    "title": "Homework",
    "section": "",
    "text": "Under construction\n\n\n\nThis syllabus is under construction until Fall 2023"
  },
  {
    "objectID": "homework/homework.html#exercises",
    "href": "homework/homework.html#exercises",
    "title": "Homework",
    "section": "Exercises",
    "text": "Exercises\nVarious tasks and exercises will be found here.\nThe exercise list will be updated as the semester progresses."
  },
  {
    "objectID": "homework/homework.html#download",
    "href": "homework/homework.html#download",
    "title": "Homework",
    "section": "Download",
    "text": "Download\nHomework Exercise 01"
  },
  {
    "objectID": "index.html#psyc-167-data-visualization",
    "href": "index.html#psyc-167-data-visualization",
    "title": "**PSYC167**",
    "section": "PSYC 167: Data Visualization",
    "text": "PSYC 167: Data Visualization\nThis is the course website for PSYC 167: Data Visualization, taught by Prof. Gabriel I. Cook; 1 credit\nDescription\nData visualization is the science and art of creating graphical representations of information and data. Visual representations provide accessible ways to see patterns, trends, and outliers in data. Variables like position, size, and orientation can focus attention and guide perception but can also bias interpretation of data. Students will learn how well-designed visualizations can reduce bias and improve comprehension for data thereby facilitating data-driven decision-making. Students will explore techniques for creating effective visualizations based on principles from cognitive and perceptual psychology, art, and design. Students will gain hands-on experience coding real-world data visualizations for local offices, organizations, and industry participants.\nThe course is targeted toward students with expressed interest in cognition and cognitive biases related to data communication, students interested in using visualization to communicate their own messages, and students interested in creating better visualization tools and systems. Students will engage in discussions of the readings, complete programming and data analysis assignments, and prepare a final project involving storytelling with data visualizations."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html",
    "href": "modules/001_installing_and_setting_up_git_and_github.html",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "",
    "text": "We will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\n\n\nCreate a GitHub account\nInstall Git\nConfigure Git for R, within R (a familiar context)\nCreate a Personal Access Token (PAT)\nSet your Git Credentials (using PAT)\nCreate a Version Control Project in RStudio (for your team project)\nMake file edits, stage the, and commit them\nPush commits to GitHub"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#overview",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#overview",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "",
    "text": "We will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\n\n\nCreate a GitHub account\nInstall Git\nConfigure Git for R, within R (a familiar context)\nCreate a Personal Access Token (PAT)\nSet your Git Credentials (using PAT)\nCreate a Version Control Project in RStudio (for your team project)\nMake file edits, stage the, and commit them\nPush commits to GitHub"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#libraries-used",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#libraries-used",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Libraries Used",
    "text": "Libraries Used\n\n{usethis}: 2.2.2: for project workflow automation\n{gitcreds}: 0.1.2: for querying git credentials"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#why-go-through-the-trouble",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#why-go-through-the-trouble",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Why Go Through the Trouble?",
    "text": "Why Go Through the Trouble?\nProjects are rarely done without collaboration. Teams collaborate, leveraging team members’ work and accomplishments. Using R in conjunction with the a distributed version control system, like Git, will facilitate that collaboration process. Writing flexible R code that does not hard-code objects will allow your research project to be reproducible, for example, when variables and data change (e.g., new data added, a new year added, etc.). Git long with GitHub will allow you to track your edits (the version control) and share your code with your collaborators or interested scholars.\nSome reasons to use version control are:\n\nFacilitates project sharing (once it’s setup, you’ll get there)\nFacilitates collaboration. Others can also report errors or suggest features to your project.\nMakes reverting back to previous states easy. You can easily revert back to a previous version of your code in the event you discover errors or you delete critical details accidentally.\nServes as a memory for edits when memory fails. All changes across different versions of your code or written content is available.\n\nRStudio integrates support for Git but this interface is a little clunky. You can use it but RStudio also allows for communication via the command line Terminal, which will be the preferred method shared here."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#installing-git",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#installing-git",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Installing Git",
    "text": "Installing Git\n\nDo I need to install Git?\n\nMac OS Users can check if already install by typing git --version at the Mac Terminal. If a version number is returned, then Git is installed.\nWindows Users can press the Windows key (or click the Start button) and type Git in the search bar. If you see Git or GitBash listed, then Git is installed.\n\nDownload and Install Git (if necessary)\n\nMac OS Users may experience problems with instructions listed at the Git download site to install Homebrew and set the PATH variable. Instead, I recommend downloading the binary version here and download it to install.\nWindows Users can download the latest version of Git here. Download and install Git, making a note of where on your computer you are install it as you may need to locate the path for RStudio, especially if you use a portable version of Git."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-github-account",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-github-account",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Creating a GitHub Account",
    "text": "Creating a GitHub Account\n\nGo to GitHub and create a free GitHub account. Make note of your username and your associated e-mail as you will need those for configuring Git with R.\n\nConsider this brief 15-minute TryGit Tutorial.\n\nStay logged in so that you can complete a later step.\nSend your PM your GitHub username. Your PM will send those to me and I will add you to a private repo. Once you are added to the repo, you can do the next step."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#checking-git-setup-in-rstudio",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#checking-git-setup-in-rstudio",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Checking Git Setup in RStudio",
    "text": "Checking Git Setup in RStudio\nYou will need to tell RStudio where to find the Git program as this may not be recognize automatically.\n\nFind the path to the Git program executable that was installed in an earlier step.\n\nIn the Terminal in RStudio (not the R console), type: where git on Windows or which git on Mac/Linux and you might find the path easily. If there are more than one paths listed, just make note of one of them.\nIf for some reason you don’t see a path listed using that approach, type: Sys.which(\"git\") in your R console. The path here will likely be truncated so you will have to fill in the gaps when performing the step to set the path.\n\nIn RStudio, go to Tools &gt; Global Options and click on left side bar menu item Git/SVN.\nSelect the option at the top to Enable version control interface for RStudio projects if it is not selected.\nSet the path to the Git executable if it is not already there. Browse to the path to where Git.exe installed on your computer. Windows Users should make note that this path should be a path containing Git.exe and not a path containing git-bash.exe.\nClick Apply and click OK."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#configuring-git-and-github",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#configuring-git-and-github",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Configuring Git and GitHub",
    "text": "Configuring Git and GitHub\nThere are two ways you can set up, either using R (console) or the command line (terminal). My recommendation is to use R because that is where you are likely most familiar. We will use the {usethis} library to help you.\nThe {usethis} library will make connecting your R project to your github account simple. This library should be installed as part of the packages from the start of the course. You will use usethis::use_git_config() to configure your GitHub account (see earlier) with Git on your computer. In the below example, you need to pass two arguments, your user.name and user.email attached to your GitHub account and then execute the modified R code:\nusethis::use_git_config(user.name = \"Jane Git\", \n                        user.email = \"jane_git@gitrdone.com\")"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-personal-access-token-pat-for-github",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-personal-access-token-pat-for-github",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Creating a Personal Access Token (PAT) for GitHub",
    "text": "Creating a Personal Access Token (PAT) for GitHub\nYou will need a personal access token for making remote changes to GitHub.\nExecute the following R to create a token.\nusethis::create_github_token()\nAfter executing the code, you will be taken to your GitHub account (if you remained logged in). Go to the bottom of the page and click generate token. Copy it to the clipboard and save it someplace safe. Do not share your token with anyone because anyone who has it can access your public or private GitHub repositories.\nNote: Your PAT will expire after some duration, usually 30 days unless you change it. For this project, I suggest you change the expiration to a date after the semester ends."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#setting-your-git-credentials-using-pat",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#setting-your-git-credentials-using-pat",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Setting your Git Credentials (using PAT)",
    "text": "Setting your Git Credentials (using PAT)\nWe now need to set those credentials for RStudio to communicate with your GitHub account.\nExecute the following R code to set your credentials:\ngitcreds::gitcreds_set()\nYou will then paste your PAT here and press return/enter. If there are options, enter the number corresponding to the one that makes the more sense for what you are doing, like set or replace your credentials."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-version-control-project-in-rstudio",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-version-control-project-in-rstudio",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Creating a Version Control Project in RStudio",
    "text": "Creating a Version Control Project in RStudio\n\nIn RStudio, File &gt; New Project &gt; Version Control &gt; Git.\nIn the pop-up, you will see a request for the “repository URL”. Paste the URL of the GitHub repository based on your liaison name. This URL will be the same as what you see on your GitHub account. However, we need to add .git to the end.\n\n    https://github.com/slicesofdata/dataviz23-stewart.git\n    https://github.com/slicesofdata/dataviz23-venglass.git\n    https://github.com/slicesofdata/dataviz23-lawson.git\n\nWhen you create the project, a directory will be created, a name will auto populate (e.g., ‘dataviz23-stewart’). If you change the name, name it something that you will know as your team project. In order to keep the class organized, I might suggest you create the project in your PSYC167 course directory. You should already have a R project for you homework called something like homework.Rproj in that course directory. WARNING: Do not create the project inside of an existing project’s directory.\n\nNote: I recommend that you also select “Open in new session” in order to compartmentalize projects. When you work on the team project, open the project. When you work on your homework or other class exercises, open your homework project.\n\nClick “Create Project” to create the new project directory, which will create:\n\na project directory on your computer\na project file with file extension .Rproj\na Git repository or link to the remote GitHub repository for the project (also an RStudio Project)\n\n\nIf the repository already exists (and it does in this instance) you should see RStudio flash a connection to GitHub and likely pull the repo contents down to your newly-created project directory. You will see the directory structure and corresponding files. Your code files should be saved to /r, the data you read or save to /data, your RMarkdown report files to /report, etc.\nThese directories are there for project management purposes. Also, to maintain a clean project, create sub-directories within those directories as needed; create new directories if and only if its contents differ qualitatively from what is in the existing directories. Because the project report will need to be reproduced, don’t complicate your code by creating RMarkdown files for code used to perform some task when only code is needed. In those cases, use .R code script files. Use .Rmd files only for a report containing text and minor code. You cannot easily source() .Rmd files and creating them will be a a hassle to deal with later. Project organization is an element of the project."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#git-workflow-basics",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#git-workflow-basics",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Git Workflow Basics",
    "text": "Git Workflow Basics\nThere are three main parts to Git Workflow:\n\nMake local changes (in your working directory)\nStage changes (in your staging directory)\nCommit changes (to apply them for pushing to your remote repository)"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#making-local-file-changes-committing-and-pushing-to-github",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#making-local-file-changes-committing-and-pushing-to-github",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Making Local File Changes, Committing, and Pushing to GitHub",
    "text": "Making Local File Changes, Committing, and Pushing to GitHub\n\nMaking a local change\n\nCreate a .R script and name it something like yourname.R. Save it to … you guessed it: /r.\n\nChecking the status of local file changes\n\nCheck for the local changes you have made at the Terminal by typing git status and press return/enter\n\n$ git status\n\nIf you made changes, Git will tell you what those changes are. For example, there will be a new file, a deleted file, a modified file, etc.\n\nStaging Changes (Add Changes)\n\nStage a specific change: If you made multiple changes and all you want to do is commit a single change and no others, you can specify the change you want to add. For example, if you want only to add a specific file, like yourname.R, you will use git add &lt;file&gt;... such that &lt;file&gt; refers to the file name.\n\nAt the Terminal prompt, type git add followed by &lt;file&gt; to include in what will be committed)\n$ git add r/yourname.R\n\nStage all change(s): When you make numerous changes, you may wish not to specify each file individually as that could be tedious. In this case, you may wish to stage all of your changes. Assuming everything you are doing is relevant to the project, one of the easiest ways to add changes is to just add all of your file changes. Note, your changes should not be done inside data files (e.g., .csv, .xlsx). Changes should only be done using R code. If not, your project will not be reproducible.\n\nAt the Terminal, you can type git add . which tells Git that you are adding all of those changes to commit them.\n$ git add .\n\n\nCommitting the change(s)\n\nNow that you made a change, you will commit it and assign a useful message to remind your future self and collaborators what you just did.\n\nAt the Terminal, type git commit to commit the changes, add -m to tell git you want a message, and then type the message as a string, \"my message here\" and then press enter/return to commit the changes.\n$ git commit -m \"added my first .R file\"\n\n\nPush the change to the remote repository\n\nWe need to push the changes to the remote GitHub repository for version control and for collaborators to access\n\nAt the Terminal, you will push those changes using git push and press enter/return to push.\n$ git push\n\nIf you navigate to your GitHub account in your web browser, you will see the changes there as soon as they arrive. Congrats!\n\nPractice (Yes, seriously): Changing, Committing, and Pushing Again\n\nYou know that file with your name is not needed for the project. Delete it from the project as you normally would delete a file (no need to use the Terminal) and then add the change, commit the change with message “deleted my silly file”, and push changes.\nIf for some reason, your push did not work, you may need to specify the project branch. Branching is beyond the scope of this course. If team members are working on separate tasks, their code will be compartmentalized so you can use the main branch.\n\nYou can set the branch to the main branch at the Terminal using git branch -M main.\n$ git branch -M main\n\n\nPushing Specific File Changes\n\nYou should not push all of your edits. For example, if you edit a file and save it but it is incomplete (e.g., it contains errors) that will create problems for your team members, you do not want to push them to the repo. If you do, your team member’s code will also break if they are sourcing (e.g., source()) your script file. Similarly, if the data file you write out contains errors, a teammate cannot read that file in successfully. So make sure that what you push is correct and accurate before pushing.\n\nPulling Changes from the Remote\n\nThe opposite of push is pull. When your teammates push their changes (e.g., data cleaning, file creation, etc.) to the repo and your code depends on those files, you will want to make sure their edits are in your local project so that you can use them.\n\nTo pull the changes down to your project, at the Terminal, type git pull.\n$ git pull\n\nYou should find the changes appear in your local project directory."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#using-the-git-tab-in-your-rstudio-pane",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#using-the-git-tab-in-your-rstudio-pane",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Using the Git Tab in your RStudio Pane",
    "text": "Using the Git Tab in your RStudio Pane\nIf you do not use the Terminal to add, commit, and push, you can also use Git with RStudio, though I tend to find this creates an annoying lag when there are lots of files.\nWhen you edit files (e.g., made changes and saved the file), the file will be detected in the project if you have set up Git. The changes detected will be listed in the window for this tab. You can then stage, commit the changes, push the changes using this RStudio GUI.\n\nClick the Git tab\nCheck the box under Staged next to the file\n\nNote: There may be a delay.\n\nClick the Commit icon on the toolbar directly above Status\n\nA window will pop up showing some of the edits to the file\nA window for Commit message will also appear for adding your message. This window is where you want to be.\n\nType your commit message in that window\n\nYour message should be clear and useful to remind your future self or colleagues of the edits but not be overly wordy.\n\nClick Commit to commit the change\nClick the Green Arrow to Push your committed change up to the remote repository.\n\nNote: You will click the Blue Arrow to Pull the changes down from the remote repository what were pushed there by your collaborators"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#other-resources",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#other-resources",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Other Resources",
    "text": "Other Resources\n\nGit Client:\n\nGit clients work like the RStudio Gui option described above but likely much better. One client is GitKraken. * If you find the Terminal command line daunting or limiting, I might recommend a Git Client to use as I am not a big fan of the RStudio interface. * GitKraken is a good option and they have lots of tutorials on their website. GitKraken is seamless to set up. Install, connect your GitHub account, select your repo to add, and voilà. You can stage, commit, and push from there.\n\nhappygitwithr"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html",
    "href": "modules/01_installing_r_and_rstudio.html",
    "title": "Installing R & RStudio",
    "section": "",
    "text": "For this course, we will use the R programming language and the RStudio IDE for manipulating data and creating data visualizations."
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#tasks",
    "href": "modules/01_installing_r_and_rstudio.html#tasks",
    "title": "Installing R & RStudio",
    "section": "Tasks",
    "text": "Tasks\nThe first step is to install these pieces of software so that you can use them.\n\nDownload and Install R\nDownload and Install RStudio\nConfigure RStudio"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#readings",
    "href": "modules/01_installing_r_and_rstudio.html#readings",
    "title": "Installing R & RStudio",
    "section": "Readings",
    "text": "Readings\n\nIntro to R\nWorking with RMarkdown"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#install-r-first-and-then-install-rstudio.",
    "href": "modules/01_installing_r_and_rstudio.html#install-r-first-and-then-install-rstudio.",
    "title": "Installing R & RStudio",
    "section": "Install R first and then install RStudio.",
    "text": "Install R first and then install RStudio.\nInstalling should be easy and you can accept all of the defaults although the desktop icons are not needed, especially for R because you will never need it; RStudio will find R for you. You can follow these videos for simple installing.\nPC: How to Install R and R Studio on Windows 10/11\nMac: Installing R and RStudio on a Mac\nNote: If you leave the desktop icon for R, you can remove that later. You will never need it because RStudio will find R for you.\n##Additional Step for Mac Users:\nDownload and Install XQuartz\nSome functions in R require an “X11 Server” and/or libraries associated with an X11 server. Apple does not provide this software with OS X anymore so unfortunately you have to do it on your own via a third-party application called XQuartz for OS X 10.9 or later.\nUse the url below to download the XQuartz file and save it to your computer. Follow the same install instructions as above for installing the XQuartz file.\nFor macOS 10.9 or later, download this XQuartz file and save it to your computer and install: https://github.com/XQuartz/XQuartz/releases/download/XQuartz-2.8.5/XQuartz-2.8.5.pkg"
  },
  {
    "objectID": "modules/02_graphical_perception.html",
    "href": "modules/02_graphical_perception.html",
    "title": "Graphical perception",
    "section": "",
    "text": "In this module, we will address some aspects of how people perceive elements of data visualizations. You will likely learn that you are not as accurate as you might have thought at extracting data from visual representations. There will be illusions."
  },
  {
    "objectID": "modules/02_graphical_perception.html#readings",
    "href": "modules/02_graphical_perception.html#readings",
    "title": "Graphical perception",
    "section": "Readings",
    "text": "Readings\n\nLooking at Data"
  },
  {
    "objectID": "modules/02_graphical_perception.html#content-pending",
    "href": "modules/02_graphical_perception.html#content-pending",
    "title": "Graphical perception",
    "section": "Content Pending",
    "text": "Content Pending"
  },
  {
    "objectID": "modules/03_reading_data_files.html",
    "href": "modules/03_reading_data_files.html",
    "title": "Reading data files",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/03_reading_data_files.html#readings",
    "href": "modules/03_reading_data_files.html#readings",
    "title": "Reading data files",
    "section": "Readings",
    "text": "Readings\n\nR Workflow Basics\nGeneral Wrangling: Sections 5.1 up through 5.5"
  },
  {
    "objectID": "modules/03_reading_data_files.html#task",
    "href": "modules/03_reading_data_files.html#task",
    "title": "Reading data files",
    "section": "Task",
    "text": "Task\n\nCreate a GitHub account if you don’t have one (this may come in handy for projects and a blog if you want)"
  },
  {
    "objectID": "modules/03_reading_data_files.html#libraries",
    "href": "modules/03_reading_data_files.html#libraries",
    "title": "Reading data files",
    "section": "Libraries",
    "text": "Libraries\n\n{openxlsx} 4.2.5.2: for reading Excel spreadsheets from a URL\n{readxl} 1.4.3: for reading Excel spreadsheets\n{readr} 2.1.4: for reading .csv, .tsv, and .fwf files\n\nFirst, we need an .xlsx data file. You can obtain one locally or online from a URL."
  },
  {
    "objectID": "modules/03_reading_data_files.html#excel-files-from-a-url",
    "href": "modules/03_reading_data_files.html#excel-files-from-a-url",
    "title": "Reading data files",
    "section": "Excel files from a URL",
    "text": "Excel files from a URL\n{readxl} 1.4.3 lacks the ability to read the file from online. We can, however, read it using {openxlsx}. The problem is that you will only be able to read a the first sheet. If the first sheet is all you need, this can work. Pass the URL to openxlsx::read.xlsx() and assign it’s contents to an object named DAT using the assignment operator &lt;-.\n\nURL &lt;- \"https://github.com/slicesofdata/dataviz23/raw/main/data/cms-top-all-time-2023-swim.xlsx\"\n\nDAT &lt;- openxlsx::read.xlsx(URL, sheet = 1)\n\nWhat does the head of the data file look like?\n\nhead(DAT)\n\n   score              name year          event   team\n1 525.35       Maia Presti 2015 1-Meter Diving Athena\n2 514.70 Makenna Parkinson 2023 1-Meter Diving Athena\n3 512.05      Emma Ng Pack 2023 1-Meter Diving Athena\n4 494.95         Izzy Doud 2023 1-Meter Diving Athena\n5 462.15     Carli Lessard 2015 1-Meter Diving Athena\n6 447.70     Alexis Romero 2023 1-Meter Diving Athena\n\n\nJust an FYI, when you want a different worksheet you will need to pass a sheet name to the sheet argument. In this case, we saved it as part of the download process. Let’s pass sheet = \"swim\".\n\nhead(\n  openxlsx::read.xlsx(URL, sheet = \"swim\")\n)\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena"
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-excel-spreadsheets-with-readxl",
    "href": "modules/03_reading_data_files.html#reading-excel-spreadsheets-with-readxl",
    "title": "Reading data files",
    "section": "Reading Excel Spreadsheets with {readxl}",
    "text": "Reading Excel Spreadsheets with {readxl}\nWe will use the {readxl} library to handing reading of Excel files. Because Excel files can contain multiple sheets, one goal would be to find out the sheet names using readxl::excel_sheets (see ?readxl::excel_sheets). This function takes one argument, which is the path to the file. Passing the path will return the sheet names in that file. We can pass the path string directly into the function or if the file path is already saved as a object, pass that.\nIn order to read an Excel spreadsheet file, you will need to specify at very least file and if you want to read a specific sheet other than the first one, then you will need to specify sheet.\n\nfile: a path to the file, including the file name\nsheet: the sheet name to read\n\n\nGetting Sheet Names\nFirst, let’s assign the file path to an object because we will use this path a few times and we don’t want to keep typing it lest we make an error.\n\nfile_name &lt;- \"cms-top-all-time-2023-swim.xlsx\"\n\nWe can examine the worksheet names:\n\nreadxl::excel_sheets(path = here::here(\"data\", file_name))\n\n[1] \"diving\" \"swim\"   \"relay\" \n\n\nGreat, we know know the sheet names. The benefit of passing an object is that you you may wish to pass the path to another function, for example, to read a sheet from the file.\n\n\nReading a Sheet\nIn order to read a sheet, we will use readxl::read_excel(), which takes the file path as the first argument and the name of the desired sheet as the second argument. You might get away with passing only the path as long as your goal is to read the first sheet because this is the default action. Let’s wrap the function in head() to see the top.\n\nhead(\n  readxl::read_excel(here::here(\"data\", file_name))\n)\n\n# A tibble: 6 × 5\n  score  name              year  event          team  \n  &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt; \n1 525.35 Maia Presti       2015  1-Meter Diving Athena\n2 514.70 Makenna Parkinson 2023  1-Meter Diving Athena\n3 512.05 Emma Ng Pack      2023  1-Meter Diving Athena\n4 494.95 Izzy Doud         2023  1-Meter Diving Athena\n5 462.15 Carli Lessard     2015  1-Meter Diving Athena\n6 447.70 Alexis Romero     2023  1-Meter Diving Athena\n\n\nThe function also turns the file content into special object type knows as a data frame. A data frame is composed of row and column data. Sometimes data frames are messy but luckily we have a fairly clean file. You can verify using R’s built-in function is.data.frame(), which will return TRUE if it’s a data frame or FALSE if not. We will assign this to an object\n\nis.data.frame(readxl::read_excel(here::here(\"data\", file_name)))\n\n[1] TRUE\n\n\nBut we don’t want the first sheet. Pass sheet = \"swim\" to read that sheet. Also, let’s read in the data and assign it to an object called DAT which will hold the data frame.\n\nDAT &lt;- readxl::read_excel(here::here(\"data\", file_name), sheet = \"swim\")\n\nViewing the head of the data frame, we can see that it is composed of 5 column vectors representing variables with names: time, name, year, event, team.\n\nhead(DAT)\n\n# A tibble: 6 × 5\n  time  name             year  event   team  \n  &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n2 23.31 Ava Sealander    2022  50 FREE Athena\n3 23.49 Kelly Ngo        2016  50 FREE Athena\n4 23.71 Helen Liu        2014  50 FREE Athena\n5 23.76 Michele Kee      2014  50 FREE Athena\n6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n\n\nOK, that was fun. In order to demonstrate reading local .csv files, we will take a detour into saving files."
  },
  {
    "objectID": "modules/03_reading_data_files.html#managing-file-paths-with-here",
    "href": "modules/03_reading_data_files.html#managing-file-paths-with-here",
    "title": "Reading data files",
    "section": "Managing file paths with {here}",
    "text": "Managing file paths with {here}\nWhen downloading the file, you may have noticed using the {here} library. A discussion of the library was delayed at the time. We will now look a little deeper into how the library simplifies working with file paths within the context of the {readr}.\nWhat’s the best way to handle directories and file paths? Undoutedly, that is the {here} library, assuming of course you are smart enough to be using projects in RStudio. When you open a file from within a project, {here} will make the project directory the working directory. And if you are organized, your data files will be in a /data directory inside the project directory. When passing \"data\" as the first argument to here::here() ( e.g., here::here(\"data\"), you will see that the function returns a string containing the full path to the project directory plus the data subdirectory.\n\nhere::here(\"data\")\n\n[1] \"C:/Users/gcook/Sync/git/dataviz23/data\""
  },
  {
    "objectID": "modules/03_reading_data_files.html#a-workflow-side-note-on-strings",
    "href": "modules/03_reading_data_files.html#a-workflow-side-note-on-strings",
    "title": "Reading data files",
    "section": "A Workflow Side Note on Strings",
    "text": "A Workflow Side Note on Strings\nYou could avoid hard coding the change of the file extension in order to streamline you workflow. Every time to pass the path and the path changes you will need to change this by hand and doing so could be extremely annoying. For example, if you change the save location or the file name, you’ll need to make updates for all code referencing the path. To avoid potential headaches, we can instead use gsub() to examine a string, look for a pattern, and replace that pattern with another pattern. All we want to do is to change \".xlsx\" or \".xls\" in the string to \".csv\". And because we will next want to use this new name for reading later, let’s assign the change to a new string object, file_csv.\nFirst, let’s see what gsub() is doing.\n\ngsub(pattern = \".xlsx|.xls\",  \n     replacement = \".csv\", \n     x = file_name\n     )\n\n[1] \"cms-top-all-time-2023-swim.csv\"\n\n\nAssign to an object:\n\nfile_csv &lt;- gsub(\".xlsx|.xls\", \".csv\", file_name)\n\nNote: Code was simplified because the arguments were passed in the order expected by the gsub() function.\nSecond, pass the path object to write_csv():\n\nreadr::write_csv(x = DAT, \n                 file = here::here(\"data\", file_csv)\n                 )\n\nDid it save? Use file.exists().\n\nfile.exists(here::here(\"data\", file_csv))\n\n[1] TRUE\n\n\nRemember, all we have done is save the data frame. This new file will contain only the data from the spreadsheet that we read earlier. Before opening this new file, we need to take a detour on general handling of reading files with {readr}."
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-a-.csv-file-stored-on-a-website",
    "href": "modules/03_reading_data_files.html#reading-a-.csv-file-stored-on-a-website",
    "title": "Reading data files",
    "section": "Reading a .csv File Stored on a Website",
    "text": "Reading a .csv File Stored on a Website\nFor example, although the mtcars data is also a built-in data set in R, if it were a read actual .csv file save on some website, you can pass the URL path as the file. This file does exist on the {tidyverse} github for {readr}.\n\nreadr::read_csv(file = \"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nBecause file if the first argument of the function, you do not need to reference it specifically. Doing so just eliminates ambiguity for more complicated function calls. You will come across a lot of examples of code that do NOT reference the arguments by name.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nBy default, readr::read_csv() tries to guess whether column/variable names are present. If you know they exist, you can set col_names = TRUE.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = T)\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nIf the names are present and you set col_names = FALSE, you will get a mess because {readr} will assume the header row is data just as the rest of the file.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = F)\n\nRows: 33 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 33 × 11\n   X1    X2    X3    X4    X5    X6    X7    X8    X9    X10   X11  \n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 mpg   cyl   disp  hp    drat  wt    qsec  vs    am    gear  carb \n 2 21    6     160   110   3.9   2.62  16.46 0     1     4     4    \n 3 21    6     160   110   3.9   2.875 17.02 0     1     4     4    \n 4 22.8  4     108   93    3.85  2.32  18.61 1     1     4     1    \n 5 21.4  6     258   110   3.08  3.215 19.44 1     0     3     1    \n 6 18.7  8     360   175   3.15  3.44  17.02 0     0     3     2    \n 7 18.1  6     225   105   2.76  3.46  20.22 1     0     3     1    \n 8 14.3  8     360   245   3.21  3.57  15.84 0     0     3     4    \n 9 24.4  4     146.7 62    3.69  3.19  20    1     0     4     2    \n10 22.8  4     140.8 95    3.92  3.15  22.9  1     0     4     2    \n# ℹ 23 more rows\n\n\nAs you can see, the column names are all prefixed with “X” and the first row is now the name of the headers. names() or colnames() will return the column names, so we can apply it and see what happens. We will wrap readr::read_csv() in names(). See how this is a problem. You can use colnames() to test this too.\n\nnames(\n  readr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = T)\n  )\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\""
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-a-.csv-file-stored-locally-on-your-computer",
    "href": "modules/03_reading_data_files.html#reading-a-.csv-file-stored-locally-on-your-computer",
    "title": "Reading data files",
    "section": "Reading a .csv File Stored Locally on your Computer",
    "text": "Reading a .csv File Stored Locally on your Computer\nIf a file actually existed on your computer, the file would not be a URL but rather the path location to where the file is stored.\nAnd now we can read the locale file as before except we are not passing the string name but rather an object (e.g., file_csv) holding the file path and file name. Voilà.\n\nreadr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows"
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-raw-data-that-is-comma-separated-e.g.-.csv",
    "href": "modules/03_reading_data_files.html#reading-raw-data-that-is-comma-separated-e.g.-.csv",
    "title": "Reading data files",
    "section": "Reading Raw Data that is Comma-Separated (e.g., .csv)",
    "text": "Reading Raw Data that is Comma-Separated (e.g., .csv)\nWe will file use readr::read_csv() to read our data file (viz., cms-top-all-time-2023-swim.csv).\n\nreadr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nIf there were only data in the file and no names representing variables on the first row, the file might look like that below. We can imitate this by skipping the first row (containing names) using skip =.\n\nreadr::read_csv(here::here(\"data\", file_csv), skip = 1)\n\nRows: 439 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): 23.29, Jocelyn Crawford, 2019, 50 FREE, Athena\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 439 × 5\n   `23.29` `Jocelyn Crawford` `2019` `50 FREE` Athena\n   &lt;chr&gt;   &lt;chr&gt;              &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt; \n 1 23.31   Ava Sealander      2022   50 FREE   Athena\n 2 23.49   Kelly Ngo          2016   50 FREE   Athena\n 3 23.71   Helen Liu          2014   50 FREE   Athena\n 4 23.76   Michele Kee        2014   50 FREE   Athena\n 5 23.77   Natalia Orbach-M   2020   50 FREE   Athena\n 6 23.77   Suzia Starzyk      2020   50 FREE   Athena\n 7 23.87   Katie Bilotti      2010   50 FREE   Athena\n 8 23.93   Jenni Rinker       2011   50 FREE   Athena\n 9 24.02   Annika Sharma      2023   50 FREE   Athena\n10 51.05   Kelly Ngo          2016   100 FREE  Athena\n# ℹ 429 more rows\n\n\nSee how the first row is assumed to be names? Setting col_names = F will fix the problem. Putting the arguments on separate rows of R code might improve code legibility.\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                skip = 1,\n                col_names = F\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): X1, X2, X3, X4, X5\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   X1    X2               X3    X4      X5    \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nBut we have no column names now. Setting col_names = will fix that. Use c() to combine 4 names, e.g., col_names = c(\"name1\", \"name2\", \"name3\", \"name4\").\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                skip = 1,\n                col_names = c(\"time\", \"name\", \"year\", \"event\")\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, X5\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   X5    \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nIf you have column names that are on row 1 of the data frame, don’t skip that row and instead set col_names = TRUE to put them in place.\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                col_names = T\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nLuckily, we have both names and data in the file and by default readr::read_csv() does what we intend."
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-data-from-a-librarypackage",
    "href": "modules/03_reading_data_files.html#reading-data-from-a-librarypackage",
    "title": "Reading data files",
    "section": "Reading Data from a Library/Package",
    "text": "Reading Data from a Library/Package\nAs mentioned earlier, mtcars is a data set on cars which is also part of base R, meaning you do not need to read it from anyplace. R does this automatically.\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# or \nprint(mtcars)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nUse names() to read the column names:\n\nnames(mtcars)\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\""
  },
  {
    "objectID": "modules/03_reading_data_files.html#object-assignment-using--",
    "href": "modules/03_reading_data_files.html#object-assignment-using--",
    "title": "Reading data files",
    "section": "Object Assignment using <-",
    "text": "Object Assignment using &lt;-\nYou will want to take the data frame object that is returned by the read.csv() function and assign it to an object of some name using the assignment operator &lt;- . Although the concept of assignment will be covered later, for now just understand that we need to make the data more accessible to work with. You could name the object anything you want. Let’s assign it to DAT standing for data frame and let’s make it ALL CAPS.\nA note about case: R is a case-sensitive language so object names like DAT, dat, DaT, etc. are possible and can refer to different objects depending on how you assign them. We will use capital letters only because I like to flag objects that are data frame as special and this approach makes them visually identifiable. You could choose your own convention for naming data frames, other objects, variables in data frames, etc. but I don’t recommend being random about it."
  },
  {
    "objectID": "modules/03_reading_data_files.html#using-read.table",
    "href": "modules/03_reading_data_files.html#using-read.table",
    "title": "Reading data files",
    "section": "Using read.table():",
    "text": "Using read.table():\nread.table() is a flexible function for reading files because you can specify how the data are separated in rows by setting the sep argument. A common separation is a comma but you might also have tabs or other special characters.\n\nDAT &lt;- read.table(file = here::here(\"data\", file_csv),\n                  sep = \",\",\n                  header = T\n                  )\n\nread.csv() is a specific case of read.table() that sets sep = \",\" for you so there is no need to pass the argument. read.csv() is the more common function you will come across for reading .csv files but read.table() works the same as long as you set the argument.\n\nDAT &lt;- read.csv(here::here(\"data\", file_csv))"
  },
  {
    "objectID": "modules/03_reading_data_files.html#using-read_csv-from-readr",
    "href": "modules/03_reading_data_files.html#using-read_csv-from-readr",
    "title": "Reading data files",
    "section": "Using read_csv() from {readr}:",
    "text": "Using read_csv() from {readr}:\nThere are advantages to using readr::read_csv() over read.csv(), which is why we will prefer it. We will assign it to an object named DAT2.\n\nDAT2 &lt;- readr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(DAT2)\n\n# A tibble: 6 × 5\n  time  name             year  event   team  \n  &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n2 23.31 Ava Sealander    2022  50 FREE Athena\n3 23.49 Kelly Ngo        2016  50 FREE Athena\n4 23.71 Helen Liu        2014  50 FREE Athena\n5 23.76 Michele Kee      2014  50 FREE Athena\n6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n\n\nWe can test whether DAT and DAT2 are the same using a logical test ==. Notice the two =. If we use one =, we will actually assign the contents of DAT2 to DAT because a single = in this context (scope) will do the same as &lt;-. A discussion of the differences is beyond the scope here but suffice it so say &lt;- is the common practice except when you are writing custom functions. In most cases, assignment inside functions are done with = because objects created inside a function are not typically needed outside that scope.\nAnyway, you can see that the contents are the same even when files are read by different functions. This is wrapped in the all() function, which will return TRUE if everything is TRUE. This is good that the contents are identical.\n\nall(DAT == DAT2)\n\n[1] TRUE"
  },
  {
    "objectID": "modules/03_reading_data_files.html#data-as-a-data-frame",
    "href": "modules/03_reading_data_files.html#data-as-a-data-frame",
    "title": "Reading data files",
    "section": "Data as a Data Frame",
    "text": "Data as a Data Frame\nYou should see an object named DAT that contains the data frame with some swim data. If you want to verify this is actually a data frame object, you can pass the DAT object into the is.data.frame() function. The function will return TRUE if it is and FALSE if it is not.\n\nis.data.frame(DAT)\n\n[1] TRUE\n\nis.data.frame(DAT2)  # tibbles are also data frames\n\n[1] TRUE"
  },
  {
    "objectID": "modules/03_reading_data_files.html#are-they-both-tibbles",
    "href": "modules/03_reading_data_files.html#are-they-both-tibbles",
    "title": "Reading data files",
    "section": "Are they both tibbles?",
    "text": "Are they both tibbles?\nTibbles are different from data frames, see the {tibble} library.\n\ntibble::is_tibble(DAT)\n\n[1] FALSE\n\ntibble::is_tibble(DAT2)\n\n[1] TRUE\n\n\nNow the you have the data frame, you can examine some of its contents, for example, the first 6 rows using the head() function.\n\nhead(DAT)    # hmm, something seems off.\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena\n\n\nBecause header rows do exist atop the .csv file, specify that they exist by passing TRUE to the header argument of the function (e.g., header = TRUE or header = T).\n\nDAT &lt;- read.table(here::here(\"data\", file_csv),\n                  sep = \",\", \n                  header = TRUE\n                  )\n\nhead(DAT)    # Perfect!\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html",
    "title": "Data frame manipulation and wrangling",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#libraries",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#libraries",
    "title": "Data frame manipulation and wrangling",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{stringr}: 1.5.0: for working with strings\n{tidyselect}: 1.2.0: for selecting sets from strings"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#external-functions",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#external-functions",
    "title": "Data frame manipulation and wrangling",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#libraries-1",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#libraries-1",
    "title": "Data frame manipulation and wrangling",
    "section": "Libraries",
    "text": "Libraries\nWe will work with a few different libraries for data manipulation. Let’s load them into our work space using library().\n\nlibrary(magrittr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\n\nMake note of any warnings that appear when loading libraries. There are some libraries that contain functions with the same names. Be aware that the most recently loaded library function will take precedence. You can avoid confusion using :: to call a function from a particular library (e.g., libraryname::functionname())."
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#select-variables-starting-with-or-ending-with-certain-characters",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#select-variables-starting-with-or-ending-with-certain-characters",
    "title": "Data frame manipulation and wrangling",
    "section": "Select Variables Starting with or Ending with Certain Characters",
    "text": "Select Variables Starting with or Ending with Certain Characters\nOne thing about {dplyr}, when you load the library, there are functions from other libraries that are imported along with {dplyr}’s own functions. These important functions are designed to work with each other, so the people who maintain the libraries have packaged them up nicely so you don’t have to load separate libraries.\nMany of the functions are imported from the {tidyselect} library and these functions are what give you additional manipulation ability. Some imported functions are: all_of(), any_of(), contains(), ends_with(), everything(), last_col(), matches(), and starts_with().\nWith functions like starts_with(), contains(), and ends_with(), you can select variables with character patterns in their names.\nRather that passing the names of the variables as the second argument (e.g., c(\"Murder\", \"Assault\")), you would pass the helper function, say starts_with(). Whatever starts_with() returns is what gets passed to select() as the variables. This is what is referred to as functional programming. Rather than coding specifically what to do, you with utilize the task of another function to passed its returned object as an argument to another function.\nBut first, we need to see what these functions, like starts_with(), are doing. For more information, use ?starts_with.\nstarts_with(match, ignore.case = TRUE, vars = NULL)\nNotice the arguments we need to pass:\n\nmatch: A character vector\nignore.case: If TRUE, the default, ignores case when matching names. This is most flexible.\nvars: A character vector of variable names. If not supplied, the variables are taken from the current selection context (as established by functions like select() or pivot_longer()).\n\nLet’s just try out starts_with() on its own. Let’s set a required pattern match = some character and because vars = NULL by default, let’s just set vars = some character vector. Note that vars is not the second argument, so you will want to name it in the function call.\n\nstarts_with(match = \"a\", vars = c(\"Hello\", \"Hi\", \"Bye\"))\n\ninteger(0)\n\n\nReturns integer(0) which is speak for “there is no match”. Hmm, OK. Let’s try another character.\n\nstarts_with(match = \"b\", vars = c(\"Hello\", \"Hi\", \"Bye\"))\n\n[1] 3\n\n\nOK, so now an integer is returned (yes, try is.integer() if you don’t believe me).\n\nis.integer(starts_with(\"b\", vars = c(\"Hello\", \"Hi\", \"Bye\")))\n\n[1] TRUE\n\n\nImportantly, the value refers to the element index/position in the vars vector. Because the third string \"Bye\" starts with \"b\", that’s what is returned.\nTry something else:\n\nstarts_with(\"h\", vars = c(\"Hello\", \"Hi\", \"Bye\"))\n\n[1] 1 2\n\n\nNow a vector with length = 2 is returned, representing both the first and the second elements start with “h”.\n\nlength(starts_with(\"h\", vars = c(\"Hello\", \"Hi\", \"Bye\")))\n\n[1] 2\n\n\nSee, it’s really a vector containing the element(s) of the vars vector matching the pattern.\nAnd yes, this the letter casing is ignored because the default ignore.case = TRUE. Set to FALSE if you want your match to be case sensitive.\n\nstarts_with(\"h\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\"), \n            ignore.case = F\n            )\n\ninteger(0)\n\n\nOK, no matches.\nYou will typically use starts_with() along with other functions. When using starts_with() in the context of select(), the vars argument is essentially passing vars = the names of the columns of the data frame passed to select().\nExample:\nselect(mydataframe,\n    starts_with(match = \"my pattern\",\n                vars = \"var names of mydataframe\")\n                )\nPassing the data frame into select() without piping it using %&gt;%:\n\nselect(USArrests, starts_with(\"m\")) %&gt;% head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\nPiping the data frame into select():\n\nUSArrests %&gt;%\n  select(., starts_with(\"m\")) %&gt;% head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\nAnother example:\n\nUSArrests %&gt;%\n  select(., ends_with(\"t\")) %&gt;% head()\n\n           Assault\nAlabama        236\nAlaska         263\nArizona        294\nArkansas       190\nCalifornia     276\nColorado       204"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-bybetween-index",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-bybetween-index",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting and Selecting Out Variables By/Between Index",
    "text": "Selecting and Selecting Out Variables By/Between Index\nThere are many approaches for selecting or selecting out column variables. You can pass multiple arguments for each specification or you can pass a single vector that contains all specifications.\n\nselect(., 1,2): select first and second columns\nselect(., c(1,2)): select first and second columns\nselect(., -c(1,2)): select out first and second columns\nselect(., 1:2): select first through second columns\nselect(., c(1:2)): select first through second columns\nselect(., -c(1:2)): select out first through second columns\n\nPotential Recommendation: use options utilizing c() to pass a vector because this habit will be more versatile with base R functionality. However, online solutions will likely not take this approach.\nLet’s make a data frame to work with first.\n\nDAT &lt;- data.frame(\n  Id  = c(100, 101, 102, 103, 104, 100, 105),\n  Sex = c('male', 'female', 'Male', NA, 'man', \"male\", \"neither\"),\n  Age = c(25, 33, 27, 40, 44, 25, 40),\n  Renting = c(\"yes\", NA, \"yes\", NA, \"no\", \"yes\", \"yes\")\n)\n\nSelect columns 1 and 2:\n\nDAT %&gt;%\n  select(., 1,2) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect columns 1 and 2 as a vector containing values 1 and 2:\n\nDAT %&gt;%\n  select(., c(1,2)) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect out columns 1 and 2 as a vector containing values 1 and 2:\n\nDAT %&gt;%\n  select(., -c(1,2)) \n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nSelect from columns 1 to 2 using the : operator:\n\nDAT %&gt;%\n  select(., 1:2) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect from columns 1 through 3 using a vector containing the : operator:\n\nDAT %&gt;%\n  select(., c(1:3)) \n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect out columns 1 through 3 using a vector containing the : operator:\n\nDAT %&gt;%\n  select(., -c(1:3))   # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-by-or-between-character-name",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-by-or-between-character-name",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting and Selecting Out Variables By or Between Character Name",
    "text": "Selecting and Selecting Out Variables By or Between Character Name\nThese approaches are similar to those offered earlier except that some involve passing variables by their name (e.g., character names). Whereas the order of the variables in a data frame may move around, the names may be more stable or permanent, at least after you have cleaned up the names. Consequently, passing variables by name may be more foolproof.\nYou don’t have to be familiar with all approaches and you may settle on using one that makes the most sense to you.\n\nselect(., \"var1\", \"var2\")\nselect(., c(\"var1\", \"var2\"))\nselect(., -c(\"var1\", \"var2\"))\nselect(., var1:var2))\nselect(., c(\"var1\":\"var2))\nselect(., -c(\"var1\":\"var2))\n\nRecommendation: use options utilizing c() as this will be more versatile with base R functionality.\nThese approaches also work but they may lead to some confusion regarding usage of quotes:\n\nselect(., var1, var2)\nselect(., c(var1, var2))\nselect(., -c(var1, var2))\n\nSelect variables Id though Age using the : operator:\n\nDAT %&gt;%\n  select(., Id:Age) # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect variables Id though Age passed as strings using the : operator:\n\nDAT %&gt;%\n  select(., \"Id\":\"Age\") # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect variables Id though Age as a vector containing the variable names passed as strings and using the : operator:\n\nDAT %&gt;%\n  select(., c(\"Id\":\"Age\")) # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect out variables Id though Age as a vector containing the variable names passed as strings and using the : operator:\n\nDAT %&gt;%\n  select(., -c(\"Id\":\"Age\"))   # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes\n\n\nYou can also use the ! operator to select NOT these variables (therefore, all others)\n\nDAT %&gt;%\n  select(., !c(\"Id\":\"Age\"))   # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-characters-in-their-names",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-characters-in-their-names",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting and Selecting Out Variables Characters in Their Names",
    "text": "Selecting and Selecting Out Variables Characters in Their Names\n\nselect(., starts_with(\"characters\"))\nselect(., ends_with(\"characters\"))\nselect(., contains('e'))\n\nSelect variables which start with character “i”:\n\nDAT %&gt;% select(., starts_with('i'))\n\n   Id\n1 100\n2 101\n3 102\n4 103\n5 104\n6 100\n7 105\n\n\nSelect variables which DO NOT start with character “s”:\n\nDAT %&gt;% select(., -starts_with('s'))\n\n   Id Age Renting\n1 100  25     yes\n2 101  33    &lt;NA&gt;\n3 102  27     yes\n4 103  40    &lt;NA&gt;\n5 104  44      no\n6 100  25     yes\n7 105  40     yes\n\n\nSelect variables which end with character “e”:\n\nDAT %&gt;% select(., ends_with('e'))\n\n  Age\n1  25\n2  33\n3  27\n4  40\n5  44\n6  25\n7  40\n\n\nSelect variables which end with character “e”:\n\nDAT %&gt;% select(., -ends_with('e'))\n\n   Id     Sex Renting\n1 100    male     yes\n2 101  female    &lt;NA&gt;\n3 102    Male     yes\n4 103    &lt;NA&gt;    &lt;NA&gt;\n5 104     man      no\n6 100    male     yes\n7 105 neither     yes\n\n\nSelect variables which contain character “g”:\n\nDAT %&gt;% select(., contains('g'))\n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nSelect variables which DO NOT contain character “g”:\n\nDAT %&gt;% select(., -contains('g'))\n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect variables containing a regular expression, use matches():\n.* will grab all names because it means any character and any number of times\n\nDAT %&gt;% select(., matches(\".*\"))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\n\\\\d will grab all variables containing a digit:\n\nDAT %&gt;% \n  mutate(., \n         var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) %&gt;%\n  select(., matches(\"\\\\d\"))\n\n  var_1 var_11 var_3 var1_var\n1     1      1     1        1\n2     1      1     1        1\n3     1      1     1        1\n4     1      1     1        1\n5     1      1     1        1\n6     1      1     1        1\n7     1      1     1        1\n\n\nv.*\\\\d will grab all variables that start with v and then contain any characters which are followed by a digit:\n\nDAT %&gt;% \n    mutate(., \n         var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) %&gt;%\n  select(., matches(\"v.*\\\\d\"))\n\n  var_1 var_11 var_3 var1_var\n1     1      1     1        1\n2     1      1     1        1\n3     1      1     1        1\n4     1      1     1        1\n5     1      1     1        1\n6     1      1     1        1\n7     1      1     1        1\n\n\n\\\\d$ will grab all variables ending in a digit ($ means end):\n\nDAT %&gt;% \n    mutate(., \n         var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) %&gt;%\n  select(., matches(\"\\\\d$\"))\n\n  var_1 var_11 var_3\n1     1      1     1\n2     1      1     1\n3     1      1     1\n4     1      1     1\n5     1      1     1\n6     1      1     1\n7     1      1     1\n\n\nYou can also negate all regular expression matches if you want to exclude:\n\nDAT %&gt;%\n      mutate(., \n         var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) %&gt;%\n  select(., -matches(\"\\\\d$\"))\n\n   Id     Sex Age Renting var1_var\n1 100    male  25     yes        1\n2 101  female  33    &lt;NA&gt;        1\n3 102    Male  27     yes        1\n4 103    &lt;NA&gt;  40    &lt;NA&gt;        1\n5 104     man  44      no        1\n6 100    male  25     yes        1\n7 105 neither  40     yes        1\n\n\nNote: The functions will return lowercase and uppercase variable name matches because the default behavior is ignore.case = TRUE. Set to FALSE if you want to perform precise surgery on the variables."
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-by-type",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-by-type",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting and Selecting Out Variables by Type",
    "text": "Selecting and Selecting Out Variables by Type\nSelect variables that are numeric:\n\nDAT %&gt;% select(., where(is.numeric))\n\n   Id Age\n1 100  25\n2 101  33\n3 102  27\n4 103  40\n5 104  44\n6 100  25\n7 105  40\n\n\nSelect variables that are NOT numeric:\n\nDAT %&gt;% select(., -where(is.numeric))\n\n      Sex Renting\n1    male     yes\n2  female    &lt;NA&gt;\n3    Male     yes\n4    &lt;NA&gt;    &lt;NA&gt;\n5     man      no\n6    male     yes\n7 neither     yes\n\n\nSelect variables that are character:\n\nDAT %&gt;% select(., where(is.character))\n\n      Sex Renting\n1    male     yes\n2  female    &lt;NA&gt;\n3    Male     yes\n4    &lt;NA&gt;    &lt;NA&gt;\n5     man      no\n6    male     yes\n7 neither     yes\n\n\nSelect variables that are NOT character:\n\nDAT %&gt;% select(., -where(is.character))\n\n   Id Age\n1 100  25\n2 101  33\n3 102  27\n4 103  40\n5 104  44\n6 100  25\n7 105  40\n\n\nSelect variables that are logical (TRUE to FALSE):\n\nDAT %&gt;% select(., where(is.logical))\n\ndata frame with 0 columns and 7 rows\n\n\nSelect variables that are NOT logical (TRUE to FALSE):\n\nDAT %&gt;% select(., -where(is.logical))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#removing-duplicate-rows-using-distinct",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#removing-duplicate-rows-using-distinct",
    "title": "Data frame manipulation and wrangling",
    "section": "Removing duplicate rows using distinct()",
    "text": "Removing duplicate rows using distinct()\n\ndplyr::distinct(): remove duplicate rows\ndplyr::distinct(., column): remove duplicate rows by column\nna.omit(): remove any row with NA’s (missing values)\n\nLet’s use the simple DAT data frame.\n\nDAT # or with %&gt;% print() \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\nNotice that rows 1 and 6 are the same person (e.g., Id) and have exactly the same data for all variables.\n\nDAT[1,] == DAT[6,]\n\n    Id  Sex  Age Renting\n1 TRUE TRUE TRUE    TRUE\n\n\nGreat that the rows are consistent but you don’t want their data twice. So let’s just remove any rows that are identical.\n\nDAT %&gt;%\n  distinct(.) #%&gt;%    # Remove exact duplicates\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 105 neither  40     yes\n\n\nIf you know each row is unique based on a variable in the data frame, you can also use distinct() to remove duplicates for a specific variable. Make sure that this variable specification is actually one that you would not want duplicates of.\n\nDAT %&gt;%             \n  distinct(., Id) # %&gt;% view_html(.) # Remove duplicates by variable; passes unique values for data frame\n\n   Id\n1 100\n2 101\n3 102\n4 103\n5 104\n6 105\n\n\nBut this function simply returns the unique values in Id. To retain the variables, set .keep_all = T. If you want to remove duplicates and assign the cleaned data frame to an object, you would likely want to keep all of your variables.\n\nDAT %&gt;%             \n  distinct(., Id, .keep_all = T) #%&gt;% view_html(.)\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 105 neither  40     yes\n\n\nNotice, however, this only removed the last instance or Id == 100. Which row to include is a judgment call. The first, the last, neither, the average? Is there a correct answer?"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-using",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-using",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases using ==",
    "text": "Filter Cases using ==\nFilter rows for which the Sex variable is equal to the string 'female':\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'female')\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nFilter rows for which the Sex variable is not equal to the string 'female':\n\nDAT %&gt;%\n  dplyr::filter(., Sex != 'female')\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nFilter rows for which the Sex variable is equal to the string 'female' AND Age is greater than the numeric 27:\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'female' & Age &gt; 27) # this \"AND\" that\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nFilter rows for which the Sex variable is equal to the string 'female' OR Age is greater than the numeric 27:\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'female' | Age &gt; 27) # this \"OR\" that\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 104     man  44      no\n4 105 neither  40     yes\n\n\nA cleaner method involves separate lines of code. Although cleaner, this will not allow the “OR” option because the data frame that is returned from the first filter() is passed to the second filter() and all cases other than \"female\" have already been removed from the data frame.\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'female') %&gt;%   # keep female (and add another pipe)\n  dplyr::filter(., Age &gt;= 27)             # keep only those equal to or older than 27\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-and-or-or",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-and-or-or",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by < and > or <= or >=…",
    "text": "Filter by &lt; and &gt; or &lt;= or &gt;=…\n\nDAT %&gt;% dplyr::filter(., Age &lt; 40)  # keep those less than \n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 102   Male  27     yes\n4 100   male  25     yes\n\nDAT %&gt;% dplyr::filter(., Age &gt; 40)  # keep older than\n\n   Id Sex Age Renting\n1 104 man  44      no\n\nDAT %&gt;% dplyr::filter(., Age &gt;= 40)  # keep equal to or older than\n\n   Id     Sex Age Renting\n1 103    &lt;NA&gt;  40    &lt;NA&gt;\n2 104     man  44      no\n3 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-by-conditional-x-or-y-using-operator",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-by-conditional-x-or-y-using-operator",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases by Conditional X or Y Using | Operator…",
    "text": "Filter Cases by Conditional X or Y Using | Operator…\nUsing the “OR” operator, |, cases can be included if “this” OR “that” condition.\nFilter numbers:\n\nDAT %&gt;%\n  dplyr::filter(., Age == 25 | Age == 40)    # filter out numeric values IN a range\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 100    male  25     yes\n4 105 neither  40     yes\n\n\nFilter characters:\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'male' | Sex == 'female')\n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 100   male  25     yes\n\n\nAlthough dplyr::filter(sex %in% c('male', 'female')) would be easier.\nFilter rows of variables of both types:\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'male' | Age == 27)  \n\n   Id  Sex Age Renting\n1 100 male  25     yes\n2 102 Male  27     yes\n3 100 male  25     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-between-values-with-between",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-between-values-with-between",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases Between Values with between()",
    "text": "Filter Cases Between Values with between()\nBetween ages 25 and 33:\n\nDAT %&gt;%\n  dplyr::filter(., between(Age, 27, 33))\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n2 102   Male  27     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-range-using-the-in-operator-this-is-in-meaning-in",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-range-using-the-in-operator-this-is-in-meaning-in",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by range using the %in% operator (this is IN meaning in)",
    "text": "Filter by range using the %in% operator (this is IN meaning in)\nThough less flexible than using between(), %in% may be easier to remember:\n\nDAT %&gt;%\n  dplyr::filter(., Age %in% 20:43)    # filter out numeric values IN a range\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nOne’s age is in the range from 20 through 43.\nIf a vector object is already defined (e.g., my_levels = c('male', 'female')), you can use that for filtering also. Such approaches are useful when data manipulation involves reusing a reference as it simplifies coding and reduces errors because the specification is defined only once.\n\nmy_levels = c('male', 'female')\n\nDAT %&gt;%\n  dplyr::filter(., Sex %in% my_levels)\n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 100   male  25     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-exclusion",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-exclusion",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by exclusion",
    "text": "Filter by exclusion\nWhen inclusion of variables is inappropriate, exclusion of them may be useful. The ! operator means “NOT” in R so you can use that to accomplish the opposite of the statement. For example, dplyr::filter(., !sex %in% c('male', NA)) will “filter the data frame to include rows in the sex column for which the value is NOT in the vector”.\nExclude rows in the Sex variable that are NA or 'male':\n\nDAT %&gt;%\n  dplyr::filter(., !Sex %in% c('male', NA))  # keep only if NOT in vector\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 102    Male  27     yes\n3 104     man  44      no\n4 105 neither  40     yes\n\n\nExclude rows in the Sex variable that are Men or 'male':\n\nDAT %&gt;%\n  dplyr::filter(., !Sex %in% c('male', 'Men'))  # keep only if NOT in vector\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 102    Male  27     yes\n3 103    &lt;NA&gt;  40    &lt;NA&gt;\n4 104     man  44      no\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-conditional-x-and-y-using-operator",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-conditional-x-and-y-using-operator",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by conditional X and Y using & operator…",
    "text": "Filter by conditional X and Y using & operator…\nBy range:\n\nDAT %&gt;%\n  dplyr::filter(., Id &gt;= 102 & Age &lt;= 43)    \n\n   Id     Sex Age Renting\n1 102    Male  27     yes\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 105 neither  40     yes\n\n\n\nDAT %&gt;%\n  dplyr::filter(., Age &gt;= 20 & Age &lt;= 43)    \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nNote: Age 20:43 won’t work. Can you figure out why?"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-na.omit",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-na.omit",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using na.omit():",
    "text": "Filter using na.omit():\n\nDAT %&gt;%\n  na.omit(.) #%&gt;%     # omit any rows with NAs \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n3 102    Male  27     yes\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-is.na-and-is.na",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-is.na-and-is.na",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using is.na() and !is.na():",
    "text": "Filter using is.na() and !is.na():\n\nDAT %&gt;%\n  filter(., is.na(Sex))       # keep NAs by variable\n\n   Id  Sex Age Renting\n1 103 &lt;NA&gt;  40    &lt;NA&gt;\n\n\nBut your goal may likely be to keep everything that is not NA:\n\nDAT %&gt;%\n  filter(., !is.na(Sex))      # remove NAs by variable\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 104     man  44      no\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nAnd filter step-by-step for each variable using %&gt;% and separate function calls:\n\nDAT %&gt;%\n  filter(., !is.na(Sex)) %&gt;%      \n  filter(., !is.na(Renting))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nSo why use separate lines of code if you can use & all in one line? One reason is that separate function calls written as separate lines of code make code inclusion/exclusion extremely easy.\nComment out what you don’t want using #:\n\nDAT %&gt;%\n  #filter(., !is.na(Sex)) %&gt;%      \n  filter(., !is.na(Renting))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-complete.cases",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-complete.cases",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using complete.cases():",
    "text": "Filter using complete.cases():\nThe complete.cases() function returns a logical vector for which TRUE reflects the row has complete information and no missing cases. Using complete.cases() along with filter(), you would retain all rows TRUE rows.\n\nDAT %&gt;%\n  dplyr::filter(., complete.cases(.))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html",
    "href": "modules/07_data_subsets_and_summaries.html",
    "title": "Data subsets and summaries",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#readings",
    "href": "modules/07_data_subsets_and_summaries.html#readings",
    "title": "Data subsets and summaries",
    "section": "Readings",
    "text": "Readings"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#task",
    "href": "modules/07_data_subsets_and_summaries.html#task",
    "title": "Data subsets and summaries",
    "section": "Task",
    "text": "Task"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#libraries",
    "href": "modules/07_data_subsets_and_summaries.html#libraries",
    "title": "Data subsets and summaries",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{lubridate} 1.9.2: for handling date and time vectors"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#external-functions",
    "href": "modules/07_data_subsets_and_summaries.html#external-functions",
    "title": "Data subsets and summaries",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#libraries-1",
    "href": "modules/07_data_subsets_and_summaries.html#libraries-1",
    "title": "Data subsets and summaries",
    "section": "Libraries",
    "text": "Libraries\nWe will work with a few different libraries for data manipulation. Let’s load them into our work space using library().\n\nlibrary(magrittr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#creating-a-new-variable",
    "href": "modules/07_data_subsets_and_summaries.html#creating-a-new-variable",
    "title": "Data subsets and summaries",
    "section": "Creating a new variable",
    "text": "Creating a new variable\nWe will pass the data frame into mutate() and then specify a name-value variable pair. When using %&gt;%, the data frame piped into the function will be represented as .. This . is not needed but serves as a good reminder that the data frame that is passed into mutate() is from the previous line of code. In order to keep the print out manageable, we will also use the slice() function.\nmutate(data_frame, \n    new_variable_name = variable\n    )\nCreate new variables that are set to a constant number or string:\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., newvar1 = 9999) %&gt;%\n  mutate(., newvar2 = \"Student\") \n\n   time             name year   event   team newvar1 newvar2\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena    9999 Student\n2 23.31    Ava Sealander 2022 50 FREE Athena    9999 Student\n3 23.49        Kelly Ngo 2016 50 FREE Athena    9999 Student\n4 23.71        Helen Liu 2014 50 FREE Athena    9999 Student\n5 23.76      Michele Kee 2014 50 FREE Athena    9999 Student\n\n\nYou can see that each row in the data frame will take on the paired value."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#modifying-a-new-variable",
    "href": "modules/07_data_subsets_and_summaries.html#modifying-a-new-variable",
    "title": "Data subsets and summaries",
    "section": "Modifying a new variable",
    "text": "Modifying a new variable\nNew variables are modified using the same name-value pairing approach. When you modify a variable, you are taking an existing variable to setting it to another value.\n\nSet an existing variable equal to a constant\nJust use an existing variable name (left of = in name-value pair).\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., time = 1) %&gt;%\n  mutate(., name = \"0\") \n\n  time name year   event   team\n1    1    0 2019 50 FREE Athena\n2    1    0 2022 50 FREE Athena\n3    1    0 2016 50 FREE Athena\n4    1    0 2014 50 FREE Athena\n5    1    0 2014 50 FREE Athena\n\n\nOK, that’s not very helpful. We just replaced our existing variables with nothing useful. You can see that name is still a &lt;chr&gt; type.\n\n\nSet an existing variable equal to another value\nAs long as {dplyr} can result the character elements of the vector, as.numeric() will convert the character strings to numbers. For example:\n\nas.numeric(c(\"1\", \"3.2\", \"6.99\"))\n\n[1] 1.00 3.20 6.99\n\n\nWe can illustrate in a data frame by creating character value that will serve as the constant, and use as.numeric() just to illustrate this example.\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., name = as.numeric(\"0\")) \n\n   time name year   event   team\n1 23.29    0 2019 50 FREE Athena\n2 23.31    0 2022 50 FREE Athena\n3 23.49    0 2016 50 FREE Athena\n4 23.71    0 2014 50 FREE Athena\n5 23.76    0 2014 50 FREE Athena\n\n\nAnd now name is a &lt;dbl&gt;, which is a type of numeric. We can see this by selecting columns from the data frame where() the variable is.numeric().\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., name = as.numeric(\"0\")) %&gt;%\n  select(., where(~is.numeric(.)))\n\n  name\n1    0\n2    0\n3    0\n4    0\n5    0\n\n\nBut if we try to convert time to numeric this way, you will see that the complex numbers will be converted to NAs, or missing.\n\nas.numeric(DAT$time)\n\nWarning: NAs introduced by coercion\n\n\n  [1] 23.29 23.31 23.49 23.71 23.76 23.77 23.77 23.87 23.93 24.02 51.05 51.24\n [13] 51.41 51.56 51.56 51.88 52.05 52.05 52.14 52.17    NA    NA    NA    NA\n [25]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [37]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [49]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [61] 55.66 55.67 55.91 56.11 56.74 56.83 57.18 57.36 57.47 57.56    NA    NA\n [73]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [85]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [97]    NA    NA    NA    NA 54.76 54.92 54.93 55.23 55.74 56.04 56.27 56.42\n[109] 56.47 56.56    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[121]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA 22.69 22.92\n[133] 22.93 22.95 23.27 23.31 23.33 23.38 23.45 23.47 50.65 50.67 50.92 51.19\n[145] 51.27 51.28 51.29 51.37 51.45 51.56    NA    NA    NA    NA    NA    NA\n[157]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[169]    NA    NA 25.94 26.22 26.28 26.57 26.82 26.90 27.14 27.14 27.16 27.17\n[181] 28.33 28.96 29.05 29.06 29.09 29.09 29.24 29.26 29.46 29.55 24.05 24.28\n[193] 24.58 24.59 24.65 24.85 25.05 25.08 25.24 25.34 54.65 54.81 54.91 55.11\n[205] 55.13 55.25 55.27 55.45 55.62 56.21    NA    NA    NA    NA    NA    NA\n[217]    NA    NA    NA    NA 19.98 20.21 20.22 20.36 20.51 20.65 20.69 20.71\n[229] 20.79 20.82 44.06 44.21 44.73 44.94 45.24 45.31 45.32 45.45 45.50 45.50\n[241]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[253]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[265]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[277]    NA    NA    NA    NA 46.99 47.57 49.32 49.97 50.03 50.29 50.35 50.41\n[289] 50.51 50.59    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[301] 54.88 55.80 55.92 56.03 56.27 56.35 56.36 56.45 56.49 56.49    NA    NA\n[313]    NA    NA    NA    NA    NA    NA    NA    NA 47.45 47.56 47.80 48.74\n[325] 48.91 49.26 49.31 49.34 49.68 49.74    NA    NA    NA    NA    NA    NA\n[337]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[349]    NA    NA 19.47 19.63 19.96 20.08 20.10 20.14 20.18 20.22 20.25 20.28\n[361] 43.28 43.69 43.74 44.43 44.57 44.59 44.81 44.81 44.83 44.87    NA    NA\n[373]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[385]    NA    NA    NA    NA    NA    NA 22.32 22.50 22.84 23.00 23.24 23.45\n[397] 23.72 23.74 23.85 23.87 24.73 24.81 24.88 25.10 25.20 25.47 25.55 25.63\n[409] 26.01 26.05 20.60 21.38 21.48 21.58 21.60 21.81 21.83 22.00 22.06 22.07\n[421] 47.01 47.72 48.39 48.50 48.54 48.82 49.00 49.45 49.52 49.60 54.52 55.15\n[433] 55.21 55.47 55.62 56.04 56.13 56.19 56.35 56.48\n\n\nThe problem we have is that the data are not in a clean form. In this data frame, some elements of time are composed of numbers, decimals, and colons (e.g., x.xx, xx:xx.xx, etc.). which all make up elements that would be numbers.\n\n\nConverting variables that are time related using {lubridate}\n{lubridate} is a library for dealing with dates and times. It is also part of the tidyverse} ecosystem.\nThe period_to_seconds() function will convert periods to seconds depending on the period format. We need to pass to it an object that equates to a period of seconds.\nFor time, the format is: hour minute second (e.g., hms). And there is a hms() function to handle this. Let’s see how it works before modifying the data frame. Load the library if it is not loaded.\nWe will pass a single character string and convert it to hms with hms() and then convert that to seconds using period_to_seconds(). Because 60 minutes and 1 hour is the same number of seconds, we should end up with the same values. We can also use ms() to convert the format into minutes and seconds and pass to period_to_seconds(). Following the examples, we will apply to the vector in the data frame.\nlubridate::period_to_seconds(lubridate::ms())\nlubridate::period_to_seconds(lubridate::hms())\nSixty minutes and one hour to hms:\n\nlubridate::hms(\"00:60:00\")\n\n[1] \"60M 0S\"\n\nlubridate::hms(\"01:00:00\")\n\n[1] \"1H 0M 0S\"\n\n\nOne day to hms:\n\nhms(\"24:00:00\")\n\n[1] \"24H 0M 0S\"\n\n\nSixty minutes and one hour to hms to seconds:\n\nlubridate::period_to_seconds(lubridate::hms(\"00:60:00\"))\n\n[1] 3600\n\nlubridate::period_to_seconds(lubridate::hms(\"01:00:00\"))\n\n[1] 3600\n\n\nOK, good. So let’s see if we can convert time. Because hms() is passed into period_to_seconds(), we first need to verify that hms() can handle it.\n\nhms(DAT$time)\n\nWarning in .parse_hms(..., order = \"HMS\", quiet = quiet): Some strings failed\nto parse, or all strings are NAs\n\n\n  [1] NA            NA            NA            NA            NA           \n  [6] NA            NA            NA            NA            NA           \n [11] NA            NA            NA            NA            NA           \n [16] NA            NA            NA            NA            NA           \n [21] \"1H 50M 30S\"  \"1H 51M 89S\"  \"1H 52M 40S\"  \"1H 52M 55S\"  \"1H 52M 57S\" \n [26] \"1H 52M 67S\"  \"1H 52M 80S\"  \"1H 52M 83S\"  \"1H 52M 88S\"  \"1H 52M 89S\" \n [31] \"4H 57M 37S\"  \"4H 59M 22S\"  \"4H 59M 78S\"  \"5H 0M 6S\"    \"5H 0M 21S\"  \n [36] \"5H 0M 47S\"   \"5H 1M 17S\"   \"5H 1M 99S\"   \"5H 2M 16S\"   \"5H 2M 23S\"  \n [41] \"10H 14M 33S\" \"10H 15M 40S\" \"10H 22M 59S\" \"10H 22M 84S\" \"10H 24M 14S\"\n [46] \"10H 24M 82S\" \"10H 26M 34S\" \"10H 26M 89S\" \"10H 33M 15S\" \"10H 36M 60S\"\n [51] \"16H 58M 48S\" \"17H 3M 21S\"  \"17H 6M 78S\"  \"17H 9M 9S\"   \"17H 9M 26S\" \n [56] \"17H 12M 18S\" \"17H 12M 46S\" \"17H 13M 58S\" \"17H 21M 98S\" \"17H 24M 49S\"\n [61] NA            NA            NA            NA            NA           \n [66] NA            NA            NA            NA            NA           \n [71] \"1H 59M 91S\"  \"2H 2M 10S\"   \"2H 3M 73S\"   \"2H 3M 85S\"   \"2H 3M 92S\"  \n [76] \"2H 5M 10S\"   \"2H 5M 56S\"   \"2H 5M 71S\"   \"2H 5M 76S\"   \"2H 6M 13S\"  \n [81] \"1H 1M 84S\"   \"1H 3M 28S\"   \"1H 3M 51S\"   \"1H 3M 91S\"   \"1H 4M 16S\"  \n [86] \"1H 4M 19S\"   \"1H 4M 65S\"   \"1H 4M 66S\"   \"1H 4M 77S\"   \"1H 4M 94S\"  \n [91] \"2H 14M 83S\"  \"2H 15M 62S\"  \"2H 18M 99S\"  \"2H 19M 6S\"   \"2H 19M 78S\" \n [96] \"2H 20M 1S\"   \"2H 21M 17S\"  \"2H 21M 77S\"  \"2H 22M 34S\"  \"2H 22M 83S\" \n[101] NA            NA            NA            NA            NA           \n[106] NA            NA            NA            NA            NA           \n[111] \"2H 1M 84S\"   \"2H 2M 58S\"   \"2H 3M 80S\"   \"2H 4M 5S\"    \"2H 4M 42S\"  \n[116] \"2H 4M 81S\"   \"2H 6M 40S\"   \"2H 7M 12S\"   \"2H 7M 33S\"   \"2H 7M 42S\"  \n[121] \"2H 0M 69S\"   \"2H 3M 59S\"   \"2H 3M 79S\"   \"2H 4M 74S\"   \"2H 5M 41S\"  \n[126] \"2H 6M 82S\"   \"2H 7M 12S\"   \"2H 7M 14S\"   \"2H 7M 81S\"   \"2H 7M 94S\"  \n[131] NA            NA            NA            NA            NA           \n[136] NA            NA            NA            NA            NA           \n[141] NA            NA            NA            NA            NA           \n[146] NA            NA            NA            NA            NA           \n[151] \"1H 50M 91S\"  \"1H 50M 98S\"  \"1H 51M 39S\"  \"1H 51M 41S\"  \"1H 51M 56S\" \n[156] \"1H 51M 64S\"  \"1H 51M 95S\"  \"1H 52M 53S\"  \"1H 52M 78S\"  \"1H 53M 4S\"  \n[161] \"4H 15M 73S\"  \"4H 27M 18S\"  \"4H 30M 33S\"  \"4H 30M 77S\"  \"4H 31M 96S\" \n[166] \"4H 32M 45S\"  \"4H 32M 57S\"  \"4H 32M 68S\"  \"4H 34M 16S\"  \"4H 34M 27S\" \n[171] NA            NA            NA            NA            NA           \n[176] NA            NA            NA            NA            NA           \n[181] NA            NA            NA            NA            NA           \n[186] NA            NA            NA            NA            NA           \n[191] NA            NA            NA            NA            NA           \n[196] NA            NA            NA            NA            NA           \n[201] NA            NA            NA            NA            NA           \n[206] NA            NA            NA            NA            NA           \n[211] \"1H 1M 10S\"   \"1H 2M 88S\"   \"1H 2M 89S\"   \"1H 3M 67S\"   \"1H 4M 10S\"  \n[216] \"1H 4M 16S\"   \"1H 4M 24S\"   \"1H 4M 26S\"   \"1H 4M 35S\"   \"1H 4M 43S\"  \n[221] NA            NA            NA            NA            NA           \n[226] NA            NA            NA            NA            NA           \n[231] NA            NA            NA            NA            NA           \n[236] NA            NA            NA            NA            NA           \n[241] \"1H 38M 35S\"  \"1H 38M 88S\"  \"1H 39M 7S\"   \"1H 39M 35S\"  \"1H 39M 63S\" \n[246] \"1H 39M 80S\"  \"1H 39M 82S\"  \"1H 40M 30S\"  \"1H 40M 31S\"  \"1H 40M 50S\" \n[251] \"4H 25M 67S\"  \"4H 28M 11S\"  \"4H 28M 89S\"  \"4H 29M 32S\"  \"4H 31M 64S\" \n[256] \"4H 32M 52S\"  \"4H 32M 65S\"  \"4H 32M 94S\"  \"4H 32M 98S\"  \"4H 34M 70S\" \n[261] \"9H 14M 11S\"  \"9H 24M 43S\"  \"9H 35M 78S\"  \"9H 36M 64S\"  \"9H 39M 27S\" \n[266] \"9H 40M 2S\"   \"9H 41M 48S\"  \"9H 45M 72S\"  \"9H 46M 63S\"  \"9H 47M 9S\"  \n[271] \"15H 17M 24S\" \"15H 32M 19S\" \"15H 45M 57S\" \"15H 47M 40S\" \"15H 52M 94S\"\n[276] \"15H 53M 75S\" \"15H 56M 57S\" \"15H 57M 89S\" \"16H 2M 45S\"  \"16H 3M 38S\" \n[281] NA            NA            NA            NA            NA           \n[286] NA            NA            NA            NA            NA           \n[291] \"1H 45M 5S\"   \"1H 45M 67S\"  \"1H 46M 51S\"  \"1H 48M 84S\"  \"1H 49M 1S\"  \n[296] \"1H 49M 38S\"  \"1H 50M 32S\"  \"1H 50M 43S\"  \"1H 51M 7S\"   \"1H 51M 57S\" \n[301] NA            NA            NA            NA            NA           \n[306] NA            NA            NA            NA            NA           \n[311] \"1H 59M 90S\"  \"2H 1M 18S\"   \"2H 1M 45S\"   \"2H 1M 60S\"   \"2H 1M 66S\"  \n[316] \"2H 1M 77S\"   \"2H 1M 78S\"   \"2H 2M 89S\"   \"2H 3M 19S\"   \"2H 3M 23S\"  \n[321] NA            NA            NA            NA            NA           \n[326] NA            NA            NA            NA            NA           \n[331] \"1H 43M 96S\"  \"1H 48M 70S\"  \"1H 49M 24S\"  \"1H 49M 95S\"  \"1H 49M 96S\" \n[336] \"1H 50M 34S\"  \"1H 50M 47S\"  \"1H 50M 49S\"  \"1H 50M 51S\"  \"1H 50M 76S\" \n[341] \"1H 46M 97S\"  \"1H 48M 74S\"  \"1H 49M 74S\"  \"1H 50M 51S\"  \"1H 50M 78S\" \n[346] \"1H 51M 11S\"  \"1H 51M 24S\"  \"1H 51M 48S\"  \"1H 51M 82S\"  \"1H 51M 83S\" \n[351] NA            NA            NA            NA            NA           \n[356] NA            NA            NA            NA            NA           \n[361] NA            NA            NA            NA            NA           \n[366] NA            NA            NA            NA            NA           \n[371] \"1H 37M 98S\"  \"1H 38M 49S\"  \"1H 39M 9S\"   \"1H 39M 19S\"  \"1H 39M 66S\" \n[376] \"1H 40M 21S\"  \"1H 40M 22S\"  \"1H 40M 44S\"  \"1H 40M 70S\"  \"1H 40M 70S\" \n[381] \"3H 55M 61S\"  \"3H 56M 68S\"  \"3H 56M 88S\"  \"3H 59M 2S\"   \"3H 59M 13S\" \n[386] \"3H 59M 17S\"  \"4H 0M 63S\"   \"4H 1M 14S\"   \"4H 2M 38S\"   \"4H 2M 99S\"  \n[391] NA            NA            NA            NA            NA           \n[396] NA            NA            NA            NA            NA           \n[401] NA            NA            NA            NA            NA           \n[406] NA            NA            NA            NA            NA           \n[411] NA            NA            NA            NA            NA           \n[416] NA            NA            NA            NA            NA           \n[421] NA            NA            NA            NA            NA           \n[426] NA            NA            NA            NA            NA           \n[431] NA            NA            NA            NA            NA           \n[436] NA            NA            NA            NA            NA           \n\n\nYikes! Note the warning and look at the output. Some strings failed and turned to NA. Looking and the time vector again, we see that contains both values like 1:52.83 and 23.87. If there is only one :, we should be able to use ms().\n\nms(DAT$time)\n\n  [1] \"23M 29S\"    \"23M 31S\"    \"23M 49S\"    \"23M 71S\"    \"23M 76S\"   \n  [6] \"23M 77S\"    \"23M 77S\"    \"23M 87S\"    \"23M 93S\"    \"24M 2S\"    \n [11] \"51M 5S\"     \"51M 24S\"    \"51M 41S\"    \"51M 56S\"    \"51M 56S\"   \n [16] \"51M 88S\"    \"52M 5S\"     \"52M 5S\"     \"52M 14S\"    \"52M 17S\"   \n [21] \"1M 50.3S\"   \"1M 51.89S\"  \"1M 52.4S\"   \"1M 52.55S\"  \"1M 52.57S\" \n [26] \"1M 52.67S\"  \"1M 52.8S\"   \"1M 52.83S\"  \"1M 52.88S\"  \"1M 52.89S\" \n [31] \"4M 57.37S\"  \"4M 59.22S\"  \"4M 59.78S\"  \"5M 0.06S\"   \"5M 0.21S\"  \n [36] \"5M 0.47S\"   \"5M 1.17S\"   \"5M 1.99S\"   \"5M 2.16S\"   \"5M 2.23S\"  \n [41] \"10M 14.33S\" \"10M 15.4S\"  \"10M 22.59S\" \"10M 22.84S\" \"10M 24.14S\"\n [46] \"10M 24.82S\" \"10M 26.34S\" \"10M 26.89S\" \"10M 33.15S\" \"10M 36.6S\" \n [51] \"16M 58.48S\" \"17M 3.21S\"  \"17M 6.78S\"  \"17M 9.09S\"  \"17M 9.26S\" \n [56] \"17M 12.18S\" \"17M 12.46S\" \"17M 13.58S\" \"17M 21.98S\" \"17M 24.49S\"\n [61] \"55M 66S\"    \"55M 67S\"    \"55M 91S\"    \"56M 11S\"    \"56M 74S\"   \n [66] \"56M 83S\"    \"57M 18S\"    \"57M 36S\"    \"57M 47S\"    \"57M 56S\"   \n [71] \"1M 59.91S\"  \"2M 2.1S\"    \"2M 3.73S\"   \"2M 3.85S\"   \"2M 3.92S\"  \n [76] \"2M 5.1S\"    \"2M 5.56S\"   \"2M 5.71S\"   \"2M 5.76S\"   \"2M 6.13S\"  \n [81] \"1M 1.84S\"   \"1M 3.28S\"   \"1M 3.51S\"   \"1M 3.91S\"   \"1M 4.16S\"  \n [86] \"1M 4.19S\"   \"1M 4.65S\"   \"1M 4.66S\"   \"1M 4.77S\"   \"1M 4.94S\"  \n [91] \"2M 14.83S\"  \"2M 15.62S\"  \"2M 18.99S\"  \"2M 19.06S\"  \"2M 19.78S\" \n [96] \"2M 20.01S\"  \"2M 21.17S\"  \"2M 21.77S\"  \"2M 22.34S\"  \"2M 22.83S\" \n[101] \"54M 76S\"    \"54M 92S\"    \"54M 93S\"    \"55M 23S\"    \"55M 74S\"   \n[106] \"56M 4S\"     \"56M 27S\"    \"56M 42S\"    \"56M 47S\"    \"56M 56S\"   \n[111] \"2M 1.84S\"   \"2M 2.58S\"   \"2M 3.8S\"    \"2M 4.05S\"   \"2M 4.42S\"  \n[116] \"2M 4.81S\"   \"2M 6.4S\"    \"2M 7.12S\"   \"2M 7.33S\"   \"2M 7.42S\"  \n[121] \"2M 0.69S\"   \"2M 3.59S\"   \"2M 3.79S\"   \"2M 4.74S\"   \"2M 5.41S\"  \n[126] \"2M 6.82S\"   \"2M 7.12S\"   \"2M 7.14S\"   \"2M 7.81S\"   \"2M 7.94S\"  \n[131] \"22M 69S\"    \"22M 92S\"    \"22M 93S\"    \"22M 95S\"    \"23M 27S\"   \n[136] \"23M 31S\"    \"23M 33S\"    \"23M 38S\"    \"23M 45S\"    \"23M 47S\"   \n[141] \"50M 65S\"    \"50M 67S\"    \"50M 92S\"    \"51M 19S\"    \"51M 27S\"   \n[146] \"51M 28S\"    \"51M 29S\"    \"51M 37S\"    \"51M 45S\"    \"51M 56S\"   \n[151] \"1M 50.91S\"  \"1M 50.98S\"  \"1M 51.39S\"  \"1M 51.41S\"  \"1M 51.56S\" \n[156] \"1M 51.64S\"  \"1M 51.95S\"  \"1M 52.53S\"  \"1M 52.78S\"  \"1M 53.04S\" \n[161] \"4M 15.73S\"  \"4M 27.18S\"  \"4M 30.33S\"  \"4M 30.77S\"  \"4M 31.96S\" \n[166] \"4M 32.45S\"  \"4M 32.57S\"  \"4M 32.68S\"  \"4M 34.16S\"  \"4M 34.27S\" \n[171] \"25M 94S\"    \"26M 22S\"    \"26M 28S\"    \"26M 57S\"    \"26M 82S\"   \n[176] \"26M 90S\"    \"27M 14S\"    \"27M 14S\"    \"27M 16S\"    \"27M 17S\"   \n[181] \"28M 33S\"    \"28M 96S\"    \"29M 5S\"     \"29M 6S\"     \"29M 9S\"    \n[186] \"29M 9S\"     \"29M 24S\"    \"29M 26S\"    \"29M 46S\"    \"29M 55S\"   \n[191] \"24M 5S\"     \"24M 28S\"    \"24M 58S\"    \"24M 59S\"    \"24M 65S\"   \n[196] \"24M 85S\"    \"25M 5S\"     \"25M 8S\"     \"25M 24S\"    \"25M 34S\"   \n[201] \"54M 65S\"    \"54M 81S\"    \"54M 91S\"    \"55M 11S\"    \"55M 13S\"   \n[206] \"55M 25S\"    \"55M 27S\"    \"55M 45S\"    \"55M 62S\"    \"56M 21S\"   \n[211] \"1M 1.1S\"    \"1M 2.88S\"   \"1M 2.89S\"   \"1M 3.67S\"   \"1M 4.1S\"   \n[216] \"1M 4.16S\"   \"1M 4.24S\"   \"1M 4.26S\"   \"1M 4.35S\"   \"1M 4.43S\"  \n[221] \"19M 98S\"    \"20M 21S\"    \"20M 22S\"    \"20M 36S\"    \"20M 51S\"   \n[226] \"20M 65S\"    \"20M 69S\"    \"20M 71S\"    \"20M 79S\"    \"20M 82S\"   \n[231] \"44M 6S\"     \"44M 21S\"    \"44M 73S\"    \"44M 94S\"    \"45M 24S\"   \n[236] \"45M 31S\"    \"45M 32S\"    \"45M 45S\"    \"45M 50S\"    \"45M 50S\"   \n[241] \"1M 38.35S\"  \"1M 38.88S\"  \"1M 39.07S\"  \"1M 39.35S\"  \"1M 39.63S\" \n[246] \"1M 39.8S\"   \"1M 39.82S\"  \"1M 40.3S\"   \"1M 40.31S\"  \"1M 40.5S\"  \n[251] \"4M 25.67S\"  \"4M 28.11S\"  \"4M 28.89S\"  \"4M 29.32S\"  \"4M 31.64S\" \n[256] \"4M 32.52S\"  \"4M 32.65S\"  \"4M 32.94S\"  \"4M 32.98S\"  \"4M 34.7S\"  \n[261] \"9M 14.11S\"  \"9M 24.43S\"  \"9M 35.78S\"  \"9M 36.64S\"  \"9M 39.27S\" \n[266] \"9M 40.02S\"  \"9M 41.48S\"  \"9M 45.72S\"  \"9M 46.63S\"  \"9M 47.09S\" \n[271] \"15M 17.24S\" \"15M 32.19S\" \"15M 45.57S\" \"15M 47.4S\"  \"15M 52.94S\"\n[276] \"15M 53.75S\" \"15M 56.57S\" \"15M 57.89S\" \"16M 2.45S\"  \"16M 3.38S\" \n[281] \"46M 99S\"    \"47M 57S\"    \"49M 32S\"    \"49M 97S\"    \"50M 3S\"    \n[286] \"50M 29S\"    \"50M 35S\"    \"50M 41S\"    \"50M 51S\"    \"50M 59S\"   \n[291] \"1M 45.05S\"  \"1M 45.67S\"  \"1M 46.51S\"  \"1M 48.84S\"  \"1M 49.01S\" \n[296] \"1M 49.38S\"  \"1M 50.32S\"  \"1M 50.43S\"  \"1M 51.07S\"  \"1M 51.57S\" \n[301] \"54M 88S\"    \"55M 80S\"    \"55M 92S\"    \"56M 3S\"     \"56M 27S\"   \n[306] \"56M 35S\"    \"56M 36S\"    \"56M 45S\"    \"56M 49S\"    \"56M 49S\"   \n[311] \"1M 59.9S\"   \"2M 1.18S\"   \"2M 1.45S\"   \"2M 1.6S\"    \"2M 1.66S\"  \n[316] \"2M 1.77S\"   \"2M 1.78S\"   \"2M 2.89S\"   \"2M 3.19S\"   \"2M 3.23S\"  \n[321] \"47M 45S\"    \"47M 56S\"    \"47M 80S\"    \"48M 74S\"    \"48M 91S\"   \n[326] \"49M 26S\"    \"49M 31S\"    \"49M 34S\"    \"49M 68S\"    \"49M 74S\"   \n[331] \"1M 43.96S\"  \"1M 48.7S\"   \"1M 49.24S\"  \"1M 49.95S\"  \"1M 49.96S\" \n[336] \"1M 50.34S\"  \"1M 50.47S\"  \"1M 50.49S\"  \"1M 50.51S\"  \"1M 50.76S\" \n[341] \"1M 46.97S\"  \"1M 48.74S\"  \"1M 49.74S\"  \"1M 50.51S\"  \"1M 50.78S\" \n[346] \"1M 51.11S\"  \"1M 51.24S\"  \"1M 51.48S\"  \"1M 51.82S\"  \"1M 51.83S\" \n[351] \"19M 47S\"    \"19M 63S\"    \"19M 96S\"    \"20M 8S\"     \"20M 10S\"   \n[356] \"20M 14S\"    \"20M 18S\"    \"20M 22S\"    \"20M 25S\"    \"20M 28S\"   \n[361] \"43M 28S\"    \"43M 69S\"    \"43M 74S\"    \"44M 43S\"    \"44M 57S\"   \n[366] \"44M 59S\"    \"44M 81S\"    \"44M 81S\"    \"44M 83S\"    \"44M 87S\"   \n[371] \"1M 37.98S\"  \"1M 38.49S\"  \"1M 39.09S\"  \"1M 39.19S\"  \"1M 39.66S\" \n[376] \"1M 40.21S\"  \"1M 40.22S\"  \"1M 40.44S\"  \"1M 40.7S\"   \"1M 40.7S\"  \n[381] \"3M 55.61S\"  \"3M 56.68S\"  \"3M 56.88S\"  \"3M 59.02S\"  \"3M 59.13S\" \n[386] \"3M 59.17S\"  \"4M 0.63S\"   \"4M 1.14S\"   \"4M 2.38S\"   \"4M 2.99S\"  \n[391] \"22M 32S\"    \"22M 50S\"    \"22M 84S\"    \"23M 0S\"     \"23M 24S\"   \n[396] \"23M 45S\"    \"23M 72S\"    \"23M 74S\"    \"23M 85S\"    \"23M 87S\"   \n[401] \"24M 73S\"    \"24M 81S\"    \"24M 88S\"    \"25M 10S\"    \"25M 20S\"   \n[406] \"25M 47S\"    \"25M 55S\"    \"25M 63S\"    \"26M 1S\"     \"26M 5S\"    \n[411] \"20M 60S\"    \"21M 38S\"    \"21M 48S\"    \"21M 58S\"    \"21M 60S\"   \n[416] \"21M 81S\"    \"21M 83S\"    \"22M 0S\"     \"22M 6S\"     \"22M 7S\"    \n[421] \"47M 1S\"     \"47M 72S\"    \"48M 39S\"    \"48M 50S\"    \"48M 54S\"   \n[426] \"48M 82S\"    \"49M 0S\"     \"49M 45S\"    \"49M 52S\"    \"49M 60S\"   \n[431] \"54M 52S\"    \"55M 15S\"    \"55M 21S\"    \"55M 47S\"    \"55M 62S\"   \n[436] \"56M 4S\"     \"56M 13S\"    \"56M 19S\"    \"56M 35S\"    \"56M 48S\"   \n\n\nGreat! All elements are in the form of \"xxM XXs\". But does {lubridate} also convert seconds to a numeric value when using period_to_seconds()? If loaded, we can also remove the name of the library when calling the functions.\n\nis.numeric(period_to_seconds(ms(DAT$time)))\n\n[1] TRUE\n\n\nSo let’s go ahead and modify the character vector named time to a numeric vector representing seconds.\n\nperiod_to_seconds(ms(DAT$time))\n\n  [1] 1409.00 1411.00 1429.00 1451.00 1456.00 1457.00 1457.00 1467.00 1473.00\n [10] 1442.00 3065.00 3084.00 3101.00 3116.00 3116.00 3148.00 3125.00 3125.00\n [19] 3134.00 3137.00  110.30  111.89  112.40  112.55  112.57  112.67  112.80\n [28]  112.83  112.88  112.89  297.37  299.22  299.78  300.06  300.21  300.47\n [37]  301.17  301.99  302.16  302.23  614.33  615.40  622.59  622.84  624.14\n [46]  624.82  626.34  626.89  633.15  636.60 1018.48 1023.21 1026.78 1029.09\n [55] 1029.26 1032.18 1032.46 1033.58 1041.98 1044.49 3366.00 3367.00 3391.00\n [64] 3371.00 3434.00 3443.00 3438.00 3456.00 3467.00 3476.00  119.91  122.10\n [73]  123.73  123.85  123.92  125.10  125.56  125.71  125.76  126.13   61.84\n [82]   63.28   63.51   63.91   64.16   64.19   64.65   64.66   64.77   64.94\n [91]  134.83  135.62  138.99  139.06  139.78  140.01  141.17  141.77  142.34\n[100]  142.83 3316.00 3332.00 3333.00 3323.00 3374.00 3364.00 3387.00 3402.00\n[109] 3407.00 3416.00  121.84  122.58  123.80  124.05  124.42  124.81  126.40\n[118]  127.12  127.33  127.42  120.69  123.59  123.79  124.74  125.41  126.82\n[127]  127.12  127.14  127.81  127.94 1389.00 1412.00 1413.00 1415.00 1407.00\n[136] 1411.00 1413.00 1418.00 1425.00 1427.00 3065.00 3067.00 3092.00 3079.00\n[145] 3087.00 3088.00 3089.00 3097.00 3105.00 3116.00  110.91  110.98  111.39\n[154]  111.41  111.56  111.64  111.95  112.53  112.78  113.04  255.73  267.18\n[163]  270.33  270.77  271.96  272.45  272.57  272.68  274.16  274.27 1594.00\n[172] 1582.00 1588.00 1617.00 1642.00 1650.00 1634.00 1634.00 1636.00 1637.00\n[181] 1713.00 1776.00 1745.00 1746.00 1749.00 1749.00 1764.00 1766.00 1786.00\n[190] 1795.00 1445.00 1468.00 1498.00 1499.00 1505.00 1525.00 1505.00 1508.00\n[199] 1524.00 1534.00 3305.00 3321.00 3331.00 3311.00 3313.00 3325.00 3327.00\n[208] 3345.00 3362.00 3381.00   61.10   62.88   62.89   63.67   64.10   64.16\n[217]   64.24   64.26   64.35   64.43 1238.00 1221.00 1222.00 1236.00 1251.00\n[226] 1265.00 1269.00 1271.00 1279.00 1282.00 2646.00 2661.00 2713.00 2734.00\n[235] 2724.00 2731.00 2732.00 2745.00 2750.00 2750.00   98.35   98.88   99.07\n[244]   99.35   99.63   99.80   99.82  100.30  100.31  100.50  265.67  268.11\n[253]  268.89  269.32  271.64  272.52  272.65  272.94  272.98  274.70  554.11\n[262]  564.43  575.78  576.64  579.27  580.02  581.48  585.72  586.63  587.09\n[271]  917.24  932.19  945.57  947.40  952.94  953.75  956.57  957.89  962.45\n[280]  963.38 2859.00 2877.00 2972.00 3037.00 3003.00 3029.00 3035.00 3041.00\n[289] 3051.00 3059.00  105.05  105.67  106.51  108.84  109.01  109.38  110.32\n[298]  110.43  111.07  111.57 3328.00 3380.00 3392.00 3363.00 3387.00 3395.00\n[307] 3396.00 3405.00 3409.00 3409.00  119.90  121.18  121.45  121.60  121.66\n[316]  121.77  121.78  122.89  123.19  123.23 2865.00 2876.00 2900.00 2954.00\n[325] 2971.00 2966.00 2971.00 2974.00 3008.00 3014.00  103.96  108.70  109.24\n[334]  109.95  109.96  110.34  110.47  110.49  110.51  110.76  106.97  108.74\n[343]  109.74  110.51  110.78  111.11  111.24  111.48  111.82  111.83 1187.00\n[352] 1203.00 1236.00 1208.00 1210.00 1214.00 1218.00 1222.00 1225.00 1228.00\n[361] 2608.00 2649.00 2654.00 2683.00 2697.00 2699.00 2721.00 2721.00 2723.00\n[370] 2727.00   97.98   98.49   99.09   99.19   99.66  100.21  100.22  100.44\n[379]  100.70  100.70  235.61  236.68  236.88  239.02  239.13  239.17  240.63\n[388]  241.14  242.38  242.99 1352.00 1370.00 1404.00 1380.00 1404.00 1425.00\n[397] 1452.00 1454.00 1465.00 1467.00 1513.00 1521.00 1528.00 1510.00 1520.00\n[406] 1547.00 1555.00 1563.00 1561.00 1565.00 1260.00 1298.00 1308.00 1318.00\n[415] 1320.00 1341.00 1343.00 1320.00 1326.00 1327.00 2821.00 2892.00 2919.00\n[424] 2930.00 2934.00 2962.00 2940.00 2985.00 2992.00 3000.00 3292.00 3315.00\n[433] 3321.00 3347.00 3362.00 3364.00 3373.00 3379.00 3395.00 3408.00\n\n\nPerfect! Let’s mutate() that variable in the data frame.\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., time = period_to_seconds(ms(time)))  \n\n  time             name year   event   team\n1 1409 Jocelyn Crawford 2019 50 FREE Athena\n2 1411    Ava Sealander 2022 50 FREE Athena\n3 1429        Kelly Ngo 2016 50 FREE Athena\n4 1451        Helen Liu 2014 50 FREE Athena\n5 1456      Michele Kee 2014 50 FREE Athena\n\n\nLet’s look at DAT now and see those seconds. You can look at the entire data frame if you wish rather than its head().\n\nhead(DAT)\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena\n\n\nThe data frame has not changed. The final step is to assign assign the returned data frame to an object. Remove the slice() so we get the entire data frame.\n\nDAT &lt;- DAT %&gt;%\n  mutate(., time = period_to_seconds(ms(time)))  \n\nNow let’s write this to /data. But we don’t want to overwrite this file. {here} won’t be as effective but we can concatenate the file_name string object with a prefix like \"cleaned\" using the paste() function in base R. We will add a hyphen, -, by passing it to the sep argument.\n\npaste(\"cleaned\", file_name, sep = \"-\")\n\n[1] \"cleaned-cms-top-all-time-2023-swim.xlsx\"\n\n\nWhen paired with here::here(), does the full file path look right?\n\nhere::here(\"data\", paste(\"cleaned\", file_name, sep = \"-\"))\n\n[1] \"C:/Users/gcook/Sync/git/dataviz23/data/cleaned-cms-top-all-time-2023-swim.xlsx\"\n\n\nWe also want to write a .csv file. Let’s use gsub() to look or the string pattern \".xlxs\" and replace it with \".csv\" for the file path string.\n\nnew_name &lt;- gsub(pattern = \".xlsx\", \n                 replacement = \".csv\", \n                 x = here::here(\"data\", paste(\"cleaned\", file_name, sep = \"-\"))\n                 )\n\nGot our new file name! Let’s write!\n\nreadr::write_csv(DAT, new_name)\n\nDone!"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarize-across-by-numeric-variables",
    "href": "modules/07_data_subsets_and_summaries.html#summarize-across-by-numeric-variables",
    "title": "Data subsets and summaries",
    "section": "Summarize across by numeric variables:",
    "text": "Summarize across by numeric variables:\n\nDAT %&gt;%\n  summarise(., across(.cols = where(is.numeric), \n                      .fns  = ~mean(.x, na.rm = TRUE))\n            )\n\n      time\n1 1309.388\n\n\nWell, that’s now actually impressive because there is only one numeric variable. What if we had more that were piped to summarize()?\n\nDAT %&gt;%\n  mutate(., \n         num1 = time,\n         num2 = time,\n         num3 = time\n         ) %&gt;%\n  summarise(., across(.cols = where(is.numeric), \n                      .fns  = ~mean(.x, na.rm = TRUE))\n            )\n\n      time     num1     num2     num3\n1 1309.388 1309.388 1309.388 1309.388\n\n\nThat was easy.\nBecause across() is so powerful, let’s just add another variable to the data frame for using in examples. You might also wish to reorder the position of variables in the data frame so that they are grouped in some way. We can use dplyr::relocate() to accomplish this. We will move the time column to the position .before one of the new variables using relocate(., time, .before = min).\nDoing so will also show you some ways to create variables.\n\nDAT &lt;- DAT %&gt;%\n  mutate(., \n         sec = time,  # will be redundant with time but named accurately\n         min  = time/60,\n         hour = time/(60*60)\n         ) %&gt;%\n  relocate(., time, .before = sec)\n\nTake a look:\n\nhead(DAT)\n\n              name year   event   team time  sec      min      hour\n1 Jocelyn Crawford 2019 50 FREE Athena 1409 1409 23.48333 0.3913889\n2    Ava Sealander 2022 50 FREE Athena 1411 1411 23.51667 0.3919444\n3        Kelly Ngo 2016 50 FREE Athena 1429 1429 23.81667 0.3969444\n4        Helen Liu 2014 50 FREE Athena 1451 1451 24.18333 0.4030556\n5      Michele Kee 2014 50 FREE Athena 1456 1456 24.26667 0.4044444\n6 Natalia Orbach-M 2020 50 FREE Athena 1457 1457 24.28333 0.4047222\n\n\nVariable names created with across() is controlled using the .names argument. The default is equivalent to .names = {.col}, which means that the name(s) are inherited from the .cols argument; the names are a stand-in for the name specification. If you wish to have control over the names, you can pass a string that that either appends (e.g.,\"{.col}suffix\") or prepends (e.g.,\"prefix{.col}\") a string to each column name. This string looks odd because it’s a special glue specification that glues together with a string with an object. We will use this concept later when using the {glue} library.\nWhen modifying .names, include a character like \"_\" (e.g.,\"{.col}_suffix\") so that the column names and the appended text are separated, making the name easily legible. If you summarize to create means, a good suggestion is something like (e.g.,\"{.col}_mean\" or (e.g.,\"{.col}_mn\")) so that you know the variable is a mean. If you prefer the function name first, you can use a prefix (e.g.,\"mean_{.col}\").\n\nDAT %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\", \"hour\"), \n                      .fns  = ~mean(.x, na.rm = TRUE),\n                      .names = \"{.col}_mean\"\n                      )\n            )\n\n  sec_mean min_mean hour_mean\n1 1309.388 21.82313 0.3637189\n\n\nYou can see how all variables in the summary end in \"_mean\".\nYou can also glue the function and the column names together by passing .names = \"{.col}_{.fn}\".\n\nDAT %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\", \"hour\"), \n                      .fns  = ~mean(.x, na.rm = TRUE),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            )\n\n     sec_1    min_1    hour_1\n1 1309.388 21.82313 0.3637189\n\n\nYou you will see there is a number that is appended to the variable name. This is because there is only one function passed to .fns. You can pass more using a special object called a list (see ?list). Unlike vectors, elements of lists need not be the same kind. Elements of lists can combinations of characters, numbers, data frames, functions, etc."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#passing-multiple-functions-from-a-list-in-across",
    "href": "modules/07_data_subsets_and_summaries.html#passing-multiple-functions-from-a-list-in-across",
    "title": "Data subsets and summaries",
    "section": "Passing multiple functions from a list() in across()",
    "text": "Passing multiple functions from a list() in across()\nPassing functions as a list requires a little fancy coding. We will pass two functions as a list so that we can calculate both the mean() and the sd() on the variables passed to across().\nA list is a special object (e.g., container) for which its elements can be different types of objects. Whereas elements of vectors can be only character or only numeric, elements of lists can hold different object. One element can be a numeric vector, another element a data frame, another element a character vector, etc. Many functions used in R will actually return lists for which elements contain different types of objects.\nOK back to two or more functions. If you pass a list() with arguments for the mean and the sd (e.g., list(mean, sd), you can summarize by both. If you want to prevent errors (yes you do) and want to keep the summaries separate (probably so), you can modify .names to pass both the column and the function (e.g., \"{.col}_{.fn}\"). The underscore is not needed here; it only helps with readability of the variables so that you don’t end up with variable names like var1mean but instead var1_mean.\nLet’s pass the summary procedures as a list to include measures of mean and standard deviation for the variables.\n\nDAT %&gt;%\n  summarise(., across(.cols  = c(\"sec\", \"min\", \"hour\"), \n                      .fns   = list(mean, sd),\n                      .names = \"{.col}_{.fn}\")\n            )\n\n     sec_1    sec_2    min_1    min_2    hour_1    hour_2\n1 1309.388 1225.964 21.82313 20.43274 0.3637189 0.3405456\n\n\nWell those are not exactly the names we want but it illustrates how names are created. Because we have two summary functions for each column variable passed to across(), they are enumerated according to the order in the list (e.g., mean then standard deviation).\n\nFixing .names when passing lists to .cols in across()\nEnumeration is not helpful for remembering variable names. There are different ways to do fix this problem, some of which may be better under certain scenarios. You have to determine what approach is best but I’ll lay out some limitations. If you pass only the functions into the list, then when you pass {.fn} to .names, the variable names in the returned data frame will take on a numeric value representing the order/element position of the functions as you entered them in the list. In this coding instance, means would be named with\"_1\" and standard deviation names with \"_2\". This approach, however, leads to confusing variable names because you have to remember which is 1 and which is 2 and of course explain this to anyone with whom you share the data. Let’s take a look.\nA better approach could be to assign the mean and sd functions their own names in the list() function call. By doing so, the name is appended and the new variable is named meaningfully.\nLet’s modify what we pass to .fns by passing a list containing 3 functions (e.g., mean(), sd(), and length()) and give each there name. I know this part is confusing because the () are dropped inside the list. This is just how R works. Don’t blame the messenger.\n\nDAT %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\", \"hour\"), \n                      .fns  = list(mean = mean, \n                                   sd = sd,\n                                   n = length\n                                   ),\n                      .names = \"{.col}_{.fn}\")\n            )\n\n  sec_mean   sec_sd sec_n min_mean   min_sd min_n hour_mean   hour_sd hour_n\n1 1309.388 1225.964   440 21.82313 20.43274   440 0.3637189 0.3405456    440\n\n\nImportantly, however, certain functions like mean() will operate in ways you might not expect. One one hand, it does what we expect when all elements can be used to calculate the mean.\n\nmean(DAT$time)\n\n[1] 1309.388\n\n\nOn the other hand, if there is a missing value, it does not computer the mean but instead something else. Let’s add an NA to the vector using c() to see what happens.\n\nmean(c(DAT$time, NA))\n\n[1] NA\n\n\n\nUnderstanding NAs when passing lists to .cols in across()\nThe mean() function returns NA rather than a mean. If there is just one NA, mean() returns NA. By design this is actually good.\nLet’s also try sd() for the standard deviation of a vector:\n\nsd(c(DAT$time, NA))\n\n[1] NA\n\n\nThe median of a vector, median():\n\nmedian(c(DAT$time, NA))\n\n[1] NA\n\n\nThe length of a vector, length():\n\nlength(c(DAT$time, NA))\n\n[1] 441\n\n\nWell, that’s interesting. By default length() will return the number of elements of the vector including NAs but by default mean() will not return the mean of a vector with NAs because na.rm = FALSE by default. If you wish to calculate the mean by removing the NAs, pass na.rm = TRUE.\n\nmean(c(DAT$time, NA), na.rm = T)\n\n[1] 1309.388\n\n\nMake note, however, that the length of this vector without NAs is shorter than the length with NAs. We can test this hypothesis on a vector with and without the NA by using na.omit() to omit any of them. Using our vector we added an NA, let’s omit it.\n\nna.omit(c(DAT$time, NA))\n\n  [1] 1409.00 1411.00 1429.00 1451.00 1456.00 1457.00 1457.00 1467.00 1473.00\n [10] 1442.00 3065.00 3084.00 3101.00 3116.00 3116.00 3148.00 3125.00 3125.00\n [19] 3134.00 3137.00  110.30  111.89  112.40  112.55  112.57  112.67  112.80\n [28]  112.83  112.88  112.89  297.37  299.22  299.78  300.06  300.21  300.47\n [37]  301.17  301.99  302.16  302.23  614.33  615.40  622.59  622.84  624.14\n [46]  624.82  626.34  626.89  633.15  636.60 1018.48 1023.21 1026.78 1029.09\n [55] 1029.26 1032.18 1032.46 1033.58 1041.98 1044.49 3366.00 3367.00 3391.00\n [64] 3371.00 3434.00 3443.00 3438.00 3456.00 3467.00 3476.00  119.91  122.10\n [73]  123.73  123.85  123.92  125.10  125.56  125.71  125.76  126.13   61.84\n [82]   63.28   63.51   63.91   64.16   64.19   64.65   64.66   64.77   64.94\n [91]  134.83  135.62  138.99  139.06  139.78  140.01  141.17  141.77  142.34\n[100]  142.83 3316.00 3332.00 3333.00 3323.00 3374.00 3364.00 3387.00 3402.00\n[109] 3407.00 3416.00  121.84  122.58  123.80  124.05  124.42  124.81  126.40\n[118]  127.12  127.33  127.42  120.69  123.59  123.79  124.74  125.41  126.82\n[127]  127.12  127.14  127.81  127.94 1389.00 1412.00 1413.00 1415.00 1407.00\n[136] 1411.00 1413.00 1418.00 1425.00 1427.00 3065.00 3067.00 3092.00 3079.00\n[145] 3087.00 3088.00 3089.00 3097.00 3105.00 3116.00  110.91  110.98  111.39\n[154]  111.41  111.56  111.64  111.95  112.53  112.78  113.04  255.73  267.18\n[163]  270.33  270.77  271.96  272.45  272.57  272.68  274.16  274.27 1594.00\n[172] 1582.00 1588.00 1617.00 1642.00 1650.00 1634.00 1634.00 1636.00 1637.00\n[181] 1713.00 1776.00 1745.00 1746.00 1749.00 1749.00 1764.00 1766.00 1786.00\n[190] 1795.00 1445.00 1468.00 1498.00 1499.00 1505.00 1525.00 1505.00 1508.00\n[199] 1524.00 1534.00 3305.00 3321.00 3331.00 3311.00 3313.00 3325.00 3327.00\n[208] 3345.00 3362.00 3381.00   61.10   62.88   62.89   63.67   64.10   64.16\n[217]   64.24   64.26   64.35   64.43 1238.00 1221.00 1222.00 1236.00 1251.00\n[226] 1265.00 1269.00 1271.00 1279.00 1282.00 2646.00 2661.00 2713.00 2734.00\n[235] 2724.00 2731.00 2732.00 2745.00 2750.00 2750.00   98.35   98.88   99.07\n[244]   99.35   99.63   99.80   99.82  100.30  100.31  100.50  265.67  268.11\n[253]  268.89  269.32  271.64  272.52  272.65  272.94  272.98  274.70  554.11\n[262]  564.43  575.78  576.64  579.27  580.02  581.48  585.72  586.63  587.09\n[271]  917.24  932.19  945.57  947.40  952.94  953.75  956.57  957.89  962.45\n[280]  963.38 2859.00 2877.00 2972.00 3037.00 3003.00 3029.00 3035.00 3041.00\n[289] 3051.00 3059.00  105.05  105.67  106.51  108.84  109.01  109.38  110.32\n[298]  110.43  111.07  111.57 3328.00 3380.00 3392.00 3363.00 3387.00 3395.00\n[307] 3396.00 3405.00 3409.00 3409.00  119.90  121.18  121.45  121.60  121.66\n[316]  121.77  121.78  122.89  123.19  123.23 2865.00 2876.00 2900.00 2954.00\n[325] 2971.00 2966.00 2971.00 2974.00 3008.00 3014.00  103.96  108.70  109.24\n[334]  109.95  109.96  110.34  110.47  110.49  110.51  110.76  106.97  108.74\n[343]  109.74  110.51  110.78  111.11  111.24  111.48  111.82  111.83 1187.00\n[352] 1203.00 1236.00 1208.00 1210.00 1214.00 1218.00 1222.00 1225.00 1228.00\n[361] 2608.00 2649.00 2654.00 2683.00 2697.00 2699.00 2721.00 2721.00 2723.00\n[370] 2727.00   97.98   98.49   99.09   99.19   99.66  100.21  100.22  100.44\n[379]  100.70  100.70  235.61  236.68  236.88  239.02  239.13  239.17  240.63\n[388]  241.14  242.38  242.99 1352.00 1370.00 1404.00 1380.00 1404.00 1425.00\n[397] 1452.00 1454.00 1465.00 1467.00 1513.00 1521.00 1528.00 1510.00 1520.00\n[406] 1547.00 1555.00 1563.00 1561.00 1565.00 1260.00 1298.00 1308.00 1318.00\n[415] 1320.00 1341.00 1343.00 1320.00 1326.00 1327.00 2821.00 2892.00 2919.00\n[424] 2930.00 2934.00 2962.00 2940.00 2985.00 2992.00 3000.00 3292.00 3315.00\n[433] 3321.00 3347.00 3362.00 3364.00 3373.00 3379.00 3395.00 3408.00\nattr(,\"na.action\")\n[1] 441\nattr(,\"class\")\n[1] \"omit\"\n\n\nAnd then get the length when NAs are omitted:\n\nlength(na.omit(c(DAT$time, NA)))\n\n[1] 440\n\n\nThis behavior is important because if you want to obtain the mean of a variable with NAs and the sample size using length(), your sample size will be inaccurate.\nIn order to see these operations on a data frame and in the context of dplyr::summarize(), let’s modify the data frame to include an additional row with some mission values. One simple approach is to use base R to use rbind() to bind a new row to the end of the data frame. In this case, the contents of that new row will be the same as the first row of the data frame (e.g., DAT[1,]). Then the name will be changed and some values will be made missing.\n\nDAT &lt;- rbind(DAT, \n             DAT[1,]\n             )\n\nModify the cells in the data frame using bracket notation from base R. When using brackets, the data frame can be referenced using row and column arguments.\nExamples:\nDAT[]       # all rows and columns\n\nDAT[,]      # all rows and columns (preferred separation with comma)\n\nDAT[1, ]    # row 1, all columns\n\nDAT[,1]     # all rows, column 1\n\nDAT[1:5, \"name\"]    # rows 1 through 5, \"name\" column\n\nDAT[, c(\"name\", \"year\"]    # all rows, \"name\" and \"year\" columns\n\nDAT[15, \"name\"]    # row 15 through 5, \"name\" column\nYou can also obtain the dimensions of a data frame using dim() from base R.\n\ndim(DAT)\n\n[1] 441   8\n\n\ndim() returns a vector with two elements: the number of rows and the number of columns. We can use this to reference the last row in the data frame in order to modify it for this example.\nFollowing from above, examine the last row, change the \"name\" to “Anonymous” and then put NAs in the \"sec\" and \"min\" columns for the same row. Remember, vectors are pure characters or numeric, they cannot contain a mixture of them. Because \"name\" is character vector and \"sec\" and \"min\" are numeric vectors, we need to fix them separately. There are other ways to accomplish this goal but this example illustrates the approach in base R so that you have some exposure.\n\nDAT[dim(DAT)[1], ]                              # the current row contents\n\n                name year   event   team time  sec      min      hour\n441 Jocelyn Crawford 2019 50 FREE Athena 1409 1409 23.48333 0.3913889\n\nDAT[dim(DAT)[1], \"name\"] &lt;- \"Anonymous\"         # make name anonymous\n\nDAT[dim(DAT)[1], c(\"sec\", \"min\")] &lt;- c(NA, NA)  # set these cells to NA\n\nAre NAs across the last row now?\n\nDAT %&gt;% tail()\n\n             name year               event   team time  sec      min      hour\n436 Aaron Lutzker 2019 100 BRST-Relay Spl.   Stag 3364 3364 56.06667 0.9344444\n437  Sean Hoerger 2020 100 BRST-Relay Spl.   Stag 3373 3373 56.21667 0.9369444\n438   Tyler Welty 2017 100 BRST-Relay Spl.   Stag 3379 3379 56.31667 0.9386111\n439  Brad Perfect 2013 100 BRST-Relay Spl.   Stag 3395 3395 56.58333 0.9430556\n440  Grant Murray 2018 100 BRST-Relay Spl.   Stag 3408 3408 56.80000 0.9466667\n441     Anonymous 2019             50 FREE Athena 1409   NA       NA 0.3913889\n\n\n\n\nComparing some functionality when passing lists to .cols in across()\nWhen functions do not contain argument for dealing with NAs, there is na.omit(), a function that takes an object and removes NAs. So you can just pass the variable to na.omit() and then wrap it in the metric function of interest. Also, because na.rm = T cannot be used for length(), na.omit() offers consistency across all functions and as a result, I believe, less confusion.\nUnfortunately, accomplishing this task can be rather tricky and requires some new syntax. This requires usage of what’s called a “lambda” technique. You will want to incorporate ~ and .x into your code. The ~ is used to indicate that you are supplying a lambda function and use of .x is to indicate where the variable in across() is used. Using this type of syntax, we can pass functions to the .fns argument that operate across a set of variables. The ?across() documentation calls this “a {purrr}-style lambda” in the arguments section. This approach can be a little bit confusing, so I’m going to show you an example, and then walk through it step by step. You can always create code snippets so you don’t have to rely on memory write complicated code like this.\nAnyway, we will precede the function with ~ and reference the vector using .x. Let’s do this and change the .fns argument slightly.\nHere is a general example:\nname = ~function(na.omit(.x))\nWe will summarize only time and sec because those variables are identical except for the row we added. We will also add dplyr::n() to see what’s going on with that function.\n\nDAT %&gt;%\n  summarise(., across(.cols = c(\"time\", \"sec\"), \n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   #sd = ~sd(na.omit(.x)),\n                                   len = ~length(na.omit(.x)),\n                                   n = ~dplyr::n()\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n  time_mean time_len time_n sec_mean sec_len sec_n\n1  1309.614      441    441 1309.388     440   441\n\n\nSo what happened? The means and lengths for time and sec are not the same. Means differ because they are calculated by different values depending on the presence of NAs. But notice that the n’s are the same based on dplyr::n(). How can the means and differ if the n’s are the same?\nSo what’s the point of all of this? Well, you need to be careful not to apply functions and assume they are doing what you believe you are doing. You always need to be smarter than the code you use. Also, there is no single answer for dealing with data. Sometimes one approach will be appropriate and in other instances another approach will be. You as the data scientist need to know that there are different methods so that you an decide where to apply those different methods."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarize-by-groups-using-group_by",
    "href": "modules/07_data_subsets_and_summaries.html#summarize-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarize by Groups Using group_by()",
    "text": "Summarize by Groups Using group_by()\n\nIdentifying how to group\nWhen you have subgroups in your data, you will often want to create summary statistics by those group levels. A typical grouping approach is by some categorical or factor variable present in a data frame. Using glympse(), we can view all variables to see what might be of interest.\n\nglimpse(DAT)\n\nRows: 441\nColumns: 8\n$ name  &lt;chr&gt; \"Jocelyn Crawford\", \"Ava Sealander\", \"Kelly Ngo\", \"Helen Liu\", \"…\n$ year  &lt;chr&gt; \"2019\", \"2022\", \"2016\", \"2014\", \"2014\", \"2020\", \"2020\", \"2010\", …\n$ event &lt;chr&gt; \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\"…\n$ team  &lt;chr&gt; \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Ath…\n$ time  &lt;dbl&gt; 1409.00, 1411.00, 1429.00, 1451.00, 1456.00, 1457.00, 1457.00, 1…\n$ sec   &lt;dbl&gt; 1409.00, 1411.00, 1429.00, 1451.00, 1456.00, 1457.00, 1457.00, 1…\n$ min   &lt;dbl&gt; 23.483333, 23.516667, 23.816667, 24.183333, 24.266667, 24.283333…\n$ hour  &lt;dbl&gt; 0.39138889, 0.39194444, 0.39694444, 0.40305556, 0.40444444, 0.40…\n\n\nLooks like some factor variables we can group by include name, year, event, and team."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarize-a-one-specific-variable-by-groups-using-group_by",
    "href": "modules/07_data_subsets_and_summaries.html#summarize-a-one-specific-variable-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarize A (one) Specific Variable by Groups Using group_by()",
    "text": "Summarize A (one) Specific Variable by Groups Using group_by()\n\nA single summary metric\nPerhaps you only want to obtain the mean() or the sum() or the sd() for a variable. If so, this is easiest.\n\nGrouping by one variable:\nThe data in cms-top-all-time-2023-swim.xlsx contain the top records for swimming events. You might be curious what year was the best of all time or what swimmer (e.g., name) has attained the most records of all time. There are different ways to accomplish this goal.\nOne approach that might be the most straight forward to new programmers is to mutate a constant count variable on each row which can be used to sum the counts for different groups.\n\nDAT %&gt;%\n  mutate(., count = 1) %&gt;%         # mutate a new variable where all rows get a 1\n  group_by(., name) %&gt;%            # group by the swimmer name\n  summarise(., count = sum(count)) # sum the count and assign it the name count\n\n# A tibble: 142 × 2\n   name            count\n   &lt;chr&gt;           &lt;dbl&gt;\n 1 A Breazeale         8\n 2 A Roeseler          2\n 3 Aaron Lutzker       6\n 4 Abel Sapirstein     1\n 5 Alec Vercruysse     4\n 6 Alex Mendoza        2\n 7 Alex Poltash        6\n 8 Allyson Yao         3\n 9 Amy Fuller          1\n10 Andrew Cox          4\n# ℹ 132 more rows\n\n\nBy default, the data frame is arranged by the grouping variable (e.g., name). We can change the order of the rows by count using arrange() but this function by default sorts in an ascending manner. If you want a descending sorting, pass count to desc() to arrange the data frame in this way. We can also assign it to an object.\n\nNAME_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  group_by(., name) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n\nNAME_count\n\n# A tibble: 142 × 2\n   name          count\n   &lt;chr&gt;         &lt;dbl&gt;\n 1 Michele Kee      11\n 2 Augusta Lewis    10\n 3 Matt Williams    10\n 4 Kelly Ngo         9\n 5 A Breazeale       8\n 6 Ava Sealander     8\n 7 Gary Simon        8\n 8 Marco Conati      8\n 9 Nic Tekieli       7\n10 Aaron Lutzker     6\n# ℹ 132 more rows\n\n\nWe can see that the top counts of all time are by Michele Kee for a total of 11. Kudos to Michele!\n\nYEAR_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  group_by(., year) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n\nYEAR_count\n\n# A tibble: 32 × 2\n   year  count\n   &lt;chr&gt; &lt;dbl&gt;\n 1 2022     81\n 2 2023     59\n 3 2020     41\n 4 2017     38\n 5 2014     27\n 6 2019     23\n 7 2013     22\n 8 2015     20\n 9 2016     17\n10 2018     16\n# ℹ 22 more rows\n\n\nWe can see that the year with the most best are by 2022 for a total of 81. Hooray for 2022!\n\n\nGrouping by two or more variables:\nWe can also summarize both the teams as well in order to see the top swimmer by team. If you want to summarize more than one variable, pass them both in group_by():\n\nTEAM_NAME_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  group_by(., team, name) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n\nTEAM_NAME_count\n\n# A tibble: 142 × 3\n# Groups:   team [2]\n   team   name          count\n   &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;\n 1 Athena Michele Kee      11\n 2 Athena Augusta Lewis    10\n 3 Stag   Matt Williams    10\n 4 Athena Kelly Ngo         9\n 5 Athena Ava Sealander     8\n 6 Stag   A Breazeale       8\n 7 Stag   Gary Simon        8\n 8 Stag   Marco Conati      8\n 9 Stag   Nic Tekieli       7\n10 Athena Ella Blake        6\n# ℹ 132 more rows\n\n\n\n\nFiltering rows and then grouping by one variable:\nFor Athenas:\n\nATHENA_NAME_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  filter(., team == \"Athena\") %&gt;%\n  group_by(., name) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n\nATHENA_NAME_count\n\n# A tibble: 67 × 2\n   name               count\n   &lt;chr&gt;              &lt;dbl&gt;\n 1 Michele Kee           11\n 2 Augusta Lewis         10\n 3 Kelly Ngo              9\n 4 Ava Sealander          8\n 5 Ella Blake             6\n 6 Jamee Mitchum          6\n 7 Katie Bilotti          6\n 8 Mackenzie Mayfield     6\n 9 Annika Jessen          5\n10 Jocelyn Crawford       5\n# ℹ 57 more rows\n\n\nWe can see that the top counts of all time are by Michele Kee with a total of 11. Nice work Michele!\nAnd for Stags:\n\nSTAG_NAME_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  filter(., team == \"Stag\") %&gt;%\n  group_by(., name) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n\nSTAG_NAME_count\n\n# A tibble: 75 × 2\n   name          count\n   &lt;chr&gt;         &lt;dbl&gt;\n 1 Matt Williams    10\n 2 A Breazeale       8\n 3 Gary Simon        8\n 4 Marco Conati      8\n 5 Nic Tekieli       7\n 6 Aaron Lutzker     6\n 7 Alex Poltash      6\n 8 Blake Weber       6\n 9 Sam Willett       5\n10 Tom Harrison      5\n# ℹ 65 more rows\n\n\nWe can see that the top counts of all time are by Matt Williams with 10. Go Matt!\nTo wrap up this example, sometimes working with separate data frames using filter() can provide more useful or manageable summaries.Perhaps you only want to obtain the mean() or the sum() or the sd() for a single variable. If so, this approach may be easiest.\nIf you are curious, here is a story covering “How CMS teams became the Stags and Athenas”.\n\n\n\nMultiple summary metrics\nSometimes you need more than one summary statistic, for example, the mean() and the sd(). This is a little more complex to code.\nNote: In these code blocks, some arguments may be removed for readability.\n\nGrouping by one variable:\n\nDAT %&gt;%\n  group_by(., event) %&gt;%\n  summarise(., \n            sec_mean = mean(sec, na.rm = T),  \n            sec_median = median(sec, na.rm = T)\n            )\n\n# A tibble: 22 × 3\n   event               sec_mean sec_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.\n 2 100 BREAST             1725.      1696.\n 3 100 BRST-Relay Spl.    1710.      1678.\n 4 100 FLY                3158.      3165 \n 5 100 FLY-Relay Spl.     3135.      3152.\n 6 100 FREE               2917.      2908.\n 7 100 FREE-Relay Spl.    2888.      2896 \n 8 1000 FREE               601.       601.\n 9 1650 FREE               990.       991.\n10 200 BACK                116.       116.\n# ℹ 12 more rows\n\n\nWe can also write the summary functions as a list inside across() along with passing .names = \"{.col}_{.fn}\" if you want the variables named automatically. This approach is more complex but is more flexible.\nWhen you want to summarize across multiple variables using a list of functions, you will want to make sure your .fns argument passes a function using a {purrr}-style lambda (e.g.,~) for that the function is applied across the variables. You will also want to edit .names = \"{.col}_{.fn}\" so that the naming is done automatically rather than hard coding the names.\n\nDAT %&gt;%\n  group_by(., event) %&gt;%\n  summarise(., across(.cols = \"sec\",\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   median = ~median(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n# A tibble: 22 × 3\n   event               sec_mean sec_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.\n 2 100 BREAST             1725.      1696.\n 3 100 BRST-Relay Spl.    1710.      1678.\n 4 100 FLY                3158.      3165 \n 5 100 FLY-Relay Spl.     3135.      3152.\n 6 100 FREE               2917.      2908.\n 7 100 FREE-Relay Spl.    2888.      2896 \n 8 1000 FREE               601.       601.\n 9 1650 FREE               990.       991.\n10 200 BACK                116.       116.\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT %&gt;%\n  group_by(., event, team) %&gt;%\n  summarise(., \n            sec_mean = mean(sec, na.rm = T),  \n            sec_median = median(sec, na.rm = T)\n            )\n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team   sec_mean sec_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436  \n 2 100 BACK            Stag     2996.      3032  \n 3 100 BREAST          Athena     64.0       64.2\n 4 100 BREAST          Stag     3386.      3394. \n 5 100 BRST-Relay Spl. Athena     63.6       64.1\n 6 100 BRST-Relay Spl. Stag     3356.      3363  \n 7 100 FLY             Athena   3365.      3369  \n 8 100 FLY             Stag     2950.      2968. \n 9 100 FLY-Relay Spl.  Athena   3332.      3326  \n10 100 FLY-Relay Spl.  Stag     2938.      2937  \n# ℹ 34 more rows\n\n\nOr pass the list:\n\nDAT %&gt;%\n  group_by(., event, team) %&gt;%\n  summarise(., across(.cols = \"sec\",\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   median = ~median(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team   sec_mean sec_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436  \n 2 100 BACK            Stag     2996.      3032  \n 3 100 BREAST          Athena     64.0       64.2\n 4 100 BREAST          Stag     3386.      3394. \n 5 100 BRST-Relay Spl. Athena     63.6       64.1\n 6 100 BRST-Relay Spl. Stag     3356.      3363  \n 7 100 FLY             Athena   3365.      3369  \n 8 100 FLY             Stag     2950.      2968. \n 9 100 FLY-Relay Spl.  Athena   3332.      3326  \n10 100 FLY-Relay Spl.  Stag     2938.      2937  \n# ℹ 34 more rows"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarizing-multiple-variables-by-groups-using-group_by",
    "href": "modules/07_data_subsets_and_summaries.html#summarizing-multiple-variables-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarizing Multiple Variables by Groups Using group_by()",
    "text": "Summarizing Multiple Variables by Groups Using group_by()\nSo far, we have shown how to summarize a single variable either with or without grouping by levels of another variable. Summaries, however, are often done for multiple variables in data frame. For example, you might want to obtain the mean() for multiple variables or obtain the mean() and the max() (or some other summary statistic) for multiple variables. The following examples prepare you for such tasks.\n\nA single summary metric\n\nGrouping by one variable:\n\nDAT %&gt;%\n  group_by(., event) %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\"),\n                      .fns = ~mean(.x, na.rm = T),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n# A tibble: 22 × 3\n   event               sec_1 min_1\n   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n 1 100 BACK            3209. 53.5 \n 2 100 BREAST          1725. 28.8 \n 3 100 BRST-Relay Spl. 1710. 28.5 \n 4 100 FLY             3158. 52.6 \n 5 100 FLY-Relay Spl.  3135. 52.2 \n 6 100 FREE            2917. 48.6 \n 7 100 FREE-Relay Spl. 2888. 48.1 \n 8 1000 FREE            601. 10.0 \n 9 1650 FREE            990. 16.5 \n10 200 BACK             116.  1.94\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT %&gt;%\n  group_by(., event, team) %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\"),\n                      .fns = ~mean(.x, na.rm = T),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team    sec_1 min_1\n   &lt;chr&gt;               &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 100 BACK            Athena 3421.  57.0 \n 2 100 BACK            Stag   2996.  49.9 \n 3 100 BREAST          Athena   64.0  1.07\n 4 100 BREAST          Stag   3386.  56.4 \n 5 100 BRST-Relay Spl. Athena   63.6  1.06\n 6 100 BRST-Relay Spl. Stag   3356.  55.9 \n 7 100 FLY             Athena 3365.  56.1 \n 8 100 FLY             Stag   2950.  49.2 \n 9 100 FLY-Relay Spl.  Athena 3332.  55.5 \n10 100 FLY-Relay Spl.  Stag   2938.  49.0 \n# ℹ 34 more rows\n\n\n\n\n\nMultiple summary metrics\nAnd if you need to summarize using multiple metrics, then pass the list into .fns:\n\nGrouping by one variable:\n\nDAT %&gt;%\n  group_by(., event) %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\"),\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   median = ~median(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n# A tibble: 22 × 5\n   event               sec_mean sec_median min_mean min_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.    53.5       53.5 \n 2 100 BREAST             1725.      1696.    28.8       28.3 \n 3 100 BRST-Relay Spl.    1710.      1678.    28.5       28.0 \n 4 100 FLY                3158.      3165     52.6       52.8 \n 5 100 FLY-Relay Spl.     3135.      3152.    52.2       52.5 \n 6 100 FREE               2917.      2908.    48.6       48.5 \n 7 100 FREE-Relay Spl.    2888.      2896     48.1       48.3 \n 8 1000 FREE               601.       601.    10.0       10.0 \n 9 1650 FREE               990.       991.    16.5       16.5 \n10 200 BACK                116.       116.     1.94       1.93\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT %&gt;%\n  group_by(., event, team) %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\"),\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   median = ~median(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   event [22]\n   event               team   sec_mean sec_median min_mean min_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436      57.0       57.3 \n 2 100 BACK            Stag     2996.      3032      49.9       50.5 \n 3 100 BREAST          Athena     64.0       64.2     1.07       1.07\n 4 100 BREAST          Stag     3386.      3394.     56.4       56.6 \n 5 100 BRST-Relay Spl. Athena     63.6       64.1     1.06       1.07\n 6 100 BRST-Relay Spl. Stag     3356.      3363      55.9       56.0 \n 7 100 FLY             Athena   3365.      3369      56.1       56.2 \n 8 100 FLY             Stag     2950.      2968.     49.2       49.5 \n 9 100 FLY-Relay Spl.  Athena   3332.      3326      55.5       55.4 \n10 100 FLY-Relay Spl.  Stag     2938.      2937      49.0       49.0 \n# ℹ 34 more rows\n\n\nDepends on the order in group_by(), so change the order:\n\nDAT %&gt;%\n  group_by(., team, event) %&gt;%\n  summarise(., across(.cols = \"sec\",\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   n = ~length(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   team [2]\n   team   event               sec_mean sec_n\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;dbl&gt; &lt;int&gt;\n 1 Athena 100 BACK              3421.     10\n 2 Athena 100 BREAST              64.0    10\n 3 Athena 100 BRST-Relay Spl.     63.6    10\n 4 Athena 100 FLY               3365.     10\n 5 Athena 100 FLY-Relay Spl.    3332.     10\n 6 Athena 100 FREE              3115.     10\n 7 Athena 100 FREE-Relay Spl.   3088.     10\n 8 Athena 1000 FREE              625.     10\n 9 Athena 1650 FREE             1031.     10\n10 Athena 200 BACK               124.     10\n# ℹ 34 more rows\n\n\nNotice the change in the order of the column variables. But remember, you can change the order later using select() and/or relocate()."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarizing-multiple-variables-with-reference-by-name",
    "href": "modules/07_data_subsets_and_summaries.html#summarizing-multiple-variables-with-reference-by-name",
    "title": "Data subsets and summaries",
    "section": "Summarizing Multiple Variables With Reference by Name`",
    "text": "Summarizing Multiple Variables With Reference by Name`\n\nVariables that are numeric\nYou can also pass variables that are a certain type, like numeric.\n\nDAT %&gt;%\n  group_by(., team, event) %&gt;%\n  summarise(., across(.cols = where(is.numeric), \n                      .fns = ~mean(.x, na.rm = TRUE), \n                      .names = \"{.col}\")\n            )\n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   team [2]\n   team   event                 time    sec   min   hour\n   &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Athena 100 BACK            3421.  3421.  57.0  0.950 \n 2 Athena 100 BREAST            64.0   64.0  1.07 0.0178\n 3 Athena 100 BRST-Relay Spl.   63.6   63.6  1.06 0.0177\n 4 Athena 100 FLY             3365.  3365.  56.1  0.935 \n 5 Athena 100 FLY-Relay Spl.  3332.  3332.  55.5  0.926 \n 6 Athena 100 FREE            3115.  3115.  51.9  0.865 \n 7 Athena 100 FREE-Relay Spl. 3088.  3088.  51.5  0.858 \n 8 Athena 1000 FREE            625.   625.  10.4  0.174 \n 9 Athena 1650 FREE           1031.  1031.  17.2  0.286 \n10 Athena 200 BACK             124.   124.   2.07 0.0345\n# ℹ 34 more rows\n\n\n\n\nVariables by pattern match\nThis approach is fun, especially if you have already named variables in ways that make selection really useful. This data frame is constrained a bit so the examples may be silly.\n\nUsing starts_with()\n\nDAT %&gt;%\n  group_by(., team, event) %&gt;%\n  summarise(., across(.cols = starts_with(\"t\"),\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   n = ~length(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   team [2]\n   team   event               time_mean time_n\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;dbl&gt;  &lt;int&gt;\n 1 Athena 100 BACK               3421.      10\n 2 Athena 100 BREAST               64.0     10\n 3 Athena 100 BRST-Relay Spl.      63.6     10\n 4 Athena 100 FLY                3365.      10\n 5 Athena 100 FLY-Relay Spl.     3332.      10\n 6 Athena 100 FREE               3115.      10\n 7 Athena 100 FREE-Relay Spl.    3088.      10\n 8 Athena 1000 FREE               625.      10\n 9 Athena 1650 FREE              1031.      10\n10 Athena 200 BACK                124.      10\n# ℹ 34 more rows\n\n\n\n\nUsing & for complex selection\nYou obviously cannot calculate numeric metrics for character variables. But how might you select variables that contain a certain character pattern but are also numeric? You cannot nest these functions (e.g., where(is.numeric(contains(\"pattern\")))). You can, however, pass the functions separately.\n\nDAT %&gt;%\n  group_by(., team, event) %&gt;%\n  summarise(., across(.cols = contains(\"e\") & where(is.numeric),\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   n = ~length(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   team [2]\n   team   event               time_mean time_n sec_mean sec_n\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;dbl&gt;  &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;\n 1 Athena 100 BACK               3421.      10   3421.     10\n 2 Athena 100 BREAST               64.0     10     64.0    10\n 3 Athena 100 BRST-Relay Spl.      63.6     10     63.6    10\n 4 Athena 100 FLY                3365.      10   3365.     10\n 5 Athena 100 FLY-Relay Spl.     3332.      10   3332.     10\n 6 Athena 100 FREE               3115.      10   3115.     10\n 7 Athena 100 FREE-Relay Spl.    3088.      10   3088.     10\n 8 Athena 1000 FREE               625.      10    625.     10\n 9 Athena 1650 FREE              1031.      10   1031.     10\n10 Athena 200 BACK                124.      10    124.     10\n# ℹ 34 more rows"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#a-functional-approach",
    "href": "modules/07_data_subsets_and_summaries.html#a-functional-approach",
    "title": "Data subsets and summaries",
    "section": "A Functional Approach",
    "text": "A Functional Approach\nYou can also throw your summaries into functions if you wish. We will create a new object that is a function object. We need to give it a name and we need to define arguments to make the function operate. We will want to make sure we have numeric variables.\n\nsummarizer &lt;- function(data, \n                       cols = NULL, \n                       ...\n                       ) {\n  data %&gt;%\n    group_by(...) %&gt;%\n    summarise(., across(.cols = {{cols}} & where(is.numeric),\n                     .fns = list(\n                          mean = ~mean(.x, na.rm = TRUE),\n                          sd   = ~sd(.x, na.rm = TRUE)\n                          ), \n                     .names = \"{col}_{fn}\")\n              )\n}\n\nTest the function:\nWithout grouping:\n\nsummarizer(DAT, cols = contains(\"e\"))\n\n# A tibble: 1 × 4\n  time_mean time_sd sec_mean sec_sd\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1     1310.   1225.    1309.  1226.\n\n\nWith grouping:\n\nsummarizer(DAT, cols = c(min, hour), event)\n\n# A tibble: 22 × 5\n   event               min_mean min_sd hour_mean hour_sd\n   &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 100 BACK               53.5   3.76     0.891  0.0626 \n 2 100 BREAST             28.8  28.4      0.479  0.473  \n 3 100 BRST-Relay Spl.    28.5  28.1      0.475  0.469  \n 4 100 FLY                52.6   3.63     0.877  0.0605 \n 5 100 FLY-Relay Spl.     52.2   3.44     0.871  0.0573 \n 6 100 FREE               48.6   3.43     0.810  0.0571 \n 7 100 FREE-Relay Spl.    48.1   3.46     0.802  0.0576 \n 8 1000 FREE              10.0   0.432    0.167  0.00719\n 9 1650 FREE              16.5   0.728    0.275  0.0121 \n10 200 BACK                1.94  0.136    0.0324 0.00227\n# ℹ 12 more rows\n\n\nAnd of course, when you really get excited, you could add functions so that you can perform different metrics. When you are done, you can save your favorite function to a file you can source()."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html",
    "title": "{ggplot} and the grammar of graphics",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#readings",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#readings",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Introduction to Vizualization\nWilke (2019). Fundamentals of Data Visualization. Aesthetic Mapping\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Introduction\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Understanding the Grammar\n\nOptional (more on the grammar):\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Build a plot layer by layer"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#load-libraries",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#load-libraries",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#external-functions",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#external-functions",
    "title": "{ggplot} and the grammar of graphics",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#ggplot-plot-composition",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#ggplot-plot-composition",
    "title": "{ggplot} and the grammar of graphics",
    "section": "{ggplot} Plot Composition",
    "text": "{ggplot} Plot Composition\nThere are five mapping components:\n\nLayer containing geometric elements and statistical transformations:\n\n\nData a tidy data frame, most typically in long/narrow format\nMapping defining how vector variables are visualized (e.g., aesthetics like shape, color, position, hue, etc.)\nStatistical Transformation (stat) representing some summarizing of data (e.g., sums, fitted curves, etc.)\nGeometric object (geom) controlling the type of visualization\nPosition Adjustment (position) controlling where visual elements are positioned\n\n\nScales that map values in the data space to values in aesthetic space\nA Coordinate System for mapping coordinates to the plane of a graphic\nA Facet for arranging the data into a grid; plotting subsets of data\nA Theme controlling the niceties of the plot, like font, background, grids, axes, typeface etc.\n\nThe grammar does not:\n\nMake suggestions about what graphics to use\nDescribe interactivity with a graphic; {ggplot2} graphics are static images, though they can be animated"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#initializing-the-plot-object",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#initializing-the-plot-object",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Initializing the Plot Object",
    "text": "Initializing the Plot Object\nWhat is a ?ggplot object? Review the docs first. Let’s apply the base layer using ggplot(). This function takes a data set and simply initializes the plot object so that you can build other components on top of it. By default, data = NULL so, you will need to pass some data argument. There is also a mapping parameter for mapping the aesthetics of the plot, by default, mapping = aes(). If you don’t pass a data frame to data, what happens?\n\nggplot()\n\n\n\n\nAn object is created but it contains no data. The default is some rectangle in space."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#passing-the-data-to-ggplot",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#passing-the-data-to-ggplot",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Passing the Data to ggplot()",
    "text": "Passing the Data to ggplot()\nYou cannot have a plot without data, so we need some data in a tidy format. We can read in a data set or create one.\n\nSWIM &lt;- readr::read_csv(here::here(\"data\", \"cleaned-cms-top-all-time-2023-swim.csv\"))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): name, year, event, team\ndbl (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nDATA &lt;- data.frame(\n A = c(1, 2, 3, 4), \n B = c(2, 5, 3, 8), \n C = c(10, 15, 32, 28), \n D = c(\"Task A\", \"Task A\", \"Task B\", \"Task B\"),\n E = c(\"circle\", \"circle\", \"square\", \"square\")\n)\n\nLet’s also quickly change the variable names to titlecase() so that the first letter is capitalize.\n\nnames(SWIM) &lt;- tools::toTitleCase(names(SWIM))\n\nNow we can pass this data frame to data.\n\nggplot(data = SWIM)\n\n\n\n\nOK, so still nothing. That’s because we haven’t told ggplot() what visual properties or aesthetics to include in the plot. Importantly, you do not have to provide this information in a base layer. {ggplot2} is flexible insofar as you can pass data in different places depending what data you want to use and at which layer on how you will use it.\nIf you set data = SWIM, the subsequent layers of the plot will inherit that data frame if you do not pass the argument in a different layer. However, you are not limited to passing only one data set. You might wish to plot the aesthetics of one data frame in one layer and then add another layer of aesthetics taken from a different data frame. TLDR; you can pass data, or not pass data, in the initialization of the base layer."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#scalingscale-transformation",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#scalingscale-transformation",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Scaling/Scale Transformation",
    "text": "Scaling/Scale Transformation\n\nprint(SWIM)\n\n# A tibble: 440 × 5\n    Time Name             Year  Event   Team  \n   &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1  1409 Jocelyn Crawford 2019  50 FREE Athena\n 2  1411 Ava Sealander    2022  50 FREE Athena\n 3  1429 Kelly Ngo        2016  50 FREE Athena\n 4  1451 Helen Liu        2014  50 FREE Athena\n 5  1456 Michele Kee      2014  50 FREE Athena\n 6  1457 Natalia Orbach-M 2020  50 FREE Athena\n 7  1457 Suzia Starzyk    2020  50 FREE Athena\n 8  1467 Katie Bilotti    2010  50 FREE Athena\n 9  1473 Jenni Rinker     2011  50 FREE Athena\n10  1442 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nLooking at the data, we have a tidy file composed of columns and rows. Looking at the data frame, you see the ‘identity’ of each case. This term is important to {ggplot}. By identity we mean variables are a numeric value, character, or factor. What you see in the data frame is the identity of the variables. Of course, we can change the identity of a variable in some way by transforming the values to z scores, log values, or each average them together to take their count and then plot any of those data. But those transformations do not represent true identities as they appear in a data set.\nIn order to take the data units in the data frame so that they can be represented as physical units on a plot (e.g., points, bars, lines, etc.), there needs to be some scaling transformation. The plot function needs to understand how many pixels high and wide to create a plot and the plot needs to know the limits of the axes for example. Similarly, the plot function needs to know what shapes to present, how many, etc. By default, the statistical transformation is an ‘identity’ transformation, or one that just takes the values and plots them as their appear in the data (their identity). More on this when we start plotting."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#choosing-a-coordinate-system",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#choosing-a-coordinate-system",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Choosing a Coordinate System",
    "text": "Choosing a Coordinate System\nAll we have now is the base layer that is taking on some coordinates. For example, where are the points plotted on the plot? The system can follow the Cartesian coordinate system or a Polar coordinate system. An example of this will follow later. For now, the default is chosen for you. What might you think it is?"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#adding-aesthetic-mappings",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#adding-aesthetic-mappings",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Adding Aesthetic Mappings",
    "text": "Adding Aesthetic Mappings\nIf you wanted your plot geometry (the geom() you add later) to inherit properties of the initialized base layer, you could pass aesthetics to the mapping argument mapping = aes() in the ggplot() function. Notice that the argument that we pass to mapping is another function, aes().\nFor example:\n\nggplot(data = SWIM, mapping = aes())\n\n\n\n\nBut this still does not present anything you can see. You might have guessed that the reason you do not see anything is because nothing was passed to aes(). Here is where you map data to aesthetics by specifying the variable information and passing them to aes(). Looking at ?aes, we see that aes() maps how properties of the data connect to, or map, onto with the features of the visualization (e.g., axis position, color, size, etc.). The aesthetics are the visual properties of the visualization, so they are essential to map by passing arguments to aes().\nHow many and what variables do pass? Looking at ?aes, you see that x and y are needed.\nBecause we passed data = SWIM in ggplot(), we can reference the variables by their column names without specifying the data frame.\nIf x = Year and y = Time:\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       )\n\n\n\n\nOK, now we can see something. Although this is progress, what is visible is rather empty and ugly. We can see that the aesthetic layer now applied to the plot scales the data to present Year along the x-axis with a range from lowest to highest value from that vector. Similarly, the mapping presents Time along the y-axis with a range from lowest to highest value in the vector. Also, the aesthetics include the variable name as a the label for the x and y axes. Of course, you can change these details later in a layer as well. More on that later.\nYou might have been tempted to pass the variable names a quoted strings (e.g., “A” and “B) but if you do that, you’ll get something different.\n\nggplot(data = SWIM, \n       mapping = aes(x = \"Year\", y = \"Time\")\n       )\n\n\n\n\nIf we want to plot the data as they are in the data frame, we would apply the ‘identity’ transformation. Again, by identity, we just need to instruct ggplot() to use the data values in the data frame. If you wanted to plot the means, frequency count, or something else, we would need to tell ggplot() how to transform the data. We are not at that point yet though."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#adding-plot-geometries",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#adding-plot-geometries",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Adding Plot Geometries",
    "text": "Adding Plot Geometries\nWe do not yet have any geometries, or geoms, added. All geom functions will take the form geom_*(). As you will see, geoms can take many forms, including, points, lines, bars, text, etc. If we want the values in Year and Time to be plotted as x and y coordinates representing points on the plot, we can add a point geometry using geom_point().\nBy adding a layer, {ggplot2} really means add, as in +. We will take the initialize plot object that contains some data along with some mapping of variables to x an y coordinates and add to it a geometry. Combined, these functions will display data which adheres to some statistical transformation at some position along some scale an in some theme.\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point()\n\n\n\n\nAt some point, you will want to assign the plot to an object. When you do, the plot will not actually render for you to view.\n\nmy_first_plot &lt;- ggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point()\n\nThen:\n\nmy_first_plot\n\n\n\n\nPro Tip: You would need to call the plot to render it as illustrated above … unless you wrap it in ().\n\n(my_first_plot &lt;- ggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point())\n\n\n\n\nYou now have a data visualization! The points geometry, geom_point(), inherits the aesthetic mapping from above and plots them as points."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#how-and-where-to-map-aesthetics",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#how-and-where-to-map-aesthetics",
    "title": "{ggplot} and the grammar of graphics",
    "section": "How and Where to Map Aesthetics?",
    "text": "How and Where to Map Aesthetics?\nYou might be wondering how you map these aesthetic properties so that when you attempt to do so, you don’t get a bunch of errors. There are two places you can map aesthetics:\nEither in the initialized plot object:\n\nggplot(data = data, mapping = aes(x, y)) + geom_point()\n\nOr in the geometry:\n\nggplot() +geom_point(data = data, mapping = aes(x, y))\n\nWe can map aesthetics in the initialized plot object by also assigning this to an object named map just so we can reference it as need.\nWhen we do this mapping:\n\nmap &lt;- ggplot(data = SWIM, \n              mapping = aes(Year, Time))\n\nThe aesthetics are inherited by the geometries that follow, which then do not require any mapping of their own…\n\nmap + \n  geom_point() + \n  geom_line()\n\n\n\n\nBut when aesthetics are NOT mapped in initialized plot:\n\nmap &lt;- ggplot() \n\nThere are no aesthetics to be inherited by the plot geometry functions because they are not passed to the ggplot() object. In this case they must be mapped as arguments the geometries themselves.\nPlot points:\n\nmap + \n  geom_point(data = SWIM, \n             mapping = aes(Year, Time)) \n\n\n\n\nPlot a line:\n\nmap + \n  geom_line(data = SWIM, \n            mapping = aes(x = Year, y = Time))\n\n\n\n\nIn a later section, we will differentiate between setting and mapping aesthetic attributes."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-as-is-from-the-data-frame",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-as-is-from-the-data-frame",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Mapping a variable as-is from the data frame`",
    "text": "Mapping a variable as-is from the data frame`\nggplot() defines the data as well as variables in aes(). You can easily map the x or y variable to the geom_*().\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = Year))"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-differs-from-whats-in-the-data-frame",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-differs-from-whats-in-the-data-frame",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Mapping a variable that differs from what’s in the data frame",
    "text": "Mapping a variable that differs from what’s in the data frame\nYou can also change a variable type in the scope of the plot without modifying it in the data frame. Let’s change Year to numeric to see what happens:\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = as.numeric(Year)))\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\n\n\n\n\nSimilarly, if we had a numeric variable and wanted to make a factor():\n\nSWIM &lt;- SWIM %&gt;%\n  mutate(., Year2 = as.numeric(Year))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Year2 = as.numeric(Year)`.\nCaused by warning:\n! NAs introduced by coercion\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = as.factor(Year2)))\n\n\n\n\nOr make a character:\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = as.character(Year2)))\n\n\n\n\nYou may have noticed that when mapped variables are numeric, the aesthetics are applied continuously and when they are character (e.g., categorical, factors), they are applied discretely. Here is a good example of mapping variable Year not as itself but by changing it to a as.numeric() or changing numeric variables to either a factor() or a character vector. You might notice that the content in the legend is messy now. Fixing this is something we will work on as we progress."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-is-not-defined-in-the-aes-mapping-of-ggplot",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-is-not-defined-in-the-aes-mapping-of-ggplot",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Mapping a variable that is not defined in the aes() mapping of ggplot()",
    "text": "Mapping a variable that is not defined in the aes() mapping of ggplot()\nSometimes you may wish to map a variable that is not defined in ggplot(). We can map a variable that is neither x nor y:\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = Team))\n\n\n\n\nThis is no problem because Team exists in the SWIM data passed to data in the ggplot() object."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#setting-and-mapping-combinations",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#setting-and-mapping-combinations",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Setting and Mapping Combinations",
    "text": "Setting and Mapping Combinations\nWe can also combine setting aesthetics and mapping them as long as the mapping takes place outside inside aes() and the setting takes place outside.\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(color = \"maroon\", aes(shape = Team))\n\n\n\n\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(color = \"blue\", aes(size = Time))\n\n\n\n\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(shape = 21, aes(color = Event))\n\n\n\n\nImportantly, just as you cannot pass constant values as aesthetics in aes(), you cannot pass a variable to an aesthetic in the geom_*() outside of aes().\nFor example, passing color = Team outside of aes() in this instance will throw an error.\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n     geom_point(color = Team)\n\nError: object 'Team' not found\nIn summary, when you want to set an aesthetic to a constant value, do so in the geom_*() function, otherwise pass an aesthetic to aes() inside the geometry function. Color options can be discovered using colors(). Linetype has fewer options. To make the color more or less transparent, adjust alpha transparency (from 0 = invisible to 1).\n\nggplot(SWIM, aes(x = Year, y = Time)) +\n  geom_point() +\n  geom_line(linetype = \"dashed\",\n            color = \"red\",\n            alpha = .3)"
  },
  {
    "objectID": "modules/10_visualizing_associations.html",
    "href": "modules/10_visualizing_associations.html",
    "title": "Visualizing associations",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/10_visualizing_associations.html#readings",
    "href": "modules/10_visualizing_associations.html#readings",
    "title": "Visualizing associations",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from FDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing associations"
  },
  {
    "objectID": "modules/10_visualizing_associations.html#external-functions",
    "href": "modules/10_visualizing_associations.html#external-functions",
    "title": "Visualizing associations",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/10_visualizing_associations.html#libraries",
    "href": "modules/10_visualizing_associations.html#libraries",
    "title": "Visualizing associations",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/10_visualizing_associations.html#load-libraries",
    "href": "modules/10_visualizing_associations.html#load-libraries",
    "title": "Visualizing associations",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/10_visualizing_associations.html#a-simple-scatterplot-with-geom_point",
    "href": "modules/10_visualizing_associations.html#a-simple-scatterplot-with-geom_point",
    "title": "Visualizing associations",
    "section": "A Simple Scatterplot with geom_point()",
    "text": "A Simple Scatterplot with geom_point()\nThe typical xy scatter plot is used to visualize the relationship between two numeric variables. Those numeric variables may be continuous or discrete, though you will see that data visualizations involving discrete numeric data do have some limitations. We will attempt to circumvent some of those limitations using different functions from {ggplot2} in the examples presented. These approaches used can also be applied to continuous data.\nAs with all geoms, geom_point() can accept its own data and aesthetics or inherit them from the initialized ggplot() object. Similar to geom_col(), we need an x and a y variable to create a point plot. The specification of x or y may depended on variables as predictors or outcomes or based on the goal of the plot.\nBecause we have swim data represeting completion times for events of different distances, we will set x = Distance and y = Time so that we can visualize Time as a function of Distance.\nTaking the data frame and piping that to ggplot(), we declare the data and the mapping to x and y.\ngeom_point(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\nWe can add the geom_point() layer that instructs how to display the data. Right out of the box, we get:\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Distance, y = Time)) +\n  geom_point()\n\n\n\n\nYour first point plot! You see small black points, axis labels, tick marks for intervals, and some apparent clustering of points around certain distances. You also see the association between distances and time, a positive association.\nWe will filter some of the event data to illustrate the {ggplot2} functionality.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point()\n\n\n\n\nThe association is still apparent in the plot. The tick marks along the x-axis changed but the clustering of points is still present. We will reserve discussion of axes for a later topic but the clustering is still present. This issue will often present itself when plotting a continuous variable like time against a discrete variable like event distance.\nIn another world, the variables may be reversed such that swimmers are tasked with swimming for a given time t, and their performance outcome is the distance they traveled. On one hand, this approach may be efficient because there would be no waiting around for slower swimmers to finish an event. On the other hand, measurement of distance in a liquid medium may be extremely difficult and time consuming, event completion may be lack luster for athletes, and the wait for results would be annoyingly painful for fans as they wait in agony for the measurement results to declare a winner. In the end, we would still have a discrete variable, now time, and a continuous variable, now distance. The data would still plague the visualization in the same way.\n\nAssociations with some smoothing\ngeom_smooth() is {ggplot2}’s solution to seeing some patterns of association in the data.\ngeom_smooth(\n  mapping = NULL,\n  data = NULL,\n  stat = \"smooth\",\n  position = \"identity\",\n  ...,\n  method = NULL,\n  formula = NULL,\n  se = TRUE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\nBy default, geom_smooth() does not add a linear fit to the data. Instead, method = 'loess' applies a Loess function on y ~ x, which will highlight curvature or wiggliness of the fit moving through data. The amounts of movement of Loess can also be controlled by the span arguemnt. You can also add your own formula to the smoothing function by passing it to the formula argument.\nAdding a geom_smooth() layer:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\nYou see the function curving in blue through the data and a gray shading around it.\nImportantly, you might want to apply another method of fit, for example a linear model, which you can achieve using method = \"lm\".\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nNow you see a line of best fit along with that gray shading again. That shading represents error variance in the model, which we will address in a topic on visualizing uncertainty. We can turn it off by setting se = FALSE.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nOf some plots, you may also not see the fit line through the entire plot. For example, changing the limits on the x axis, from 0 to 800 by adding plot layer, xlim(0, 800), will demonstrate a problem that you might experience and wish to fix.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() + \n  xlim(0, 800) +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe can change the default behavior using fullrange = T:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() + \n  xlim(0, 800) +\n  geom_smooth(method = \"lm\", \n              fullrange = T\n              )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe line now extends to the limets. geom_smooth() has many options but for now you see how we can plot points and add various fits to them."
  },
  {
    "objectID": "modules/10_visualizing_associations.html#geom_point-when-a-variable-is-a-factor",
    "href": "modules/10_visualizing_associations.html#geom_point-when-a-variable-is-a-factor",
    "title": "Visualizing associations",
    "section": "geom_point() when a variable is a factor",
    "text": "geom_point() when a variable is a factor\nPoint plots can all be used for plotting individual data points for categorical data.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point()\n\n\n\n\nYou see now that geom_point() will plot only the existing levels of Distance in the data set and provides the level label at each tick mark. If your goal is to change your tick marks for numeric data, this is not the solution because the scale will violate rules of mathematics.\n\nSetting aesthetic\nWe can change color, fill, shape, size, and alpha of points in the plot either by setting a constant or mapping color to an aesthetic. We will address setting here and mapping later.\nHere we plot open circles in black, filled with green, and make them somewhat transparent.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(shape = 21, \n             size = 3,\n             col = \"black\", \n             fill = \"green\",\n             alpha = .3\n             )\n\n\n\n\nThe procedure of mapping aesthetics introduces other variables from the data set into the plot. We do not need to change the color or shape of points for each event distance for the viewer to understand the plot. Position along x already communicates the distance. Mapping aesthetics of variables already present would confound the data and result in a plot that manipulates both position and color to communicate one variable, distance. This is not needed. By contrast, mapping variables that are not already present in the data introduces new information and complexity. These represent a different class of plots altogether."
  },
  {
    "objectID": "modules/10_visualizing_associations.html#multiclass-scatterplots",
    "href": "modules/10_visualizing_associations.html#multiclass-scatterplots",
    "title": "Visualizing associations",
    "section": "Multiclass Scatterplots",
    "text": "Multiclass Scatterplots\nThe typical xy scatter plot is used to visualize the relationship between two continuous variables. When your data vary in a different way and you don’t want to create a 3-dimensional plot (you really don’t want to anyway), you can map a third variable to the point plot to create a multiclass scatterplot that decorates the plot with a new aesthetic (e.g., color, size, transparency, etc.).\nIn most instances, you will want to map categorical variable to aesthetics like size or shape and numeric variables to aesthetics like size and alpha.\n\nMapping existing variables to aesthetics\nWe can map an existing variable to a new aesthetic. For example, Distance is already present in the plot but we can map it the color aesthetic. using aes(col = Distance). Well, because color may best be used or categorical variables, we will make it factor on the fly.\nUsing aes(col = factor(Distance)), we get:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = factor(Distance)),\n    alpha = .3,\n    position = \"jitter\"\n    )\n\n\n\n\nWe are not encoding a third variable in this plot but rather confounding color with an existing variable in the point plot. This approach can bias attention to particular subsets of the data unintentionally especially when some colors share properties with some colors used in the plot but not others.\nWe could also map an existing numeric variable to the color aesthetic. Using aes(col = factor(Distance)), we get:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = Distance),\n    alpha = .3,\n    position = \"jitter\"\n    )\n\n\n\n\nThe darker blue points are now associated with shorter distances, which itself may be conceptually difficult but the point here is that a data element can be mapped to an aesthetic.\nThese two examples, however, do not may new variables that introduce new information to understand subsets of the data.\n\n\nMapping new variables to aesthetics\nWe can map a new variable to the plot. Looking at the variables present, we can map School to the color in order to see whether time and distance are related in the same way across schools. The legend will be really big, so we will also remove it for now.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = School),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend=F\n    )\n\n\n\n\nAnd for men and women:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = Team),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    )\n\n\n\n\n\n\nAdding model fits using geom_smooth():\nIn order to see a linear association, however, we might want to fit a linear model to the subsets. We will need to make sure there are no factor() or as.character() functions for the variables or you will not see a line.\nSpecifically, we will use geom_smooth() to add a fit line to the plot.\nThe pattern for all schools:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(col = School),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe will that a line is fit through ALL of the data illustrating of course that time increases as a function of distance. Yes, this is silly but the main goal here is to understand how {ggplot} works.\nIn order to examine the linear fit pattern for all schools, we would map the School variable as an aesthetic to geom_smooth().\nNotice, however, that we are now passing aes(col = School) in geom_point() to make points for schools vary by color and in geom_smooth() to apply fit lines for each school. Remember that geom_*() aesthetics are inderited from ggplot() by default (e.g., inherit.aes = TRUE).\nLet’s just map aes(col = School) in ggplot() instead so that both geom_*()s inherit it.\nThe pattern across schools:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., \n         aes(x = Distance, y = Time, col = School),\n         ) +\n  geom_point(\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nYou see that the linear fits are almost identical for the two schools. You can comment out show.legend = F to see the school names.\nWhat about across male and female swimmers?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., \n         aes(x = Distance, y = Time, col = Team),\n         ) +\n  geom_point(\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe visualization now shows that the slope differs by subgroup, in particular that the slope is steeper for female swimmers. Again, comment out show.legend = F to see. We can add confidence intervals or error to the fit line on the plot but doing so is something we will deal with in the topic on visualizing uncertainty. That being said, the astute student of statistics should also know there is uncertainty to the lint-of-best-fit because it represents a fit of the current data, which may have sampling error. Bootstrapping the model fit will allow or visualization of uncertainty of the model fit.\n\n\nBubble Plots\nWhen the decorative element is point size, the plot type is referred to as a bubble plot and this is a special case of a multiclass scatterplot. Though some may refer to is as such, technically speaking, adding a color element is not bubble plot for obvious reasons.\n\n\nMapping existing variables to aesthetics\nWe will map a variable to the size aesthetic of the point plot. For now, don’t worry about arguments other than size.\nWe can map size = Time:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(size = Time),\n    alpha = .2,\n    position = \"jitter\"\n    )\n\n\n\n\nThe bubbles here simply represent the y variable mapped to the size aesthetic. We are not conveying a third variable in this plot but rather confounding size with an existing variable in the point plot. One thing to know is that the visual system loves size and to shading (e.g,. contrast). Both are present here, so be mindful of bias such a plot has on visual attention and perception. We will address such issues when we address concepts of attentional control.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(size = Time),\n    alpha = .2,\n    position = \"jitter\"\n    )\n\n\n\n\n\n\nMapping new variables to aesthetics\nWe will look at the data in a different way now. The data frame contains split times for the first 50. A split time is a time measurement of partial distance in swimming. For example, for a 200 meter event, you can measure split times for ways you a split the event (e.g., 25, 50, 100 meters). A swimmer who maintains the same time across splits is performing differently from one who swims at different paces across splits.\nLet’s look at split times for 50 meters as a function of distance. You will notice that Distance = 50 is dropped out of the plots because there is no split time.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Split50)) +\n  geom_point(\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nYou can see that the split times for the first 50 meters seems to increase as the distance of the event increases. Swimmers are pacing differently.\nAnd for splits and even time:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Split50, y = Time)) +\n  geom_point(\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLonger split times are associated with overall longer event times.\nMapping a new variable like Distance to point size will adjust the size of the points by the event distance.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Split50, y = Time)) +\n  geom_point(\n    aes(size = Distance),\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can see that the point diameter increases with distance. Although this bubble plot introduces a new variable, Distance, to the plot which was not visualized before, it really fails to communicate something useful in the data that was not already presented.\nWhat if we plotted Time as as function of Distance and mapped Split50 to the size aesthetic?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50),\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThis bubble plot now illustrates that the split times vary within the event distance and is associate with longer event times.\nAnd if we map event types to color:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    alpha = .3,\n    position = \"jitter\",\n    show.legend = F\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can see that the larger point sizes reflecting longer split times also appears to be associated with the event participated in. Notice the color palette used and the size of the points in the legend. Some color are difficult to differentiate when the alpha is dialed down. But without lowering alpha, the points would have a different problem. If this were a plot we wanted to share, we would need to fix it a lot. Later on, we will cover ways to change colors, the size of the points in the legend later, change the scale and tick marks on the axes, etc.\nYou can see how in some cases, bubble plots may be appropriate for presenting 4-Dimensional data for which two variables are numeric (X and Y), an additional variable is categorical and mapped to color (or shape) and another variable is numeric and mapped to size.\n{ggplot2}} will also provide warnings when applying a discrete variable to an aesthetic like size, for example, Using size for a discrete variable is not advised."
  },
  {
    "objectID": "modules/10_visualizing_associations.html#connected-scatterplots",
    "href": "modules/10_visualizing_associations.html#connected-scatterplots",
    "title": "Visualizing associations",
    "section": "Connected Scatterplots",
    "text": "Connected Scatterplots\nThere are instances when you may wish to visualize the order of events in a scatterplot. For example, the demand and price or a good may be associated but those may also change at different time points. These are sometimes presented as connected scatterplots.\nWhereas geom_line() will create a line between x and y data (imaging invisible points), geom_path() will connect those x and y positions to reveal other associations like the time pattern.\nLet’s compare the two functions using some made up data.\n\nDAT &lt;- data.frame(\n  x = c(1, 2, 3, 4, 5, 4, 7),\n  y = c(12, 16, 13, 15, 19, 20, 22),\n  label = c(2013:2019)\n  ) \n\nA geom_line():\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_line()\n\n\n\n\nA geom_path():\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_path(col = \"red\")\n\n\n\n\nAdding labels as text (and changing their color and size):\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_path(col = \"red\") +\n  geom_text(aes(label = label,\n                size = factor(label), \n                col = label)\n            )\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\nNote that geom_line() does not work well with the existing swim data. Points will be connected.\n\nSWIM %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_line()\n\n\n\n\nAnd geom_path() will connect the based on the order of the date but this type of plot is not relevant here as there is no order or time course.\n\nSWIM %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_path()"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html",
    "href": "modules/11_spatial_position_and_adjustment.html",
    "title": "Spatial position and adjustment",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#readings",
    "href": "modules/11_spatial_position_and_adjustment.html#readings",
    "title": "Spatial position and adjustment",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Overlapping points\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Overplotting"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#external-functions",
    "href": "modules/11_spatial_position_and_adjustment.html#external-functions",
    "title": "Spatial position and adjustment",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#libraries",
    "href": "modules/11_spatial_position_and_adjustment.html#libraries",
    "title": "Spatial position and adjustment",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#load-libraries",
    "href": "modules/11_spatial_position_and_adjustment.html#load-libraries",
    "title": "Spatial position and adjustment",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#default-point-position",
    "href": "modules/11_spatial_position_and_adjustment.html#default-point-position",
    "title": "Spatial position and adjustment",
    "section": "Default Point Position",
    "text": "Default Point Position\nWe will use the SWIM data from 2023 to manipulate point position. To illustrate the effect best, we will also trim out some long times/events.\nFirst, we should remind ourselves that the default setting for points plotting using geom_point() is the “identity” for the x and y mappings.\nThe default position argument is position = \"identity\":*\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = \"identity\")"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#adjusting-point-position",
    "href": "modules/11_spatial_position_and_adjustment.html#adjusting-point-position",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Position",
    "text": "Adjusting Point Position\nThere are two main ways of adjusting the spatial position for point plots. One solution is to adjust the position argument within geom_point() and the other is to use a sister function geom_jitter(). However, you adjust your data, you must acknowledge that you are the creator of the graphic and that are are making the decision to change those point positioning. The adjustment will influence how users perceive, attend to, and interpret the visualization you produce and distribute. You must consider the degree of the adjustment and weigh the costs and benefits of “massaging” the data visualized. You also much assume responsibility and accountability for doing so.\n\ngeom_point(position = \"jitter\")\ngeom_jitter()\n\n\nChanging the position argument of geom_point()\nUsing gome_point(), we can pass position = \"jitter\" instead of position = \"identity\":\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = \"jitter\")\n\n\n\n\n\n\nUsing geom_jitter()\nWe can use geom_jitter() to jitter the points for us. The default argument for position adjustment in this function is position = \"jitter\". For more details, you can read the documentation of geom_jitter().\nUsing geom_jitter() rather than geom_point():\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_jitter()\n\n\n\n\n\nCustomizing jitter spread\nGiven position = \"jitter\" applies a stochastic function to reposition points along both x and y axes, one should not be surprised that to see functions contain arguments allowing for more control over movement along each axis (e.g., height and width).\nIn general, smaller values passed to these arguments will result in less dispersion of the points from their original positions. For both arguments, a jittering of points is applied in both positive and negative directions, so the total spread is twice the value specified in the argument. For example, passing width = 1 will jitter points having an “identity” position of x along that x axis, ranging from x - 1 to x + 1. You should also be mindful of the scales because an adjustment of 1 on some scales will be minimal and an adjustment of .3 on other scales may be quite dramatic. For example, on these scales, you really wont perceive much change if you used .3.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_jitter(height = 5, \n              width  = 10\n              )\n\n\n\n\nDespite setting these arguments to values, keep in mind that they do not control all points in exactly the same manner each time. The function still has some random component to it, so you will not be able to reproduce the plot with any consistency. We will address the topic of plot replication versus reproduction later.\n\n\n\nChanging the position of a categorical variable\nAnother limitation that you see in this example is the limited movement of the points. They are fairly locked along the Distance variable. Part of the reason is that these values are discrete, or categorical rather than continuous so the movement is very constrained relative to what you might normally see in a numeric by numeric scatterplot.\nLet’s change Distance to a character (e.g,. is.character()) or a factor (e.g., factor(), as.factor(), etc.) on the fly inside ggplot():\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point()\n\n\n\n\nYou will immediately notice that the x axis has changed. Disregard the label change as that is a simple fix with xlab(\"Distance\") and is irrelevant to this current discussion. Importantly, factorizing the variable will make visible all levels of the factor variable present in the data. For example, you now see 50 which was not displayed before. This outcome illustrates the difference in default scale_*() functions for numeric and categorical data but we will address scale manipulations later. You will also notice that the interval between factor levels is equivalent along the x axis despite them not being numerically equal by nature. That behavior is a trade off by default which you can fix should you consider the perceptual implications of this approach problematic.\nThe main point here is to illustrate position manipulation. Let’s use geom_jitter() for comparison.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter() \n\n\n\n\nBy default, you see sufficient movement in points, which may be too much or too little jitter depending on the data. We can adjust the height and width of the jitter here too but notice the value change when the variable is a factor.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 2,\n              height = 0\n              )\n\n\n\n\nLet’s pass larger values:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 5,\n              height = 0\n              )\n\n\n\n\nAnd larger values:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 10,\n              height = 0\n              )\n\n\n\n\nThe more you jitter, the more the data take a position different from their “identity”. The adjustment is obviously more misleading when made on Time variable. Let’s dial the movement down a bit using a decimal value:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = .3,\n              height = 0\n              )\n\n\n\n\nYou will see that the height position did not change but the width did. Note that for categorical data (e.g., characters and factors), a width adjustment of 0.5 will jitter points in a way that makes them difficult if not impossible to determine the category level they belong to. In other words, the points from the levels of Distance overlap even though they should not. The last plot is the only one of those above that jitters in a way that still allows you to the the groups from which the data belong.\nAs a final note, be mindful of jitter adjustments applied by default. If you have a discrete variable, jitter along the corresponding axis and leave the other at 0. If both x and y are numeric/continuous, jitter only enough to fix your problem without altering the data more than necessary because otherwise you are lying with data visualizations whether intentionally or unintentionally so.\n\n\nReproducing Plots\nYou can observe the behavior of the functions used above by replicating the function calls. By doing so, you will see that the position of the points changed across those calls. Although we can replicate a procedure to address overplotting, we can not do so in a way that makes the position reproducible across multiple function calls because of the stochastic function applied to do so.\nBy reproduction, we mean that you return the same plot for every single call of the same code. Reproduction minimizes the confusion that occurs when your visualization changes when presented to your audience (including you) on different occasions.\n\nSetting a seed in geom_point()\nIn order to reproduce point position instead of replicating something very similar, use position_jitter() along with the seed argument. The seed determines the calculation of the jitter, so setting it will result in returning the same plot every single call.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15)\n             )\n\n\n\n\nFor this reason, I recommend using geom_point() over geom_jitter()."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#adjusting-point-transparency",
    "href": "modules/11_spatial_position_and_adjustment.html#adjusting-point-transparency",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Transparency",
    "text": "Adjusting Point Transparency\nWhen points are opaque, your only option is to change their position. But changing position means changing the data from identity to something else. This may not be your first line of attack.\nNow that we have set a seed or reproduction, we can also adjust the transparency of the points by passing values from 0 to 1 to the alpha argument. In conjunction with position adjustments, alpha adjustments will facilitate the perception of two points (compared with one) with minimal position adjustment.\nBy default points are opaque, alpha = 1:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = 1)\n\n\n\n\nAnd can be made invisible by passing alpha = 0:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = 0)\n\n\n\n\nValues in between can be used to find the correct balance between points being too transparent, too dark, and too difficult to see when multiple points take the same position. Of course, with this data example, the identity of all points are the same at each level of the event by nature. As a result, you see a lot of variation that is not really present in the data.\nToo light to perceive?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .2)\n\n\n\n\nToo dark to discriminate?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .4)\n\n\n\n\nKeep in mind also that alpha transparency will interact with point color, so there is never a particular rule of thumb."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#adding-group-level-data",
    "href": "modules/11_spatial_position_and_adjustment.html#adding-group-level-data",
    "title": "Spatial position and adjustment",
    "section": "Adding Group Level Data",
    "text": "Adding Group Level Data\nOne problem with all the points is the inability to either see or process all of the points in the plot. Extracting out mean Time for the Distance variable is quite the cognitive task.\nRemember that {ggplot} allows for adding layers to plots. We have shown how to add a geom_point() and a geom_bar() to the same plot using the same data. But we could also add the a geom that presents a new data frame. For example, we could obtain the mean Time for each Distance and pass that data frame as a separate geom_point() layer.\nLet’s first get the summarized data frame:\n\nMEAN_TIMES_BY_DIST &lt;- SWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  group_by(., Distance) %&gt;%\n  summarize(., Time = mean(Time))\n\nWe see the association at the group level too.\n\nMEAN_TIMES_BY_DIST %&gt;% knitr::kable()\n\n\n\n\nDistance\nTime\n\n\n\n\n50\n23.59429\n\n\n100\n55.19567\n\n\n200\n121.51304\n\n\n400\n268.98667\n\n\n500\n305.51333\n\n\n\n\n\nNow let’s add that layer and make the points “tomato” colored:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .4) +\n  geom_point(data = MEAN_TIMES_BY_DIST,\n             mapping = aes(x = Distance, Time),\n             col = \"tomato\", \n             size = 4, \n             alpha = .7)\n\n\n\n\nWe could do the same thing for the counts:\n\nCOUNTS_BY_DIST &lt;- SWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  group_by(., Distance) %&gt;%\n  summarize(., \n            Count = dplyr::n(),\n            Time = mean(Time)\n            )\n\nWe now have a data frame that contains the mean Time and the Count for events. We can add a geom_point() layer that plots the mean Time as a point that varies in size corresponding to the Count.\n\nCOUNTS_BY_DIST %&gt;% knitr::kable()\n\n\n\n\nDistance\nCount\nTime\n\n\n\n\n50\n14\n23.59429\n\n\n100\n67\n55.19567\n\n\n200\n79\n121.51304\n\n\n400\n3\n268.98667\n\n\n500\n6\n305.51333\n\n\n\n\n\nUsing some new aesthetics for geom_point(), we illustrate the addition of the plot here.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 10),\n             alpha = .4) +\n  geom_point(data = COUNTS_BY_DIST, \n             mapping = aes(size = Count),\n             shape   = 21, # open circle\n             col     = \"black\",\n             fill    = \"tomato\",\n             #stroke = 1, # makes outer ring of 21 thicker\n             alpha   = .65) +\n  theme_minimal()\n\n\n\n\nRemember that plot layer matters. Different orders of layers will render different plots.\nLet’s change the geom layer order and change alpha for each geom:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(data = COUNTS_BY_DIST, \n             mapping = aes(size = Count),\n             shape   = 21, # open circle\n             col     = \"black\",\n             fill    = \"tomato\",\n             #stroke = 1, # makes outer ring of 21 thicker\n             alpha   = 1) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 10),\n             alpha = .3) +\n  theme_minimal()"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#adjusting-point-size",
    "href": "modules/11_spatial_position_and_adjustment.html#adjusting-point-size",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Size",
    "text": "Adjusting Point Size\nAnother option to overcome overplotting is to create what is known as a counts chart. Wherever there is more point overlap, the size of the circle gets bigger. Some people use a geom_count() for this approach. The default statistical transformation for geom_count() is stat = \"sum\", which sums up the count of the points in order to plot points of sizes relative to their counts. Although presenting larger points does not really fall perfectly under the topic of position adjustment, larger points do in fact take up more space on the plot, so in a way they are an adjustment of a point’s spatial position. When using geom_count(), however, you have to tinker a little when you also want to jitter points because by default position = \"jitter\" will also cause your sized points jitter, which is confusing. If size of points can be used, you may find adding a second geom_point() that uses summarized data to be a more intuitive solution."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#creating-a-stacked-bar-plot",
    "href": "modules/11_spatial_position_and_adjustment.html#creating-a-stacked-bar-plot",
    "title": "Spatial position and adjustment",
    "section": "Creating a stacked bar plot",
    "text": "Creating a stacked bar plot\nLet’s add the School variable to the plot using aes(fill = School) to the geom_*() layer:\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event)\n         ) +\n  geom_bar(aes(fill = School))\n\n\n\n\nWe can also have the aesthetic inherited from ggplot() if aes(fill = School) is defined as part of ggplot():\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar()\n\n\n\n\nThe bars take on different representations as you can see. You can also plot the counts with a different aesthetic combination.\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = School, \n                       fill = Event\n                       )\n         ) +\n  geom_bar()\n\n\n\n\nNotice that with stacked bars, you encode the count as the length of the colored rectangle. For the user to compare counts for comparisons, they can use the height position for the first stack only because the bars are on an aligned scale. The other bars in the stack do not have the same starting an ending points. These bars on on an unaligned scale, which makes the decoding task more difficult for the user. In addition to this alignment issue, the bars may also encourage decoding of area, which is also a challenging cognitive task that leads to perceptual errors. For discussion of more of these perceptual issues, see Cleveland & McGill (1984). Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods.\nWhen you want to facilitate comparisons of bars, you might want to change their positions by creating a grouped bar plot."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#stacking-with-position-fill",
    "href": "modules/11_spatial_position_and_adjustment.html#stacking-with-position-fill",
    "title": "Spatial position and adjustment",
    "section": "Stacking with position = \"fill\"",
    "text": "Stacking with position = \"fill\"\nA problem with stacking is that the counts are raw and are not conditionalized on all the\nUsing position = \"fill\" will stretch the bars so that the counts are relative to the distribution.\n\nplot1 &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = School, \n                       fill = Event)\n         ) +\n  geom_bar() \n\nplot2 &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = School, \n                       fill = Event\n                       )\n         ) +\n  geom_bar(position = \"fill\", ) \n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 1))"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#creating-a-grouped-bar-plot",
    "href": "modules/11_spatial_position_and_adjustment.html#creating-a-grouped-bar-plot",
    "title": "Spatial position and adjustment",
    "section": "Creating a grouped bar plot",
    "text": "Creating a grouped bar plot\nStacking is not always the desired outcome. We often want to see the bars for the subgroups. We will need to override the default position. Dodging is a general way to correct for overlapping objects, whether points, bars, box plots, etc. You can practice using it with geom_point() but we will use it here for bars. Specifically, we will override the default position argument, position = \"stacked\" and make is position = \"dodge\" so that the bar positions dodge each other.\nDodging a geom_*() like bars, points, or rectangles, will preserve their vertical position while also adjusting their horizontal position.\nBesides the examples illustrated below, you can find more examples in the tidyverse documentation.\ngeom_bar(position = \"dodge\")\n\nposition = \"dodge\"\nposition = \"dodge2\": adds padding to bars\nposition = position_dodge(): with padding control etc.\nposition = position_dodge2(): with padding control etc.\n\nDefault behavior of position_dodge():\n\nd1_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = position_dodge(), show.legend = F)\n\nYou will need a grouping variable specified in the global or local geom_*() for position_dodge() whereas this is not a requirement for position_dodge2(). Moreover, position_dodge2() differs from position_dodge() insofar as it does not need a grouping variable in a layer and works with bars and rectangles. It it likely your go-to function for positioning box plots because you can adjust their widths.\nDefault behavior of position_dodge2():\n\nd2_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = position_dodge2(), show.legend = F)\n\nAdding a padding to position_dodge2():\n\nd3_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = \n             position_dodge2(padding = .5), \n           show.legend = F)"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#plotting-a-grid-grob-graphic-object",
    "href": "modules/11_spatial_position_and_adjustment.html#plotting-a-grid-grob-graphic-object",
    "title": "Spatial position and adjustment",
    "section": "Plotting a Grid Grob (Graphic Object)",
    "text": "Plotting a Grid Grob (Graphic Object)\nWe can take the three objects and arrange them in a grid using gridExtra::arrangeGrob(). We can specify the number of colons and or rows as well. In this case, we can plot them all as a single column and they will appear in the order the plots are added in arrangeGrob().\n\nplot(gridExtra::arrangeGrob(d1_plot, \n                            d2_plot,\n                            d3_plot,\n                            ncol = 1)\n     )"
  },
  {
    "objectID": "modules/12_considerations_in_data_visualization.html",
    "href": "modules/12_considerations_in_data_visualization.html",
    "title": "Considerations in data visualization",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/12_considerations_in_data_visualization.html#readings",
    "href": "modules/12_considerations_in_data_visualization.html#readings",
    "title": "Considerations in data visualization",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. The principle of proportional ink\nWilke (2019). Fundamentals of Data Visualization. Common pitfalls of color use\nWilke (2019). Fundamentals of Data Visualization. Telling a story"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html",
    "href": "modules/13_color_scales_and_palettes.html",
    "title": "Color scales and palettes",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#readings",
    "href": "modules/13_color_scales_and_palettes.html#readings",
    "title": "Color scales and palettes",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Color basics\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Color scales"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#external-functions",
    "href": "modules/13_color_scales_and_palettes.html#external-functions",
    "title": "Color scales and palettes",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#libraries",
    "href": "modules/13_color_scales_and_palettes.html#libraries",
    "title": "Color scales and palettes",
    "section": "Libraries",
    "text": "Libraries\n\n{colorblindr} 0.1.0: for simulations of color vision deficiencies to ggplot2 objects; post-hoc color editing\n{colorspace} 2.1.0: for manipulating and assessing colors and color palettes\n{cowplot} 1.1.1: for ggplot add-ons; object management\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{ggplot2} 3.4.3: for plotting\n{ggthemes} 4.2.4: for palettes and themes\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{patchwork} 1.1.3: for plotting on grids\n{RColorBrewer} 1.1.3: for color palettes"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#load-libraries",
    "href": "modules/13_color_scales_and_palettes.html#load-libraries",
    "title": "Color scales and palettes",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(colorspace)\nlibrary(cowplot)\nlibrary(ggthemes)  # for scale_color_colorblind()\nlibrary(colorblindr)\nlibrary(khroma)"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#to-distinguish-categories-qualitative",
    "href": "modules/13_color_scales_and_palettes.html#to-distinguish-categories-qualitative",
    "title": "Color scales and palettes",
    "section": "To distinguish categories (qualitative)",
    "text": "To distinguish categories (qualitative)\n\nSWIM %&gt;%\n  ggplot(., aes(x = School, fill = Event)) +\n  geom_bar()"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#to-represent-numeric-values-sequential",
    "href": "modules/13_color_scales_and_palettes.html#to-represent-numeric-values-sequential",
    "title": "Color scales and palettes",
    "section": "To represent numeric values (sequential)",
    "text": "To represent numeric values (sequential)\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic()\n\n\n\n\nWhen no fill scale is defined, default is scale_fill_gradient(), which we can change to something else.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_fill_viridis_c()\n\n\n\n\nBut the function won’t change anything if we don’t use the proper scale_*_() function.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_viridis_c()\n\n\n\n\nOr:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_viridis_c(option = \"B\", begin = 0.15)"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#to-represent-numeric-values-diverging",
    "href": "modules/13_color_scales_and_palettes.html#to-represent-numeric-values-diverging",
    "title": "Color scales and palettes",
    "section": "To represent numeric values (diverging):",
    "text": "To represent numeric values (diverging):\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_gradient2()\n\n\n\n\nOr:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_diverging() \n\n\n\n\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_distiller(type = \"div\")\n\n\n\n\nThere are other applications too but we cannot get into them all here."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#color-scales-built-into-ggplot2",
    "href": "modules/13_color_scales_and_palettes.html#color-scales-built-into-ggplot2",
    "title": "Color scales and palettes",
    "section": "Color Scales Built into {ggplot2}",
    "text": "Color Scales Built into {ggplot2}\nThere are colors built into {ggplot2}. The scale_*() functions will also following the naming conventions scale_color_*() or scale_fill_*(). When you have bars, remember that you are changing fill color and with solid circle points you are changing col so your go-to functions should adhere to those naming conventions (e.g., scale_fill_*() and scale_color_*()). Some examples include: scale_color_brewer() or scale_color_distiller() for discrete or continuous scales, respectively.\n{ggplot} functions:\n\nscale_color_hue(): color, data: discrete, palette: qualitative\nscale_fill_hue(): fill, data: discrete, palette: qualitative\nscale_color_gradient(): color, data: continuous, palette: sequential\nscale_color_gradient2(): color, data: continuous, palette: diverging\nscale_fill_viridis_c(): color, data: continuous, palette: sequential\nscale_fill_viridis_d(): fill, data: discrete, palette: sequential\nscale_color_brewer(): color, data: discrete , palette: qualitative, diverging, sequential\nscale_fill_brewer(): fill, data: discrete, palette: qualitative, diverging, sequential\nscale_color_distiller(): color, data: continuous, palette: qualitative, diverging, sequential"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#colorspace-color-palettes",
    "href": "modules/13_color_scales_and_palettes.html#colorspace-color-palettes",
    "title": "Color scales and palettes",
    "section": "{colorspace} Color Palettes",
    "text": "{colorspace} Color Palettes\n\ncolorspace::hcl_palettes(type = \"sequential\", plot = TRUE) # all sequential palettes\n\n\n\n\n\ncolorspace::hcl_palettes(type = \"diverging\", plot = TRUE, n = 9) # all diverging palettes\n\n\n\n\n\ncolorspace::divergingx_palettes(plot = TRUE, n = 9) # all divergingx palettes"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#example-plots",
    "href": "modules/13_color_scales_and_palettes.html#example-plots",
    "title": "Color scales and palettes",
    "section": "Example plots",
    "text": "Example plots\nWe can then specify the function according to our goal using: scale_&lt;aesthetic&gt;_&lt;datatype&gt;_&lt;colorscale&gt;(). We can see an example with filling points.\nContinuous:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous()\n\n\n\n\nContinuous and Sequential:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n#  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_sequential()\n\n\n\n\nDiscrete and Sequential:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = School)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_discrete_sequential()\n\n\n\n\nA specific palette added: palette = \"Inferno\"\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n#  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_sequential(palette = \"Inferno\")\n\n\n\n\nContinuous and Diverging:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_diverging()"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#exploring-colorspace",
    "href": "modules/13_color_scales_and_palettes.html#exploring-colorspace",
    "title": "Color scales and palettes",
    "section": "Exploring {colorspace}",
    "text": "Exploring {colorspace}\nFor a dynamic exploration use colorspace::hcl_wizard(), which is a {shiny} app . When you are done exploring, click the “Return to R” box.\n\nColor Picker\n{colorspace} also has a color picker function, colorspace::hclcolorpicker() which will allow you to pick color and obtain the hexidecimal color codes. You can also obtain html color names and rgb codes for colors at websites like htmlcolorcodes.com. With recent updates to RStudio, color names written as character strings when typed in the console or in files will display the color. Hint: you must type the names in lowercase (e.g., “mediumseagreen. If the color is not known by its name, then you won’t see the background string color change."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#discrete-qualitative-scales",
    "href": "modules/13_color_scales_and_palettes.html#discrete-qualitative-scales",
    "title": "Color scales and palettes",
    "section": "Discrete, qualitative scales",
    "text": "Discrete, qualitative scales\nDiscrete, qualitative scales are sometimes best set manually.\nAn example using default color palette:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Distance, y = Time, color = School)) +\n  geom_point(position = position_jitter()) +\n  scale_color_hue()\n\n\n\n\nNow consider the following plot.\n\nSWIM %&gt;%\n  ggplot(., aes(x = School, y = Time, fill = Event)) + \n  geom_col() \n\n\n\n\nTo set the color, add a layer:\nFor the hue, scale_&lt;datatype&gt;_hue() could be scale_colour_hue() or scale_fill_hue(). The two function are listed below.\nscale_colour_hue(\n  ...,\n  h = c(0, 360) + 15,\n  c = 100,\n  l = 65,\n  h.start = 0,\n  direction = 1,\n  na.value = \"grey50\",\n  aesthetics = \"colour\"\n)\n\nscale_fill_hue(\n  ...,\n  h = c(0, 360) + 15,\n  c = 100,\n  l = 65,\n  h.start = 0,\n  direction = 1,\n  na.value = \"grey50\",\n  aesthetics = \"fill\"\n)\nWhen you are trying to customize a plot for a client or find issue with the color palettes out-of-the-box, scale_color_manual() or scale_fill_manual() are likely your best friends. As you see in the functions, you need to pass some color values. This is a vector of color by name or hexidecimal code.\nscale_colour_manual(\n  ...,\n  values,\n  aesthetics = \"colour\",\n  breaks = waiver(),\n  na.value = \"grey50\"\n)\n\nscale_fill_manual(\n  ...,\n  values,\n  aesthetics = \"fill\",\n  breaks = waiver(),\n  na.value = \"grey50\"\n)\nBut you need to know how values are mapped to subgroups. How many subgroups are there and what are they?\n\nglimpse(SWIM) \n\nRows: 201\nColumns: 10\n$ Year     &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ School   &lt;chr&gt; \"Pomona-Pitzer-CA\", \"Claremont-Mudd-Scripps-CA\", \"Claremont-M…\n$ Team     &lt;chr&gt; \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\"…\n$ Relay    &lt;chr&gt; \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\"…\n$ Distance &lt;dbl&gt; 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 2…\n$ Name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"…\n$ Age      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2…\n$ Event    &lt;chr&gt; \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"…\n$ Time     &lt;dbl&gt; 97.74, 101.34, 101.64, 102.21, 102.83, 102.93, 103.55, 103.63…\n$ Split50  &lt;dbl&gt; 26.35, 24.40, 24.06, 24.99, 24.37, 27.46, 28.54, 26.75, 25.77…\n\nunique(SWIM$Event)\n\n[1] \"Medley\"       \"Freestyle\"    \"IM\"           \"Butterfly\"    \"Breaststroke\"\n[6] \"Backstroke\"  \n\n\nMake note of the order.\nThe order of the colors in the vector passes to values will map to the order of the levels in the data frame. We can demonstrate this by changing the data frame arrangement.\nSorting by ascending or descending order changes the data frame.\n\nSWIM %&gt;% select(., Event) %&gt;% unique()\n\n# A tibble: 6 × 1\n  Event       \n  &lt;chr&gt;       \n1 Medley      \n2 Freestyle   \n3 IM          \n4 Butterfly   \n5 Breaststroke\n6 Backstroke  \n\nSWIM %&gt;% arrange(., desc(Event)) %&gt;% select(., Event) %&gt;% unique()\n\n# A tibble: 6 × 1\n  Event       \n  &lt;chr&gt;       \n1 Medley      \n2 IM          \n3 Freestyle   \n4 Butterfly   \n5 Breaststroke\n6 Backstroke  \n\n\nSo how you sort the data frame matters, right? No. \nIs this vector a factor? Note, you can also see this using glimpse().\n\nis.factor(SWIM$Event)\n\n[1] FALSE\n\n\n\nglimpse(SWIM)\n\nRows: 201\nColumns: 10\n$ Year     &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ School   &lt;chr&gt; \"Pomona-Pitzer-CA\", \"Claremont-Mudd-Scripps-CA\", \"Claremont-M…\n$ Team     &lt;chr&gt; \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\"…\n$ Relay    &lt;chr&gt; \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\"…\n$ Distance &lt;dbl&gt; 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 2…\n$ Name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"…\n$ Age      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2…\n$ Event    &lt;chr&gt; \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"…\n$ Time     &lt;dbl&gt; 97.74, 101.34, 101.64, 102.21, 102.83, 102.93, 103.55, 103.63…\n$ Split50  &lt;dbl&gt; 26.35, 24.40, 24.06, 24.99, 24.37, 27.46, 28.54, 26.75, 25.77…\n\n\nWhat are the levels?\n\nlevels(SWIM$Event)\n\nNULL\n\n\nThe levels() function will only return levels if the vector is a factor.\nLet’s change the variable in the data frame:\n\nSWIM &lt;- SWIM %&gt;% mutate(., Event = factor(Event))\n\n\nlevels(SWIM$Event)\n\n[1] \"Backstroke\"   \"Breaststroke\" \"Butterfly\"    \"Freestyle\"    \"IM\"          \n[6] \"Medley\"      \n\nnum_events &lt;- length(levels(SWIM$Event))\n\n\nis.ordered(SWIM$Event)\n\n[1] FALSE\n\n\nSo it is not an ordered factor but it does have an order and that order will affect the plot.\nThe colors in the vector passed to values will map onto the order of the levels as displayed by levels().\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#reverse-the-using-rev",
    "href": "modules/13_color_scales_and_palettes.html#reverse-the-using-rev",
    "title": "Color scales and palettes",
    "section": "Reverse the using rev()",
    "text": "Reverse the using rev()\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = rev(Event))) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nSomething is wrong. Double check your data and labels."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#mutate-to-change-the-order-of-levels",
    "href": "modules/13_color_scales_and_palettes.html#mutate-to-change-the-order-of-levels",
    "title": "Color scales and palettes",
    "section": "mutate() to change the order of levels",
    "text": "mutate() to change the order of levels\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                      ))\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOK, so we see that the color changes because the order of the levels changed. They are reordered in the plot legend."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#mutate-to-make-it-an-ordered-factor",
    "href": "modules/13_color_scales_and_palettes.html#mutate-to-make-it-an-ordered-factor",
    "title": "Color scales and palettes",
    "section": "mutate() to make it an ordered factor",
    "text": "mutate() to make it an ordered factor\nThe order of the labels does not make a factor ordered. We need to do something special to accomplish that, which we will do here. However, the example is arbitrary here as there is not order or ranking to how I arrange them.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                       ),\n                           ordered = T)\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#change-the-labels-for-the-levels",
    "href": "modules/13_color_scales_and_palettes.html#change-the-labels-for-the-levels",
    "title": "Color scales and palettes",
    "section": "Change the labels for the levels",
    "text": "Change the labels for the levels\nPass a vector of equal length with label names.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                       ),\n                           labels = c(\"Free\", \"Breast\", \"Fly\",\n                                      \"Back\", \"IM\", \"Medley\"))\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nColors didn’t change but labels did."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#pair-a-color-with-a-level",
    "href": "modules/13_color_scales_and_palettes.html#pair-a-color-with-a-level",
    "title": "Color scales and palettes",
    "section": "Pair a Color with a Level",
    "text": "Pair a Color with a Level\nI’m not going to get into why this approach is actually a vector but you can test it if you want.\n\nis.vector(c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n            Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n            IM = \"maroon\", Medley = \"gray\"))\n\n[1] TRUE\n\n\nPass a vector of names and color values.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n               Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n               IM = \"maroon\", Medley = \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#pass-a-vector-of-colors",
    "href": "modules/13_color_scales_and_palettes.html#pass-a-vector-of-colors",
    "title": "Color scales and palettes",
    "section": "Pass a vector of colors",
    "text": "Pass a vector of colors\nChanging the colors inside the function can be annoying so you might just create a vector object to pass to values.\n\ncolor_vector &lt;- c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n                  Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n                  IM = \"maroon\", Medley = \"gray\")\n  \nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nVectors containing additional name elements\nIf that vector contains names that are not in the variable vector, then the function will not break. Rather, colors will show for level in the data only. We are going to save this plot object to use later.\n\ncolor_vector &lt;- c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n                  Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n                  IM = \"maroon\", Medley = \"gray\",\n                  SomethingNew = \"blue\"\n                  )\n\n(SWIM_plot &lt;- SWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n)\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nVectors missing name elements\nBut when names in the data vector are not in the color vector, something interesting happens.\n\n(color_vector &lt;- color_vector[1:3])\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\n\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFirst, and most obviously, the missing pair is dropped from the legend. So the data points are stripped from the plot too, right? Look closer. No! They are in a there but plotting as \"grey50\". This happens because the default setting na.value = \"grey50\".\nThere is also no warning, so double check your plots!\nMore dramatically, show only the first color element.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[1])\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\ncolor_vector\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\nwhich(names(color_vector) == \"Freestyle\")\n\n[1] 1\n\n\nThis approach can be useful if you want to color only certain events by their name. The goal would be to determine which color corresponds to the Freestyle and plot only that. But remember, there are names in the vector and color values.\n\ncolor_vector\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\nnames(color_vector)\n\n[1] \"Freestyle\"    \"Breaststroke\" \"Butterfly\"   \n\n\nWe need to find out the color position corresponding to the name position Using which() we can evaluate the names to determine which position is the Freestyle.\n\nwhich(names(color_vector) == \"Freestyle\")\n\n[1] 1\n\n\nWhat we get returned is position 1. Of course, you knew that but something might change and if it moves position based on a reordering, then hard coding won’t work.\nTo obtain the color associated with element position 1, use [] notation after the vector.\n\ncolor_vector[1] # hard coded solution\n\nFreestyle \n\"#E69F00\" \n\ncolor_vector[which(names(color_vector) == \"Freestyle\")] # flexible solution\n\nFreestyle \n\"#E69F00\" \n\n\nPutting it all together, pass that to values:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[which(\n    names(color_vector) == \"Freestyle\")]\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAnd if you wanted more than one event, evaluate with %in% rather than ==. For example, names(color_vector) %in% c(\"Freestyle\", \"Butterfly\").\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[which(\n    names(color_vector) %in% c(\"Freestyle\", \"Butterfly\"))]\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html",
    "href": "modules/14_histograms_and_density_plots.html",
    "title": "Histograms and density plots",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#readings",
    "href": "modules/14_histograms_and_density_plots.html#readings",
    "title": "Histograms and density plots",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing distributions: Histograms and density plots"
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#external-functions",
    "href": "modules/14_histograms_and_density_plots.html#external-functions",
    "title": "Histograms and density plots",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#libraries",
    "href": "modules/14_histograms_and_density_plots.html#libraries",
    "title": "Histograms and density plots",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#load-libraries",
    "href": "modules/14_histograms_and_density_plots.html#load-libraries",
    "title": "Histograms and density plots",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#geom_histogram",
    "href": "modules/14_histograms_and_density_plots.html#geom_histogram",
    "title": "Histograms and density plots",
    "section": "geom_histogram()",
    "text": "geom_histogram()\nThe histogram will plot the counts of common instances within a vector. Plotting a geom_histogram() will require mapping a variable to either x or y in aes(). The only difference will be the distribution orientation, which could have course be changed also with coord_flip().\nIf x = Time:\n\nSWIM %&gt;%\n  ggplot(., aes(x = Time)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nIf y = Time:\n\nSWIM %&gt;%\n  ggplot(., aes(y = Time)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nIf you have both x and y mapped, you will get an error.\nSWIM %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_histogram()\nError in `geom_histogram()`:\n! Problem while computing stat.\nℹ Error occurred in the 1st layer.\nCaused by error in `setup_params()`:\n! `stat_bin()` must only have an x or y aesthetic."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#histograms-depend-on-the-chosen-bin-width",
    "href": "modules/14_histograms_and_density_plots.html#histograms-depend-on-the-chosen-bin-width",
    "title": "Histograms and density plots",
    "section": "Histograms depend on the chosen bin width",
    "text": "Histograms depend on the chosen bin width"
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#setting-bins-number",
    "href": "modules/14_histograms_and_density_plots.html#setting-bins-number",
    "title": "Histograms and density plots",
    "section": "Setting bins Number",
    "text": "Setting bins Number\nThe bins parameter in geom_histogram() controls number of bins, defaults to 30, and is overridden by the binwidth argument. Depending on your data, this may or may not provide the best representation of data. You can also specify the number of bins. This will force geom_histogram() to adjust the bin width based on the number of bind you specify. Let’s create two examples.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(bins = 20) +\n  labs(title = \"bins = 20\", tag = \"A\")\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(bins = 60) +\n  labs(title = \"bins = 60\", tag = \"B\")\n\nBecause the total number of bins will capture all frequency counts in the data, setting fewer bins will result in plots that have more counts per bin than will plots with many bins. Examine the counts along the y-axis to see this.\n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 2))\n\n\n\n\nNot only is the narrowness of the bars associated with more bins but the this is the result of fewer counts, which ultimately affects your range along the y axis. This means that when you plot two bars side-by-side (to facilitate comparison of bars by their heights), the height will be confounded by the scale; you are not comparing bars on aligned scales (See Cleveland & McGill (1984)). This results in perceptual problems."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#setting-binwidth",
    "href": "modules/14_histograms_and_density_plots.html#setting-binwidth",
    "title": "Histograms and density plots",
    "section": "Setting binwidth",
    "text": "Setting binwidth\nWhen you plot a geom_histogram(), R reminds you to consider the binwidth by providing the error: stat_bin() using bins = 30. Pick better value with binwidth. The binwidth argument controls the bin width along the X-axis and this argument overrides the bin argument.\nYou could make your bin width narrow relative to the data being plotted. For example, 1/10 of a second (e.g., binwidth = .1) for swim events. Similarly, if your vector contains discrete values, binwidth = 1 would plot the frequency count for all instances.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(aes(Time)) +\n  geom_histogram(binwidth = .1) +\n  labs(title = \"binwidth = .1\", tag = \"A\")\n\nBut this produces a very granular plot that is not very useful. The counts are so few and the distribution is not very apparent visually. By contrast, if you set it too wide (e.g., binwidth = 30), then you might loose a lot of detail. Notice also that the x axis does not provide tick marks that help with the binning, whether narrow or wide.\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(aes(Time)) +\n  geom_histogram(binwidth = 30) +\n  labs(title = \"binwidth = 30\", tag = \"B\")\n\n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 2))\n\n\n\n\nIs this better?\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(binwidth = 5) +\n  labs(title = \"binwidth = 5\", tag = \"C\")\n\n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 1))"
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#center-the-bin",
    "href": "modules/14_histograms_and_density_plots.html#center-the-bin",
    "title": "Histograms and density plots",
    "section": "Center the bin",
    "text": "Center the bin\nOnce you are happy with the width, you can think about centering them. center will be used to specify the center of the bin containing the bin value. For now, there is some adjustment, though not perfect, to the scale to see the differences.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 200) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(binwidth = 10) +\n  ggtitle(\"binwidth = 10\") +\n  # add some detailing to better see\n  scale_x_continuous(breaks = seq(0, 350, 10)) +\n  labs(title = \"default center\", tag = \"A\")\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 200) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(binwidth = 10,\n                 center = 1) +\n  # add some detailing to better see\n  scale_x_continuous(breaks = seq(0, 350, 10)) +\n  labs(title = \"center = 1\", tag = \"B\")\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 200) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(binwidth = 10,\n                 center = 0) +\n  # add some detailing to better see\n  scale_x_continuous(breaks = seq(0, 350, 10)) +\n  labs(title = \"center = 0\", tag = \"C\")\n\nplot4 &lt;- SWIM %&gt;%\n  filter(Time &lt; 200) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(binwidth = 10,\n                 center = 5) +\n  # add some detailing to better see\n  scale_x_continuous(breaks = seq(0, 350, 10)) +\n  labs(title = \"center = 5\", tag = \"D\")\n\nplot(gridExtra::arrangeGrob(plot1, plot2, plot3, plot4, ncol = 2))\n\n\n\n\nFor more details on center, see ?geom_histogram."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#color-and-other-aesthetics",
    "href": "modules/14_histograms_and_density_plots.html#color-and-other-aesthetics",
    "title": "Histograms and density plots",
    "section": "Color and other Aesthetics",
    "text": "Color and other Aesthetics\nAnd can also change the color of the bars in the histogram or make them transparent (e.g., fill = \"transparent\").\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(\n    fill = \"tomato2\",\n    color = \"black\",\n    linetype = \"dashed\"\n  ) +\n  labs(title = 'fill = \"tomato2\"\\nlinetype = \"dashed\"',\n      tag = \"A\"\n      )\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(\n    fill = \"transparent\",\n    color = \"tomato2\",\n    linetype = \"solid\"\n  ) +\n  labs(title = 'color = \"tomato2\"\\nlinetype = \"solid\"',\n       tag = \"B\"\n  )\n\nTwo arrangements of the plots illustrate their differences.\n\npatchwork::plot_layout(plot1 + plot2)\n\n$ncol\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n$nrow\nNULL\n\n$byrow\nNULL\n\n$widths\nNULL\n\n$heights\nNULL\n\n$guides\nNULL\n\n$tag_level\nNULL\n\n$design\nNULL\n\nattr(,\"class\")\n[1] \"plot_layout\"\n\npatchwork::plot_layout(plot1 / plot2)\n\n$ncol\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n$nrow\nNULL\n\n$byrow\nNULL\n\n$widths\nNULL\n\n$heights\nNULL\n\n$guides\nNULL\n\n$tag_level\nNULL\n\n$design\nNULL\n\nattr(,\"class\")\n[1] \"plot_layout\""
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#stacked-histograms",
    "href": "modules/14_histograms_and_density_plots.html#stacked-histograms",
    "title": "Histograms and density plots",
    "section": "Stacked histograms",
    "text": "Stacked histograms\nYou can stack bars in histograms just as you did with geom_bar(). Mapping a variable to fill will introduce the distribution for levels of the fill variable. However, if you think stacking a histogram will be useful, it really isn’t.\n\nSWIM %&gt;%\n  ggplot(., aes(x = Time, fill = Team)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nEven if the bars are not opaque, they are not much better. In general, histograms with overlapped bars a rarely useful.\n\nSWIM %&gt;%\n  ggplot(., aes(x = Time, fill = Team)) +\n  geom_histogram(alpha = .5)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThere are certainly things that you can do to the plot but there are better options."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#histograms-with-y-as-density",
    "href": "modules/14_histograms_and_density_plots.html#histograms-with-y-as-density",
    "title": "Histograms and density plots",
    "section": "Histograms with y as Density",
    "text": "Histograms with y as Density\nThe default operation of geom_histogram() is to plot the frequency counts along the y axis corresponding to the x variable mapped in aes(). The statistical transformation adjusted using after_stat(). You will see that the default mapping to the y variable is after_stat(count). We can add this explicitly either in geom_histogram() to across ggplot() and geom_histogram()\nFor example:\n  ggplot(.) + \n  geom_histogram(mapping = aes(x = Time,\n                               y = after_stat(count)\n                               )\n  )\n  \n  ggplot(., mapping = aes(x = Time)) + \n  geom_histogram(mapping = aes(y = after_stat(count)))\n\nafter_stat(count)\n\n(plot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(.) +\n  geom_histogram(aes(x = Time,\n                     y = after_stat(count)\n                     )\n                 ) +\n  labs(title = 'aes(y = after_stat(count))',\n       tag = \"A\")\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe plot looks the same as we have seen before because this is the default operation. We can, however, change the statistical transformation using after_stat() to create a density plot.\n\n\nafter_stat(density)\n\n(plot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(.) +\n  geom_histogram(aes(x = Time,\n                     y = after_stat(density)\n                     )\n                 ) +\n  labs(title = 'aes(y = after_stat(density))', \n       tag = \"B\"\n       )\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nUsing {patchwork} to create a grob, we can add divide the grid space using / so that the plots are on top of each other.\n\npatchwork::plot_layout(plot1 / plot2)\n\n$ncol\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n$nrow\nNULL\n\n$byrow\nNULL\n\n$widths\nNULL\n\n$heights\nNULL\n\n$guides\nNULL\n\n$tag_level\nNULL\n\n$design\nNULL\n\nattr(,\"class\")\n[1] \"plot_layout\"\n\n\nNotice, however, that the visualization of the binned bars along with the density function does not provide provide what you might expect to see. That’s because a density function is continuous whereas histograms are not.\nIf you add a density layer, you can see them both together:\n\nplot2 + geom_density(aes(x = Time))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nMore on geom_density() later."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#histograms-using-stat_bin",
    "href": "modules/14_histograms_and_density_plots.html#histograms-using-stat_bin",
    "title": "Histograms and density plots",
    "section": "Histograms using stat_bin",
    "text": "Histograms using stat_bin\nAlthough you are familiar with the usage of geom_()s that include statistical transformations (remember all plots have a stat_()), statistical transformation functions with naming convention stat_*() allow for geoms. For stat_bin, which create bins, the default geom = \"bar\" and position = \"stack\", which you saw with the stacking of the colored bars using geom_histogram().\nstat_bin(\n  mapping = NULL,\n  data = NULL,\n  geom = \"bar\",\n  position = \"stack\",\n  ...,\n  binwidth = NULL,\n  bins = NULL,\n  center = NULL,\n  boundary = NULL,\n  breaks = NULL,\n  closed = c(\"right\", \"left\"),\n  pad = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\ngeom = \"bar\"\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  stat_bin(\n    geom = \"bar\"\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#densities-or-area-plots-using-stat_bin",
    "href": "modules/14_histograms_and_density_plots.html#densities-or-area-plots-using-stat_bin",
    "title": "Histograms and density plots",
    "section": "Densities or Area Plots using stat_bin",
    "text": "Densities or Area Plots using stat_bin\ngeom = \"density\"\ngeom = \"area\"\nstat = \"density\"\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  stat_bin(\n    geom = \"density\",\n    fill = \"gold\",\n    col = \"black\"\n  ) +\n  labs(title = 'geom = \"density\"',\n       tag = \"A\"\n       )\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  stat_bin(\n    geom = \"area\",\n    fill = \"gold\",\n    col = \"black\"\n  ) +\n  labs(title = 'geom = \"area\"',\n       tag = \"B\"\n  )\n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAs you can see, the geom settings produce the same plots."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#geom_density",
    "href": "modules/14_histograms_and_density_plots.html#geom_density",
    "title": "Histograms and density plots",
    "section": "geom_density()",
    "text": "geom_density()\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\nWe can also change aesthetics using:\n- color: line color\n- size: line thickness\n- linetype: line type \n- fill: fill color of the area \n- alpha: opacity/transparency\nLet’s crest some plots.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_density() +   \n  labs(title = \"no fill\", tag = \"A\")\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_density(fill = \"gold\") +\n  labs(title = 'fill = \"gold\"', tag = \"B\")\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_density(\n    fill = \"gold\",\n    bw = 0.5,               # a very small bandwidth\n    kernel = \"gaussian\"     # Gaussian kernel (the default)\n  ) +\n  labs(title = 'fill = \"gold\"\\nkernel = \"gaussian\"', tag = \"C\")\n\nplot4 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_density(\n    fill = \"gold\",\n    bw = 50,                   # a larger bandwidth\n    kernel = \"rectangular\"     # Gaussian kernel (the default)\n  ) +\n  labs(title = 'fill = \"gold\"\\nkernel = \"rectangular\"', tag = \"D\")\n\n\nplot(gridExtra::arrangeGrob(plot1, plot2, plot3, plot4, ncol = 2))\n\n\n\n\nThe plots present the data in different ways. Choosing the best type of plot will involve some consideration. You should not feel compelled to use plots out-of-the-box."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html",
    "href": "modules/15_coordinates_axes_and_position_scales.html",
    "title": "Coordinates, axes, and position scales",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#readings",
    "href": "modules/15_coordinates_axes_and_position_scales.html#readings",
    "title": "Coordinates, axes, and position scales",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Coordinate Systems / Axes\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Position scales and axes"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#external-functions",
    "href": "modules/15_coordinates_axes_and_position_scales.html#external-functions",
    "title": "Coordinates, axes, and position scales",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#libraries",
    "href": "modules/15_coordinates_axes_and_position_scales.html#libraries",
    "title": "Coordinates, axes, and position scales",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#load-libraries",
    "href": "modules/15_coordinates_axes_and_position_scales.html#load-libraries",
    "title": "Coordinates, axes, and position scales",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#the-cartesian-coordinate-system",
    "href": "modules/15_coordinates_axes_and_position_scales.html#the-cartesian-coordinate-system",
    "title": "Coordinates, axes, and position scales",
    "section": "The Cartesian Coordinate System",
    "text": "The Cartesian Coordinate System\nThe coordinate system described above is that Cartesian coordinate system, within which locations are specified by positions on the x and y axis corresponding to specific values determined by x and y as single values or specified by sets of values belonging to x and y. Because axes themselves are lines and represent continuous position scales, they stretch in real numbers beyond 0 in both directions, resulting in four quadrants of the coordinate system. Thus, x and y axes can contain both positive and negative real numbers. The visualization, however, needs axis limits in order to define the space along x and y for the data to appear. As you are familiar, many plots limit x and y axes to a value of 0 on the low end and some other value on the upper end. Data that exist outside of the define plot axis limits will not be depicted in the plot.\nA plot depicting values from x and y variables from the same unit system should be visualized such that the interval between values along two axes is equivalent. For example, if x and y both represent quantities, the number of pixels separating 1 and 3 on the x axis should be equivalent on the y axis. In other words, the same number of data units along the x or y axis should correspond to the same distance on those axes. Violations of this representation occur and present perceptual distortions of the data. In some instances, for example, when the limits of the x and y axes are the same, the plot should take form as a square rather than rectangle with either the x or the y axis longer than the other.\nWhen the variables are on different scales, however, either x or y axis could be stretched or compressed for a different perspective depending on the goal so storytelling. As long as one is not trying to bias their audience in a way to mislead them, a favorable aspect ratio could be one with good aesthetics. A plot with balance is always appealing. Something too wide or too tall may just appear odd. In general, an aspect ratio should be chosen that communicates important aspects of differences in position are noticeable.\nWhen plots (e.g., geom_()s) use statistical transformations (e.g., jittering), you should consider carefully the influence of the data position relative to the actual data. Fine tuned these transformations to ensure the the visualize data are most true to the actual data to reduce bias."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#coordinate-functions-coord_",
    "href": "modules/15_coordinates_axes_and_position_scales.html#coordinate-functions-coord_",
    "title": "Coordinates, axes, and position scales",
    "section": "Coordinate Functions: coord_*()",
    "text": "Coordinate Functions: coord_*()\nThere are a variety of coord_() layer functions for . By default, plots already have a coord_cartesian() layer. Also, the x-axis is oriented horizontally and the y-axis is oriented vertically. By tradition, predictor variables assume the x-axis orientation, whereas outcome variables assume the y-axis.\n\ncoord_flip()\ncoord_flip() is used to flip the Cartesian coordinate system such that the x and y axis swap positions. Flipping may facilitate plot perception, for example, when bar length rather than height either makes more sense or supports comparisons. Outcome variables that are natively perceived in terms of length rather than height may also benefit from plotting the outcome variable along the x axis.\n\nSWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  group_by(Event) %&gt;%\n  summarize(Time = mean(Time)) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Event, y = Time)) +\n  geom_col() +\n  coord_flip()\n\n\n\n\n\n\ncoord_fixed()\nWhen ensuring the aspect ratio of the coordinate system is important, coord_fixed() will prove helpful.\nThe most important parameter of the function is ratio, which by default is set to ratio = 1. The ratio represents the aspect ratio, expressed as y / x. Thus, the number of units on the y-axis that are equivalent to one unit on the x-axis. Thus, ratio = 1 ensures that one unit on the x-axis equates to 1 unit on the y-axis.\nYou can easily modify this to a different value, for example, 1.5, 2 or 10 to make the y axis longer than the x axis by this ratio. If you wish to make the y axis shorted, use a value or fraction to be less than 1 (e.g., 1/5). In addition, xlim and ylim parameters can be set in this layer.\nTo illustrate, let’s set the two axis limits to begin and end at the same values using xlim() and ylim(). Both require a two element vector. In addition, the default ratio is ratio = 1.\n\nSWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  xlim(0, 60) +\n  ylim(0, 60) +\n  #coord_equal()\n  coord_fixed(ratio = 1)\n\nWarning: Removed 12 rows containing missing values (`geom_point()`).\n\n\n\n\n\nSetting ratio = 2:\n\nSWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  xlim(0, 60) +\n  ylim(0, 60) +\n  coord_fixed(ratio = 2)\n\nWarning: Removed 12 rows containing missing values (`geom_point()`).\n\n\n\n\n\nYou see that the plot is now lengthened 2:1 in favor of the y-axis.\nBut the function might not work exactly as you expect. For example, if you axis limits are not set to be the same, but rather x is twice that of y, then a ratio of 1 behaves perhaps a little different from what you might think.\n\nexpand_plot &lt;- SWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point()\n\nnoexpand_plot &lt;- SWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  # do not expand axis (no padding))\n  coord_cartesian(expand = FALSE)\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(expand_plot, noexpand_plot, ncol = 1))\n)\n\n\n\n\nBe careful:\n\nnoexpand_plot2 &lt;- SWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  # do not expand axis (no padding))\n  #coord_cartesian(expand = FALSE) +\n  #coord_cartesian(expand = FALSE,\n  #                xlim = c(0, 40),\n  #                ylim = c(0, 80)\n  #                ) +\n  coord_fixed(ratio = 1, \n              xlim = c(0, 40), \n              ylim = c(0, 80)\n              )\n  #scale_y_continuous(expand = c(0, 0))\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(expand_plot, \n                           noexpand_plot,\n                           noexpand_plot2,\n                           ncol = 1))\n)\n\n\n\n\n\n\ncoord_equal()\n\nSWIM %&gt;% \n  filter(Distance == 100) %&gt;%\n  ggplot(data = .,\n         mapping = aes(x = Split50, y = Time)) +\n  geom_point() +\n  xlim(0, 60) +\n  ylim(0, 60) +\n  coord_equal()\n\nWarning: Removed 12 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#nonlinear-scales",
    "href": "modules/15_coordinates_axes_and_position_scales.html#nonlinear-scales",
    "title": "Coordinates, axes, and position scales",
    "section": "Nonlinear scales",
    "text": "Nonlinear scales\nIn many cases, you will be trying to visualize data that are linear such that the numeric values of the variable map on to the same positions in space. The interval between numeric values is the same as the interval in physical space for the printed plot. In other cases, the interval between values may not be linear. For example, data that are converted to logarithms, square roots, cubes, etc. have one distance representing the actual numeric values (linear) and another distance corresponding to the values on the transformed scale (ordinal).\nWilke discusses several issues related to linear and nonlinear scales is his chapter covering axes. In particular, he discusses instances for presenting data as logarithms, how to plot the, and\nlog-transformed data, we can get confused about whether the data were transformed using the natural logarithm or the logarithm to base 10. And it’s not uncommon for labeling to be ambiguous, e.g. “log(x)”, which doesn’t specify a base at all. I recommend that you always verify the base when working with log-transformed data. When plotting log-transformed data, always specify the base in the labeling of the axis."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#examples-of-plots-with-axis-problems",
    "href": "modules/15_coordinates_axes_and_position_scales.html#examples-of-plots-with-axis-problems",
    "title": "Coordinates, axes, and position scales",
    "section": "Examples of Plots with Axis Problems",
    "text": "Examples of Plots with Axis Problems\nAs we have seen with some plots out-of-the-box, the tick marks along either the x or y axis are not suitable for favorable perceptual experiences. The user can be particularly strained with the height of the bar cannot be mapped to a value on the y-axis or a position along the x-axis cannot be mapped well to the bin. These problems are seen in these two simple examples.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(bins = 20) +\n  labs(title = \"bins = 20\",  \n       tag = \"A\",\n       )\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(bins = 60) +\n  labs(title = \"bins = 60\",  \n       tag = \"B\",\n       )\n\n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 1))\n\n\n\n\nThe previous modules are replete with plots containing this problem that compromises your ability to interpret the plot. At the time we introduced those plots, ways to address this problem were not introduced. This module addresses scale and axis adjustments."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#position-scale-types",
    "href": "modules/15_coordinates_axes_and_position_scales.html#position-scale-types",
    "title": "Coordinates, axes, and position scales",
    "section": "Position Scale Types",
    "text": "Position Scale Types\nAlthough there are several types of scales, the two most common are scales for continuous data or discrete data. The focus will be on changing them.\nscale_*_continuous()\nscale_*_discrete()"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#position-scales-for-continuous-data-scale__continuous",
    "href": "modules/15_coordinates_axes_and_position_scales.html#position-scales-for-continuous-data-scale__continuous",
    "title": "Coordinates, axes, and position scales",
    "section": "Position scales for continuous data: scale_*_continuous()",
    "text": "Position scales for continuous data: scale_*_continuous()\nThe continuous scale:\nscale_y_continuous(\n  name = waiver(),\n  breaks = waiver(),\n  minor_breaks = waiver(),\n  n.breaks = NULL,\n  labels = waiver(),\n  limits = NULL,\n  expand = waiver(),\n  oob = censor,\n  na.value = NA_real_,\n  trans = \"identity\",\n  guide = waiver(),\n  position = \"left\",\n  sec.axis = waiver()\n)\n\nAxis limits\nIn general, axis limits specify where the axis should start and where is should end (what’s rendered is a little more complicated though).\nNotice there are four plots (e.g., A, B, C, and D). Examine them for differences in their bars. Plot D bars look different from the others beyond the obvious y-axis difference. The data passed to the geom for that plot are not what appear on the plot. After the plot was rendered, the x-axis was adjusted by adjusting its limits.\nA layer was added to the plot to set the limits scale_x_continuous(limits = c(0, 300)). Although there was no filtering of Time from the data frame, the limits were adjusted and the x-axis appears like Plots A, B, and C. Because the limits were adjusted after the statistical transformation took place in the geom, what you see is incorrect for the data. Whereas this approach presents no perceptual issue for most geoms, this approach will result in a misrepresentation of data for histogram plots displaying proportions or percentages. If you wish to present percentages, adjust the data frame a priori.\n\n\nTick Marks\nYou can specify where ticks appear along an axis by passing break specifications to breaks. Breaks also need corresponding labels. We will address both together because a label needs to exist for each of the breaks.\nWe can add breaks as a vector but remember that labels = scales::percent is just changing the rendering of the plot, not the actual values from the statistical transformation. You will need to pass a vector of proportions.\n  scale_y_continuous(breaks = c(.05, .10, .15, .20, .30),\n                     labels = scales::percent\n                     )\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = c(.05, .10, .15, .20, .30),\n                     labels = scales::percent\n                     ) \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nWait! Not all ticks are there. This is because geom_histogram() made adjustments to the plot by default. You will need to make sure the limits accommodate the breaks.\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = c(.05, .10, .15, .20, .30),\n                     labels = scales::percent,\n                     limits = c(0, .30)\n    ) +\n  labs(y = \"\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nBut notice also that only certain breaks were specified. Whether intentional or unintentional, there is a 10% jump from 20% to 30%. This looks odd but perhaps that was intentional.\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = c(.05, .10, .15, .20, .30),\n                     labels = scales::percent,\n                     limits = c(0, .30)\n    ) +\n  labs(y = \"\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#breaks-as-a-sequence-using-seq",
    "href": "modules/15_coordinates_axes_and_position_scales.html#breaks-as-a-sequence-using-seq",
    "title": "Coordinates, axes, and position scales",
    "section": "Breaks as a sequence using seq()",
    "text": "Breaks as a sequence using seq()\nUsing seq() we can specify the starting point (from) the ending point (to) and the step by which to create the sequence.\nFor example, seq(from = 0, to = .3, by = .05) will return 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3. We could also make the breaks sequence from 0 to 1 but if we truncate the limits, then you just won’t see them anyway. Just don’t truncate the bottom.\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = seq(0, 1, by = .05),\n                     labels = scales::percent,\n                     limits = c(0, .20)\n    ) +\n  labs(y = \"\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#break-labels",
    "href": "modules/15_coordinates_axes_and_position_scales.html#break-labels",
    "title": "Coordinates, axes, and position scales",
    "section": "Break labels",
    "text": "Break labels\nYou see that a labels adjustment has been added to the y-axis. This should suggest to you that you could pass your own break labels to either axis.\nFor example, we can just add a couple labels on the x-axis. Keep in mind that specifying labels will override other labeling by default.\n  scale_x_continuous(\n    breaks = c(100, 200),\n    label = c(\"100m\", \"Wow\")\n    )\nAnd we can make the labelling more clear along the y-axis but making the sequence step smaller.\n  scale_y_continuous(breaks = seq(0, 1, by = .02),\n                     labels = scales::percent,\n                     limits = c(0, .2)\n                     )\nWhich gives us:\n\nSWIM %&gt;%\n  filter(Time &lt; 300) %&gt;%\n  ggplot(., aes(Time)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)))) +\n  scale_y_continuous(breaks = seq(0, 1, by = .02),\n                     labels = scales::percent,\n                     limits = c(0, .2)\n                     ) +\n  scale_x_continuous(breaks = c(100, 200),\n                     label = c(\"100m\", \"Wow\")\n                     ) +\n  labs(y = \"\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#position-scales-for-discrete-data-scale__discrete",
    "href": "modules/15_coordinates_axes_and_position_scales.html#position-scales-for-discrete-data-scale__discrete",
    "title": "Coordinates, axes, and position scales",
    "section": "Position scales for discrete data: scale_*_discrete()",
    "text": "Position scales for discrete data: scale_*_discrete()\nA geom_*() that plots data for a categorical variable, will have a discrete x-axis.\ndiscrete_scale(\n  aesthetics,\n  scale_name,\n  palette,\n  name = waiver(),\n  breaks = waiver(),\n  labels = waiver(),\n  limits = NULL,\n  expand = waiver(),\n  na.translate = TRUE,\n  na.value = NA,\n  drop = TRUE,\n  guide = \"legend\",\n  position = \"left\",\n  super = ScaleDiscrete\n)\n\n\nLimits and Breaks\nWhen adjusting discrete limits, the limits correspond to the levels.\nscale_x_discrete(limits = c(\"Freestyle\", \"Butterfly\"))\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  scale_x_discrete(limits = c(\"Freestyle\", \"Butterfly\"))\n\nWarning: Removed 72 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIf you try to adjust a discrete axis using scale_*_continuous(), you will get the following error.\nError: Discrete value supplied to continuous scale\nAnd breaks operate the same way so we can specify as vector here too.\nbreaks = c(\"Freestyle\", \"Butterfly\")\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  scale_x_discrete(breaks = c(\"Freestyle\", \"Butterfly\"))\n\n\n\n\nThen select a subset by level:\nscale_x_discrete(limits = c(\"Freestyle\", \"Butterfly\"))\nAlternatively, if you don’t want to reference a long function like scale_x_discrete(), there are shorthand functions for limits which you could just add as layers to the plot.\n\nxlim(): a two-element vector with the start and end values\nylim(): a two-element vector with the start and end values\n\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  ylim(0, 600) +\n  xlim(\"Backstroke\" , \"Freestyle\", \"Butterfly\")\n\nWarning: Removed 57 rows containing missing values (`geom_point()`).\n\n\n\n\n#scale_x_discrete(breaks = c(\"Freestyle\", \"Butterfly\"))\n\nYou can also expand plot limits to ensure you include a value. For more, see expand_limits()."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#other-scale-functions",
    "href": "modules/15_coordinates_axes_and_position_scales.html#other-scale-functions",
    "title": "Coordinates, axes, and position scales",
    "section": "Other Scale Functions",
    "text": "Other Scale Functions\nThere are many other scale_*_() functions you could apply.\nscale_x_sqrt(...)\nscale_y_sqrt(...)"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#reverse-a-continuous-scale",
    "href": "modules/15_coordinates_axes_and_position_scales.html#reverse-a-continuous-scale",
    "title": "Coordinates, axes, and position scales",
    "section": "Reverse a Continuous Scale",
    "text": "Reverse a Continuous Scale\nscale_x_reverse()\nscale_y_reverse()\n\nSWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  scale_y_reverse()"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#convert-to-log-scale",
    "href": "modules/15_coordinates_axes_and_position_scales.html#convert-to-log-scale",
    "title": "Coordinates, axes, and position scales",
    "section": "Convert to Log Scale",
    "text": "Convert to Log Scale\nWhenever you perform operations, you should know what the returned values with be. The default logging function, log(), calculates the natural log. Use log10() or log(base = 10) to calculate base 10 logs.\nscale_x_log10(...)\nscale_y_log10(...)\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  labs(title = \"default\",\n       tag = \"A\",\n  ) + coord_flip()\n\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  scale_y_log10() +\n  labs(title = \"scale_y_log10()\",\n       tag = \"B\",\n       y = \"log10(Time)\"\n  ) + coord_flip()\n\n\nplot(gridExtra::arrangeGrob(plot1, plot2, ncol = 1))\n\n\n\n\nAlthough the data have been transformed, one problem is that that the labels are not fixed to match the transformation.\nWe can set breaks and labels in scale_y_log10() as we have done earlier. This steps is failry complicated. Just as we fixed labels for percents with scales::percent, the {scales} library offers assistance here as well. We can use scales::trans_breaks() and pass some arguments.\n   breaks = scales::breaks_log(n = 6, base = 10)\n   labels = labels = scales::label_log(digits = 2)\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  # create breaks and labels corresponding to the breaks \n  scale_y_log10(\n   breaks = scales::breaks_log(n = 6, base = 10),\n  ) + \n  labs(title = \"scale_y_log10() \",\n       subtitle = \"with with scales::breaks_log() \",\n       tag = \"C\",\n       y = \"log10(Time)\"\n  ) + coord_flip()\n\nplot4 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Event, y = Time)) +\n  geom_point(position = position_jitter()) +\n  # create breaks and labels corresponding to the breaks \n  scale_y_log10(\n   breaks = scales::breaks_log(n = 6, base = 10),\n   labels = scales::label_log(digits = 2)\n  ) + \n  labs(title = \"scale_y_log10()  \",\n       subtitle = \"with breaks and exponentiated labels\",\n       tag = \"D\",\n       y = \"log10(Time)\"\n  ) + coord_flip()\n\n\n \nplot(gridExtra::arrangeGrob(plot3, plot4, ncol = 1))\n\n\n\n\nBut they still might not look right. We can control our axis breaks by creating a sequence of values that we pass to scale_x_log10(breaks = ?). Starting at 10 seconds, we square to obtain 9 values.\n\n10 * 2^seq(from = 0, to = 9, by = 1)\n\n [1]   10   20   40   80  160  320  640 1280 2560 5120\n\n\nWe can create a starting point by creating a new data frame and defining an object to hold the fastest time and then plug that into seq().\n\nSWIM_with_min &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  filter(Event == \"Freestyle\") %&gt;%\n  #filter(Distance == 200) %&gt;%\n  mutate(Distance = factor(Distance)) \n\nminTime &lt;- min(SWIM_with_min$Time)\nmaxTime &lt;- max(SWIM_with_min$Time)\n\n(plot5 &lt;- SWIM_with_min %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Distance)) +\n  geom_point(position = position_jitter()) +\n  # create breaks starting at 10 and then doubling\n  scale_y_log10(\n   breaks = minTime * 2^seq(from = 0, to = 9, by = 1),\n   #labels = scales::log_breaks(10)# label_log(digits = 2)\n  ) + \n  labs(title = \"scale_y_log10() with breaks sequence\",\n       subtitle = paste0(\"adjusted to fastest time of: \", minTime, \"s\"),\n       tag = \"E\",\n       y = \"log10(Time)\",\n       x = \"\"\n  ) \n)"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#position-scales-for-datetime-data",
    "href": "modules/15_coordinates_axes_and_position_scales.html#position-scales-for-datetime-data",
    "title": "Coordinates, axes, and position scales",
    "section": "Position scales for date/time data",
    "text": "Position scales for date/time data\nThere area also scales for dealing with date and times. These can be used also in conjunction with breaks_pretty().\nscale_*_date()\nscale_*_time()"
  },
  {
    "objectID": "modules/16_statistical_transformations.html",
    "href": "modules/16_statistical_transformations.html",
    "title": "Statistical transformations",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/16_statistical_transformations.html#readings",
    "href": "modules/16_statistical_transformations.html#readings",
    "title": "Statistical transformations",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Weighting data\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Stats"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#external-functions",
    "href": "modules/16_statistical_transformations.html#external-functions",
    "title": "Statistical transformations",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#libraries",
    "href": "modules/16_statistical_transformations.html#libraries",
    "title": "Statistical transformations",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#load-libraries",
    "href": "modules/16_statistical_transformations.html#load-libraries",
    "title": "Statistical transformations",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#data-aggregation-using-group_by",
    "href": "modules/16_statistical_transformations.html#data-aggregation-using-group_by",
    "title": "Statistical transformations",
    "section": "Data aggregation using group_by()",
    "text": "Data aggregation using group_by()\nLet’s go through a simple example of data aggregation using group_by().\n\nDATA &lt;- data.frame(\n  Student = c(\"Jim\", \"Sally\", \"June\", \"Mildred\", \"Tilford\", \"Beavis\", \"Herman\", \"Peppa\", \"Kay\", \"Jake\", \"Name Missing\"),\n  Score  = c(80, 85, 79, 80, 81, 91, 89, 60, 65, 67, 65), \n  School = c(\"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\", \"D\", \"E\", \"E\"), \n  District = c(\"West\", \"West\", \"West\", \"West\", \"East\", \"East\", \"East\", \"North\", \"North\" , \"North\", \"North\")\n  ) \n\nYou can see that the performance for all students is on average, for example, if you didn’t know where they went to school. We would take only the mean.\n\nDATA %&gt;%\n  summarize(Score = mean(Score))     # calculate average\n\n     Score\n1 76.54545\n\n\nLet’s say we try to determine average performance for “all students” if we had the data aggregated as the school level and not the individual level.\n\nDATA %&gt;%\n  group_by(School) %&gt;%\n  summarize(Score = mean(Score)) %&gt;% # get the school level aggregated data\n  summarize(Score = mean(Score))     # then calculate average across all schools\n\n# A tibble: 1 × 1\n  Score\n  &lt;dbl&gt;\n1  75.5\n\n\nLet’s say we try to determine average performance for “all students” if we had the data aggregated as the district level and not the individual level.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  summarize(Score = mean(Score)) %&gt;% # get the district level aggregated data\n  summarize(Score = mean(Score))     # then calculate average across all districts\n\n# A tibble: 1 × 1\n  Score\n  &lt;dbl&gt;\n1  77.4\n\n\nSo what’s the average performance for students? Well, that interpretation differs based on how values are treated. At the highest level, all students’ Scores are weighed equally. Each student contributes to the data in the same way. When aggregated by School, each school contributes to the calculation equally, even if the number of bodies per school differs. And finally, when data are aggregated at the District level, all districts are treated equally in the calculation independent on the number of schools in a district. Only with weighting means would you end up with the same average performance.\nMeasures of variability in the data, however, reveal something else. Schools differ in variability and schools within districts vary as well. Depending on the level of aggregation, you may never notice interesting patterns in data that lead to questions to investigate and later policies to change. For example, addressing a school that is left behind others or a district that is left behind others. Aggregation can also lead to inefficient allocations of resources. If one school in a district needs help rather than all schools in the district needing help, the cost may differ substantially.\n\nstd_error &lt;- function(x) { sd(na.omit(x)) / sqrt(length(na.omit(x))) }\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  summarize(Var = var(Score),\n            SD  = sd(Score),\n            SEM = std_error(Score),\n            min = min(Score),\n            max = max(Score)\n  ) %&gt;% mutate(range = max - min)\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 8\n# Groups:   School [5]\n  School District   Var    SD   SEM   min   max range\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      West      12.5 3.54   2.5     80    85     5\n2 B      West       0.5 0.707  0.5     79    80     1\n3 C      East      28   5.29   3.06    81    91    10\n4 D      North     12.5 3.54   2.5     60    65     5\n5 E      North      2   1.41   1       65    67     2"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#grouping-structure-of-group_by-and-mutate",
    "href": "modules/16_statistical_transformations.html#grouping-structure-of-group_by-and-mutate",
    "title": "Statistical transformations",
    "section": "Grouping structure of group_by() and mutate()",
    "text": "Grouping structure of group_by() and mutate()\nLet’s mutate() the mean for Score after sub-setting with group_by().\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  mutate(Score = mean(na.omit(Score)))\n\n# A tibble: 11 × 4\n# Groups:   School, District [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim           82.5 A      West    \n 2 Sally         82.5 A      West    \n 3 June          79.5 B      West    \n 4 Mildred       79.5 B      West    \n 5 Tilford       87   C      East    \n 6 Beavis        87   C      East    \n 7 Herman        87   C      East    \n 8 Peppa         62.5 D      North   \n 9 Kay           62.5 D      North   \n10 Jake          66   E      North   \n11 Name Missing  66   E      North   \n\n\nThere are two things to watch when using this mutate() following group_by().\n1. A Score will be assigned to each row/case or Student in the data frame.\nWhen schools and districts are grouped, each student in the same school will have the same assigned average value. All rows are maintained, none dropped.\n2. The returned tibble takes on a new structure.\nLooking at the feedback in the console, you see the following report preceding the data.\nA tibble: 11 × 3\n# Groups:   School, District [5]\nYou also see this structure using glimpse().\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  mutate(Score = mean(na.omit(Score))) %&gt;%\n  glimpse()\n\nRows: 11\nColumns: 4\nGroups: School, District [5]\n$ Student  &lt;chr&gt; \"Jim\", \"Sally\", \"June\", \"Mildred\", \"Tilford\", \"Beavis\", \"Herm…\n$ Score    &lt;dbl&gt; 82.5, 82.5, 79.5, 79.5, 87.0, 87.0, 87.0, 62.5, 62.5, 66.0, 6…\n$ School   &lt;chr&gt; \"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\", \"D\", \"E\", \"E\"\n$ District &lt;chr&gt; \"West\", \"West\", \"West\", \"West\", \"East\", \"East\", \"East\", \"Nort…\n\n\nRows: 11\nColumns: 3\nGroups: School, District [5]\nWhat does the [5] mean? Well, before we answer this, let’s use summarize()."
  },
  {
    "objectID": "modules/16_statistical_transformations.html#grouping-structure-of-group_by-and-summarize",
    "href": "modules/16_statistical_transformations.html#grouping-structure-of-group_by-and-summarize",
    "title": "Statistical transformations",
    "section": "Grouping structure of group_by() and summarize()",
    "text": "Grouping structure of group_by() and summarize()\nLet’s summarize() the mean for Score after sub-setting with group_by().\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  summarize(Score = mean(Score))\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   School [5]\n  School District Score\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nThere are two things to watch when using this summarize() following group_by().\n1. A Score average is assigned to each row/case or School in this aggregated data frame.\nWhen schools and districts are grouped, each school will have its own average value. Rows from the data frame are dropped as are columns that are not passed to group_by(). In this case, School, District, and the new variable, Score are returned.\n2. The returned tibble takes on a new structure.\nThe feedback in the console is a little more detailed here.\n`summarise()` has grouped output by 'School'. You can override using the `.groups` argument.\n# A tibble: 5 × 3\n# Groups:   School [5]\nYou see reference to overriding the grouping using .groups. According to the tidyverse documentation for grouping, this parameter “controls the grouping structure of the output. The historical behaviour of removing the right hand side grouping variable corresponds to .groups = \"drop_last\" without a message or .groups = NULL with a message (the default)”.\nYou have most likely paid little attention to this message. By default summarize() keeps the first grouping variable passed to group_by() in the returned tibble. This is why you see School referenced and not District or both variables. So, do you want your data frame to contain groups or no groups? Stated differently, do you just want that data summarized by your grouping variables and have a simple nxm data frame or do you want something more complex?\nTo see the structure better, let’s first look a the structure of DATA and then more closely at the summarized version.\n\nstr(DATA)\n\n'data.frame':   11 obs. of  4 variables:\n $ Student : chr  \"Jim\" \"Sally\" \"June\" \"Mildred\" ...\n $ Score   : num  80 85 79 80 81 91 89 60 65 67 ...\n $ School  : chr  \"A\" \"A\" \"B\" \"B\" ...\n $ District: chr  \"West\" \"West\" \"West\" \"West\" ...\n\n\nLet’s assign the summarized data frame to an object for inspection.\n\nDSUM &lt;- DATA %&gt;%\n  group_by(School, District) %&gt;%\n  summarize(Score = mean(Score))\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\nFor DSUM, the structure is different. In particular, you see reference to (S3: grouped_df/tbl_df/tbl/data.frame). This tells you that the data frame is not a simple nxm but contains groups. You could think of this as 3 nxm data frames organized together. For more details, see the dplyr documentation.\n\nstr(DSUM)\n\ngropd_df [5 × 3] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ School  : chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n $ District: chr [1:5] \"West\" \"West\" \"East\" \"North\" ...\n $ Score   : num [1:5] 82.5 79.5 87 62.5 66\n - attr(*, \"groups\")= tibble [5 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ School: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ .rows : list&lt;int&gt; [1:5] \n  .. ..$ : int 1\n  .. ..$ : int 2\n  .. ..$ : int 3\n  .. ..$ : int 4\n  .. ..$ : int 5\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\n\ngroup_by() and summarize() with .groups\nWhen you group data using group_by() and then summarize(), the summary variables (e.g., mean) will result in a single row for each level of a single grouping variable. If there are more than one grouping variable, the additional grouping variable will be introduced to the data frame as a second column. The total number of rows in the data frame will be equal to the number of levels of group 1 x number of levels of group 2 if an only if each levels of group 1 has a corresponding level for group 2,\nfor example:\nsex   age    mean\nmen   young  x\nmen   old    x\nwomen young  x\nwomen old    x\nIf there is no pairing of levels in the data (e.g., no men who are old), that row will be omitted from the returned data frame.\nfor example:\nsex   age    mean\nmen   young  x\nwomen young  x\nwomen old    x\nrather than:\nsex   age    mean\nmen   young  x\nmen   old    NA\nwomen young  x\nwomen old    x\nYou really need to query ?dplyr::summarize to understand .groups, which controls the grouping of the returned data frame. This is also experimental to summarize(), so it might not be available in the future.\nThere are four argument options:\n\n\"drop_last\": dropping the last level of grouping. This was the only supported option before version 1.0.0.\n\"drop\": All levels of grouping are dropped.\n\"keep\": Same grouping structure as .data.\n\"rowwise\": Each row is its own group.\n\n\n.groups = \"drop_last\":\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"drop_last\")\n\n# A tibble: 14 × 3\n# Groups:   Event [6]\n   Event        Distance   Time\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8\n 2 Backstroke        200  124. \n 3 Breaststroke      100   61.6\n 4 Breaststroke      200  139. \n 5 Butterfly         100   55.3\n 6 Butterfly         200  125. \n 7 Freestyle          50   23.6\n 8 Freestyle         100   51.9\n 9 Freestyle         200  107. \n10 Freestyle         500  306. \n11 Freestyle        1650 1143. \n12 IM                200  126. \n13 IM                400  269. \n14 Medley            200  104. \n\n\nYou will see that the grouping for Distance is not in the grouping structure because it was the last grouping.\n# A tibble: 14 × 3\n# Groups:   Event [6]\n   Event        Distance   Time\n\n\n.groups = \"drop\":\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"drop\")\n\n# A tibble: 14 × 3\n   Event        Distance   Time\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8\n 2 Backstroke        200  124. \n 3 Breaststroke      100   61.6\n 4 Breaststroke      200  139. \n 5 Butterfly         100   55.3\n 6 Butterfly         200  125. \n 7 Freestyle          50   23.6\n 8 Freestyle         100   51.9\n 9 Freestyle         200  107. \n10 Freestyle         500  306. \n11 Freestyle        1650 1143. \n12 IM                200  126. \n13 IM                400  269. \n14 Medley            200  104. \n\n\nYou will see that all group are dropped from the grouping structure.\n# A tibble: 14 × 3\n   Event        Distance   Time\n\n\n.groups = \"keep\":\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"keep\")\n\n# A tibble: 14 × 3\n# Groups:   Event, Distance [14]\n   Event        Distance   Time\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8\n 2 Backstroke        200  124. \n 3 Breaststroke      100   61.6\n 4 Breaststroke      200  139. \n 5 Butterfly         100   55.3\n 6 Butterfly         200  125. \n 7 Freestyle          50   23.6\n 8 Freestyle         100   51.9\n 9 Freestyle         200  107. \n10 Freestyle         500  306. \n11 Freestyle        1650 1143. \n12 IM                200  126. \n13 IM                400  269. \n14 Medley            200  104. \n\n\nYou will see that all group are kept in the grouping structure.\n# A tibble: 14 × 3\n# Groups:   Event, Distance [14]\n   Event        Distance   Time\n\n\n.groups = \"rowwise\":\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"rowwise\")\n\n# A tibble: 14 × 3\n# Rowwise:  Event, Distance\n   Event        Distance   Time\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8\n 2 Backstroke        200  124. \n 3 Breaststroke      100   61.6\n 4 Breaststroke      200  139. \n 5 Butterfly         100   55.3\n 6 Butterfly         200  125. \n 7 Freestyle          50   23.6\n 8 Freestyle         100   51.9\n 9 Freestyle         200  107. \n10 Freestyle         500  306. \n11 Freestyle        1650 1143. \n12 IM                200  126. \n13 IM                400  269. \n14 Medley            200  104. \n\n\nYou will see that there groups but these are not based on the\n# A tibble: 14 × 3\n# Rowwise:  Event, Distance\nThe grouping structure always matters for subsequent computations. But with \"rowwise\" you will see this clearly. Following from above, let’s say we wanted to compute the mean across all of the Events in the data frame returned by group_by() then summarize(). We add mutate(mean = mean(Time)) on a new line of our piped code block.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"rowwise\") %&gt;%\n  mutate(mean = mean(Time))\n\n# A tibble: 14 × 4\n# Rowwise:  Event, Distance\n   Event        Distance   Time   mean\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100   59.8   59.8\n 2 Backstroke        200  124.   124. \n 3 Breaststroke      100   61.6   61.6\n 4 Breaststroke      200  139.   139. \n 5 Butterfly         100   55.3   55.3\n 6 Butterfly         200  125.   125. \n 7 Freestyle          50   23.6   23.6\n 8 Freestyle         100   51.9   51.9\n 9 Freestyle         200  107.   107. \n10 Freestyle         500  306.   306. \n11 Freestyle        1650 1143.  1143. \n12 IM                200  126.   126. \n13 IM                400  269.   269. \n14 Medley            200  104.   104. \n\n\nThe mean column does not contain a single mean replicated for each row in the data frame. Rather the grouping was per row, so each row has its one mean. The mean of a single value is, of course, itself.\n\n\nRevisiting \".groups = drop_last\":\nReturning to the default .groups structure, which is \"drop_last\", we can add the same mutate() to see what happens.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"drop_last\") %&gt;%\n  mutate(mean = mean(Time))\n\n# A tibble: 14 × 4\n# Groups:   Event [6]\n   Event        Distance   Time  mean\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke        100   59.8  92.1\n 2 Backstroke        200  124.   92.1\n 3 Breaststroke      100   61.6 100. \n 4 Breaststroke      200  139.  100. \n 5 Butterfly         100   55.3  90.4\n 6 Butterfly         200  125.   90.4\n 7 Freestyle          50   23.6 326. \n 8 Freestyle         100   51.9 326. \n 9 Freestyle         200  107.  326. \n10 Freestyle         500  306.  326. \n11 Freestyle        1650 1143.  326. \n12 IM                200  126.  197. \n13 IM                400  269.  197. \n14 Medley            200  104.  104. \n\n\nThe mean column still has different values but they are replicated on rows with the same Event group. This is because the data are grouped that way.\n\n\nRevisiting .groups = \"drop\":\nLet’s again add the same mutate() to see what happens.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),\n            .groups = \"drop\") %&gt;%\n  mutate(mean = mean(Time))\n\n# A tibble: 14 × 4\n   Event        Distance   Time  mean\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke        100   59.8  193.\n 2 Backstroke        200  124.   193.\n 3 Breaststroke      100   61.6  193.\n 4 Breaststroke      200  139.   193.\n 5 Butterfly         100   55.3  193.\n 6 Butterfly         200  125.   193.\n 7 Freestyle          50   23.6  193.\n 8 Freestyle         100   51.9  193.\n 9 Freestyle         200  107.   193.\n10 Freestyle         500  306.   193.\n11 Freestyle        1650 1143.   193.\n12 IM                200  126.   193.\n13 IM                400  269.   193.\n14 Medley            200  104.   193.\n\n\n\n\nConsider ungroup():\n.groups = \"drop\" in effect works the same as does ungroup(). The grouping structure is broken and all subsequent operations are based on the ungrouped data frame.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time)) %&gt;%\n  ungroup() %&gt;%\n  mutate(mean = mean(Time))\n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 14 × 4\n   Event        Distance   Time  mean\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke        100   59.8  193.\n 2 Backstroke        200  124.   193.\n 3 Breaststroke      100   61.6  193.\n 4 Breaststroke      200  139.   193.\n 5 Butterfly         100   55.3  193.\n 6 Butterfly         200  125.   193.\n 7 Freestyle          50   23.6  193.\n 8 Freestyle         100   51.9  193.\n 9 Freestyle         200  107.   193.\n10 Freestyle         500  306.   193.\n11 Freestyle        1650 1143.   193.\n12 IM                200  126.   193.\n13 IM                400  269.   193.\n14 Medley            200  104.   193.\n\n\nKeep in mind that functions work as they are programmed to work. Functions do not work like you think they work. You must understand the function and check our work to ensure your calculations are what you intend them to be.\n\n\nThe order of operations matters\nTo illustrate further, consider you want to calculate some summary statistics. You set out to obtain the mean and the standard deviation for your data. Those computations will be performed according to the grouping structure.\nWhen you compute standard deviation and the mean of Time, you assign the mean to Time because you want your plot to contain a clean name rather than one like Time_Mean that you will have to address in the plot.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time_sd = sd(Time),  # get sd of Time\n            Time = mean(Time)    # get mean, assign to same name\n            )\n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 14 × 4\n# Groups:   Event [6]\n   Event        Distance Time_sd   Time\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 Backstroke        100    4.47   59.8\n 2 Backstroke        200    8.02  124. \n 3 Breaststroke      100    5.76   61.6\n 4 Breaststroke      200   10.5   139. \n 5 Butterfly         100    4.32   55.3\n 6 Butterfly         200    7.74  125. \n 7 Freestyle          50    1.99   23.6\n 8 Freestyle         100    4.00   51.9\n 9 Freestyle         200   10.8   107. \n10 Freestyle         500   20.3   306. \n11 Freestyle        1650   98.2  1143. \n12 IM                200    8.13  126. \n13 IM                400   22.2   269. \n14 Medley            200    3.41  104. \n\n\nBoth variables use the same data because the standard deviation assigns the value to a different variable name Time_sd. The mean() is not based on some changed variable.\nThe output is different from the one returned when the mean is computed before the standard deviation and in particular when the mean is assigned to Time. In this case, the standard deviation is based on this new Time variable. Because the standard deviation is a measure of variability, and Time does not vary based on the grouping structure, NA is returned.\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time),   # get mean, assign to same name\n            Time_sd = sd(Time)   # get sd of Time        \n            )\n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 14 × 4\n# Groups:   Event [6]\n   Event        Distance   Time Time_sd\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 Backstroke        100   59.8      NA\n 2 Backstroke        200  124.       NA\n 3 Breaststroke      100   61.6      NA\n 4 Breaststroke      200  139.       NA\n 5 Butterfly         100   55.3      NA\n 6 Butterfly         200  125.       NA\n 7 Freestyle          50   23.6      NA\n 8 Freestyle         100   51.9      NA\n 9 Freestyle         200  107.       NA\n10 Freestyle         500  306.       NA\n11 Freestyle        1650 1143.       NA\n12 IM                200  126.       NA\n13 IM                400  269.       NA\n14 Medley            200  104.       NA\n\n\nIf you really wanted the standard deviation of all the means, consider ungrouping and then compute the standard deviation or use .groups =  \"drop\" in summarize(). Realize, however, this latter functionality is experimental and may not work sometime later. You are likely better off using ungroup().\n\nSWIM %&gt;%\n  group_by(Event, Distance) %&gt;%\n  summarize(Time = mean(Time)) %&gt;%  # get mean, assign to same name\n  ungroup() %&gt;%\n  mutate(sd = sd(Time))\n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 14 × 4\n   Event        Distance   Time    sd\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke        100   59.8  285.\n 2 Backstroke        200  124.   285.\n 3 Breaststroke      100   61.6  285.\n 4 Breaststroke      200  139.   285.\n 5 Butterfly         100   55.3  285.\n 6 Butterfly         200  125.   285.\n 7 Freestyle          50   23.6  285.\n 8 Freestyle         100   51.9  285.\n 9 Freestyle         200  107.   285.\n10 Freestyle         500  306.   285.\n11 Freestyle        1650 1143.   285.\n12 IM                200  126.   285.\n13 IM                400  269.   285.\n14 Medley            200  104.   285."
  },
  {
    "objectID": "modules/16_statistical_transformations.html#new-variable-columns",
    "href": "modules/16_statistical_transformations.html#new-variable-columns",
    "title": "Statistical transformations",
    "section": "New Variable Columns",
    "text": "New Variable Columns\ngroup_by() is not designed to create new variables but rather create groups. The function, however, does not require variables in a data frame in order to group based on their levels or differences in values.\n\ngroup_by() using a function\nHeretofore, we have grouped by column variables in a data frame. But you can also group in other ways, for example, by a variable calculated by a function. For example, if you wanted to group by standard deviations, you could calculated the standard deviation (Score-mean(Score)) / sd(Score) for each student and then cut() that variable into groups. cut will take a numeric vector variable and turn it into a factor variable of n groups as determined by what you pass to breaks. There is also an argument to make the factor ordered if you wish, ordered_result = TRUE but the default behavior does not order the factor. You can also change the level labels if you inspect the function.\n\nDATA %&gt;%\n  group_by(., z_factor = cut( x = ((Score - mean(Score)) / sd(Score) ), \n                          breaks = 5, \n                          ordered_result = T\n                          )\n  )\n\n# A tibble: 11 × 5\n# Groups:   z_factor [4]\n   Student      Score School District z_factor       \n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;ord&gt;          \n 1 Jim             80 A      West     (0.194,0.781]  \n 2 Sally           85 A      West     (0.781,1.37]   \n 3 June            79 B      West     (0.194,0.781]  \n 4 Mildred         80 B      West     (0.194,0.781]  \n 5 Tilford         81 C      East     (0.194,0.781]  \n 6 Beavis          91 C      East     (0.781,1.37]   \n 7 Herman          89 C      East     (0.781,1.37]   \n 8 Peppa           60 D      North    (-1.57,-0.979] \n 9 Kay             65 D      North    (-1.57,-0.979] \n10 Jake            67 E      North    (-0.979,-0.392]\n11 Name Missing    65 E      North    (-1.57,-0.979] \n\n\nYou can see that there are 4 different levels of the grouping variable. The tibble is grouped of course too.\nIf you struggle with remembering the formula for a z score, scale() will to the same thing.\n\nDATA %&gt;%\n  mutate(z = (Score - mean(Score))/sd(Score),\n         scale = scale(Score)\n         )\n\n        Student Score School District          z      scale\n1           Jim    80      A     West  0.3269018  0.3269018\n2         Sally    85      A     West  0.8000492  0.8000492\n3          June    79      B     West  0.2322724  0.2322724\n4       Mildred    80      B     West  0.3269018  0.3269018\n5       Tilford    81      C     East  0.4215313  0.4215313\n6        Beavis    91      C     East  1.3678261  1.3678261\n7        Herman    89      C     East  1.1785671  1.1785671\n8         Peppa    60      D    North -1.5656877 -1.5656877\n9           Kay    65      D    North -1.0925403 -1.0925403\n10         Jake    67      E    North -0.9032814 -0.9032814\n11 Name Missing    65      E    North -1.0925403 -1.0925403\n\n\nIf you want n groups based on specific breaks, then pass a vector of those break units. For example, if we want levels to correspond to some meaningful standard-deviation cuts. For example, if you wanted to group those with z scores ranging from infinitely negative to -2, -2 to -1, - to 1, 1 to 2, and 2 to infinitely large, you could specify the breaks. If there are no values in those ranges, then there won’t be any data for those breaks.\n\nDATA %&gt;%\n  group_by(z_factor = cut( scale(Score), \n                          breaks = c(-Inf, -2, -1, 1, 2, Inf),\n                          ordered_result = T\n                          ), \n           ) %&gt;%\n  ungroup() \n\n# A tibble: 11 × 5\n   Student      Score School District z_factor\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;ord&gt;   \n 1 Jim             80 A      West     (-1,1]  \n 2 Sally           85 A      West     (-1,1]  \n 3 June            79 B      West     (-1,1]  \n 4 Mildred         80 B      West     (-1,1]  \n 5 Tilford         81 C      East     (-1,1]  \n 6 Beavis          91 C      East     (1,2]   \n 7 Herman          89 C      East     (1,2]   \n 8 Peppa           60 D      North    (-2,-1] \n 9 Kay             65 D      North    (-2,-1] \n10 Jake            67 E      North    (-1,1]  \n11 Name Missing    65 E      North    (-2,-1] \n\n\nYou can also just group by the function without using cut() if you wish to group by those with identical values on the variable. In this case, using count() or tally() reveals there are only two instances with the same score.\n\nDATA %&gt;%\n  group_by(., z_factor = ((Score - mean(Score)) / sd(Score) )) %&gt;%\n  count(sort = TRUE)     # tally(sort = TRUE)\n\n# A tibble: 9 × 2\n# Groups:   z_factor [9]\n  z_factor     n\n     &lt;dbl&gt; &lt;int&gt;\n1   -1.09      2\n2    0.327     2\n3   -1.57      1\n4   -0.903     1\n5    0.232     1\n6    0.422     1\n7    0.800     1\n8    1.18      1\n9    1.37      1"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#adddrop-grouping-variable-columns",
    "href": "modules/16_statistical_transformations.html#adddrop-grouping-variable-columns",
    "title": "Statistical transformations",
    "section": "Add/drop Grouping Variable Columns",
    "text": "Add/drop Grouping Variable Columns\nBy default, group_by() on a data frame that is already grouped (see earlier on grouped data frame), the existing grouping structure will be replaced by new grouping structure.\nLet’s get an example. Please note that this example assigned the tibble to an object but whether you assign or not, the grouped structure exists. So functions that follow the group_by() keep that structure.\n\nschool_grouped &lt;- DATA %&gt;%\n  group_by(School) \n\nschool_grouped\n\n# A tibble: 11 × 4\n# Groups:   School [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nNow group by a new column:\n\nschool_grouped %&gt;%\n  group_by(District)\n\n# A tibble: 11 × 4\n# Groups:   District [3]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nYou will see the grouping structure has changed.\n# A tibble: 11 × 4\n# Groups:   District [3]\n\nRetain Grouping\nIf you want to retain the existing group, you would need to use .add = TRUE.\n\nschool_grouped %&gt;%\n  group_by(District, .add = TRUE)\n\n# A tibble: 11 × 4\n# Groups:   School, District [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nNotice in the console, that both School and District are included in the groups.\n# A tibble: 11 × 4\n# Groups:   School, District [5]"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#why-care-about-grouping-structure",
    "href": "modules/16_statistical_transformations.html#why-care-about-grouping-structure",
    "title": "Statistical transformations",
    "section": "Why Care About Grouping Structure",
    "text": "Why Care About Grouping Structure\nWell, the functions you apply to a grouped tibble will sometimes lead to calculations that are not what you intend. We provided some examples earlier but given the importance of the issue, we may benefit from another example.\nLet’s say you want to compute the average for each school and add that school average for each student. This would tell you how the student differs from their school performance. Then you want to obtain the mean of all the schools and see how the school differs from all the schools.\nYou code it out:\n\nDATA %&gt;%\n  # group \n  group_by(School) %&gt;%\n  # calculate the mean of Score for each School\n  mutate(School_Mean = mean(Score)) %&gt;%  \n  # calculate the mean of all values (think Grand Mean from stats)\n  mutate(Mean_of_all = mean(School_Mean)) %&gt;%\n  # calculate the school performance relative to all\n  mutate(School_Performance = factor(case_when(\n    School_Mean &lt; Mean_of_all ~ \"Below Average\",\n    School_Mean == Mean_of_all ~ \"Average\",\n    School_Mean &gt; Mean_of_all ~ \"Above Average\"\n    ), ordered = T)\n  )\n\n# A tibble: 11 × 7\n# Groups:   School [5]\n   Student      Score School District School_Mean Mean_of_all School_Performance\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;ord&gt;             \n 1 Jim             80 A      West            82.5        82.5 Average           \n 2 Sally           85 A      West            82.5        82.5 Average           \n 3 June            79 B      West            79.5        79.5 Average           \n 4 Mildred         80 B      West            79.5        79.5 Average           \n 5 Tilford         81 C      East            87          87   Average           \n 6 Beavis          91 C      East            87          87   Average           \n 7 Herman          89 C      East            87          87   Average           \n 8 Peppa           60 D      North           62.5        62.5 Average           \n 9 Kay             65 D      North           62.5        62.5 Average           \n10 Jake            67 E      North           66          66   Average           \n11 Name Missing    65 E      North           66          66   Average           \n\n\nPerfect. OK, let’s plot it. Oh but first let me inspect the data. Um, why is School_Performance the same for all Students? Schools are not performing the same so they cannot all be average. Check your case_when() for errors because that where the new variable was created. Then you spend 40 days and 40 nights trying to fix your code. No matter what you do with case_when(), you cannot fix the problem. So you try to create 42 data frames to solve your problem. Even grandma knows that is a ridiculous strategy. She suggests you read the documentation for all of the functions you used because one time her pot-luck cake flopped and she inspected the expiration date for all of her ingredients and found the baking soda was old.\nYou discover that the grouping structure is retained on all operations until that grouping structure is removed or replaced."
  },
  {
    "objectID": "modules/16_statistical_transformations.html#variable-loss-with-summarize",
    "href": "modules/16_statistical_transformations.html#variable-loss-with-summarize",
    "title": "Statistical transformations",
    "section": "Variable loss with summarize()",
    "text": "Variable loss with summarize()\nBecause summarize() returns a tibble based on the grouping structure, you will lose all variables that are not in the grouping structure. By design, it no longer allows you to return a data frame with duplicated rows based on the variables passed to group_by().\nReturning to the school data, what this means, is that you cannot retain the School if you group by the District in order to obtain averages by district.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  summarize(Mean = mean(Score))\n\n# A tibble: 3 × 2\n  District  Mean\n  &lt;chr&gt;    &lt;dbl&gt;\n1 East      87  \n2 North     64.2\n3 West      81  \n\n\nIf you try to add School to group_by(), then you will only obtain the averages by schools within districts.\n\nDATA %&gt;%\n  group_by(School, District) %&gt;%\n  summarize(Mean = mean(Score)) \n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   School [5]\n  School District  Mean\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nYou can try to summarize based on a variable without assign it to a function but that is no longer allowed with summarize(). The following code block will throw an error.\nDATA %&gt;%\n  group_by(District) %&gt;%\n  summarize(Mean = mean(Score),\n          School               # add school \n          )"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#an-alternative-to-summarize-reframe",
    "href": "modules/16_statistical_transformations.html#an-alternative-to-summarize-reframe",
    "title": "Statistical transformations",
    "section": "An alternative to summarize(): reframe()",
    "text": "An alternative to summarize(): reframe()\nInstead, you can use reframe(), which allows for previous functionality of summarize() that is now deprecated.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  reframe(Mean = mean(Score),\n          School,\n          Student\n          )\n\n# A tibble: 11 × 4\n   District  Mean School Student     \n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;       \n 1 East      87   C      Tilford     \n 2 East      87   C      Beavis      \n 3 East      87   C      Herman      \n 4 North     64.2 D      Peppa       \n 5 North     64.2 D      Kay         \n 6 North     64.2 E      Jake        \n 7 North     64.2 E      Name Missing\n 8 West      81   A      Jim         \n 9 West      81   A      Sally       \n10 West      81   B      June        \n11 West      81   B      Mildred     \n\n\nRemember that the operations in summarize(), mutate(), and reframe() all depend on the grouping structure. If you wanted to add variables, you would need to group a different way and you would need to add all variables into summarize() every step of the way.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  reframe(District_Mean = mean(Score),\n          School, \n          Student,\n          Score\n          ) %&gt;%\n  ungroup() %&gt;%\n  group_by(School) %&gt;%\n  reframe(School_Mean = mean(Score),\n          School, \n          Student,\n          Score,\n          District_Mean\n          ) %&gt;%\n  ungroup()\n\n# A tibble: 11 × 5\n   School School_Mean Student      Score District_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n 1 A             82.5 Jim             80          81  \n 2 A             82.5 Sally           85          81  \n 3 B             79.5 June            79          81  \n 4 B             79.5 Mildred         80          81  \n 5 C             87   Tilford         81          87  \n 6 C             87   Beavis          91          87  \n 7 C             87   Herman          89          87  \n 8 D             62.5 Peppa           60          64.2\n 9 D             62.5 Kay             65          64.2\n10 E             66   Jake            67          64.2\n11 E             66   Name Missing    65          64.2"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#retaining-distinct-data-after-mutate-using-distinct",
    "href": "modules/16_statistical_transformations.html#retaining-distinct-data-after-mutate-using-distinct",
    "title": "Statistical transformations",
    "section": "Retaining distinct data after mutate() using distinct()`",
    "text": "Retaining distinct data after mutate() using distinct()`\nThis is just too tedious. Your better option is mutate() as all variables will be added to the full data frame. All variables are neatly and logically appended to the right hand side of the data frame.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  group_by(School) %&gt;%\n  mutate(School_Mean = mean(Score))\n\n# A tibble: 11 × 6\n# Groups:   School [5]\n   Student      Score School District District_Mean School_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt;\n 1 Jim             80 A      West              81          82.5\n 2 Sally           85 A      West              81          82.5\n 3 June            79 B      West              81          79.5\n 4 Mildred         80 B      West              81          79.5\n 5 Tilford         81 C      East              87          87  \n 6 Beavis          91 C      East              87          87  \n 7 Herman          89 C      East              87          87  \n 8 Peppa           60 D      North             64.2        62.5\n 9 Kay             65 D      North             64.2        62.5\n10 Jake            67 E      North             64.2        66  \n11 Name Missing    65 E      North             64.2        66  \n\n\nAlso, when you use a new group_by(), it will replace previous grouping structure by default. The following two code blocks return the same data frame.\nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  group_by(School) %&gt;%\n  mutate(School_Mean = mean(Score))\n  \nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  ungroup() %&gt;%                   # ungroup\n  group_by(School) %&gt;%\n  mutate(School_Mean = mean(Score))\nIf you wish those variables to remain, you have a couple of options. The first would be to use mutate().\nNotice, however, that if you want to extract the summaries from the large data frame as you would have had you used summarize() , you cannot just select() your column of interest because the repetitions will exist for each row in the data frame.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  select(c(\"School\", \"District_Mean\"))\n\nAdding missing grouping variables: `District`\n\n\n# A tibble: 11 × 3\n# Groups:   District [3]\n   District School District_Mean\n   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n 1 West     A               81  \n 2 West     A               81  \n 3 West     B               81  \n 4 West     B               81  \n 5 East     C               87  \n 6 East     C               87  \n 7 East     C               87  \n 8 North    D               64.2\n 9 North    D               64.2\n10 North    E               64.2\n11 North    E               64.2\n\n\nYou can obtain the rows that are distinct() (unique) and then pick() the ones to keep.\n\nDATA %&gt;%\n  group_by(District) %&gt;%\n  mutate(District_Mean = mean(Score)) %&gt;%\n  distinct(., pick(c(\"District\", \"District_Mean\")))\n\n# A tibble: 3 × 2\n# Groups:   District [3]\n  District District_Mean\n  &lt;chr&gt;            &lt;dbl&gt;\n1 West              81  \n2 East              87  \n3 North             64.2\n\n\nBut you will need to ungroup() before distinct() because, as we have mentioned before, all subsequent functions other than group_by() will maintain the previous grouping structure by default.\n\nDATA %&gt;%\n  group_by(School) %&gt;%\n  mutate(School_Mean = mean(Score)) %&gt;%\n  ungroup()\n\n# A tibble: 11 × 5\n   Student      Score School District School_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;\n 1 Jim             80 A      West            82.5\n 2 Sally           85 A      West            82.5\n 3 June            79 B      West            79.5\n 4 Mildred         80 B      West            79.5\n 5 Tilford         81 C      East            87  \n 6 Beavis          91 C      East            87  \n 7 Herman          89 C      East            87  \n 8 Peppa           60 D      North           62.5\n 9 Kay             65 D      North           62.5\n10 Jake            67 E      North           66  \n11 Name Missing    65 E      North           66"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#the-jitter-problem-with-full-data-frame",
    "href": "modules/16_statistical_transformations.html#the-jitter-problem-with-full-data-frame",
    "title": "Statistical transformations",
    "section": "The Jitter problem with full data frame",
    "text": "The Jitter problem with full data frame\nJittering takes place at the row level. Because the full data frame is used, each row plotted gets jitter. This means that the group mean that is on each row (redundant per group) is plotted. In such cases, you might be better off using one data frame for the full plot and a summarized data frame for the other plot. You can define the data frame in ggplot() or in the specific geom_point(). In this example, we will define it in ggplot() along with aesthetics. This will be inherited by default for the first geom_point() and then we can specify for the second geom_point().\nBecause there are different data frames, Time can be used in both data sets. There is no need to have two different variables as there is for the full data set.\n\nSWIMMEAN &lt;- SWIM_NEW %&gt;%\n  # group both (creates nxm subsets)\n  group_by(Event, School) %&gt;% \n  summarize(Time = mean(Time)) %&gt;%\n  ungroup() %&gt;%\n  # and we need to add a shape too\n  mutate(\n    Shape  = ifelse(stringr::str_detect(School, \"CMS\"), 21, 24) # filled\n  ) \n\n`summarise()` has grouped output by 'Event'. You can override using the\n`.groups` argument.\n\nSWIMMEAN\n\n# A tibble: 12 × 4\n   Event        School  Time Shape\n   &lt;chr&gt;        &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Backstroke   CMS     97.8    21\n 2 Backstroke   PP     100.     24\n 3 Breaststroke CMS    105.     21\n 4 Breaststroke PP      89.3    24\n 5 Butterfly    CMS     73.9    21\n 6 Butterfly    PP      80.5    24\n 7 Freestyle    CMS     81.2    21\n 8 Freestyle    PP     102.     24\n 9 IM           CMS    162.     21\n10 IM           PP     126.     24\n11 Medley       CMS    104.     21\n12 Medley       PP     104.     24\n\n\nNotice that this data frame contains only four variables: Event, School, Time, and Shape. All aesthetics for a plot using that data set will be constrained to those variables. Because both data frames contain them, we can just add the aesthetics to the plot object rather than the geom.\n\nsubset_identity_plot &lt;- SWIM_NEW %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event,\n                       y = Time, \n                       shape = Shape\n                       )\n         ) +\n  # plot all data (y = Time) from SWIM\n  geom_point(position = position_jitter(seed = 167, \n                                        height = 0, \n                                        width = .2),\n             alpha = .8,\n             size = 2\n  ) +\n  # Add a layer using the grouped data (y = Time) from SWIMMEAN\n  geom_point(data = SWIMMEAN,\n             size = 3,\n             fill = \"grey60\",\n             stroke = 1,\n             alpha = 1,\n             position = position_jitter(seed = 167, height = 0, width = .3)\n             ) +\n  coord_flip() +\n  scale_shape_identity() +\n  labs(caption = \"Caption illustration:\\nCMS (cicle),  PP (triangle); Mean (filled)\")\n\nsubset_identity_plot\n\n\n\n\nBoth plots together:\n\nsuppressMessages(\n  plot(gridExtra::arrangeGrob(full_identity_plot, \n                       subset_identity_plot, ncol = 1)\n  )\n)\n\n\n\n\nWhat you see in the second plot is what you might expect. Remember, that if you want to pass a grouping variable summary as an additional layer of a plot, you might be better off creating a separate data frame and pass it separately."
  },
  {
    "objectID": "modules/16_statistical_transformations.html#examples-of-color-versions",
    "href": "modules/16_statistical_transformations.html#examples-of-color-versions",
    "title": "Statistical transformations",
    "section": "Examples of Color Versions",
    "text": "Examples of Color Versions\n\ncolor_plot1 &lt;- SWIM_NEW %&gt;%\n  # group both (creates nxm subsets)\n  group_by(Event, School) %&gt;%\n  mutate(MeanTime = mean(Time)) %&gt;%\n  ungroup() %&gt;%\n  ggplot(., aes(x = Event, \n                y = Time, \n                col = School, \n                fill = School\n                )\n         ) +\n  # plot all data (y = Time)\n  geom_point(position = position_jitter(seed = 167, \n                                        height = 0, \n                                        width = .2),\n             pch = 1,\n             alpha = .7,\n             stroke = 1,\n             size = 2\n  ) +\n  # Add a layer using the grouped data (y = MeanTime)\n  geom_point(aes(y = MeanTime), \n             size = 2,\n             alpha = .4\n             ) +\n  coord_flip() +\n  labs(caption = \"Caption illustration:\\nMeans are closed circles\")\n\ncolor_plot2 &lt;- SWIM_NEW %&gt;%\n  # group both (creates nxm subsets)\n  group_by(Event, School) %&gt;% \n  mutate(MeanTime = mean(Time)) %&gt;%\n  ungroup() %&gt;%\n  ggplot(., aes(x = Event, \n                y = Time, \n                col = School, \n                fill = School\n                )\n         ) +\n  # plot all data (y = Time)\n  geom_point(position = position_jitter(seed = 167, \n                                        height = 0, \n                                        width = .2),\n             alpha = .7,\n             size = 2\n  ) +\n  # Add a layer using the grouped data (y = MeanTime)\n  geom_point(aes(y = MeanTime), \n             pch = 1,\n             size = 2,\n             stroke = 1,\n             alpha = .4\n             ) +\n  coord_flip() +\n  labs(caption = \"Caption illustration:\\nMeans are open circles\")\n\nplot(gridExtra::arrangeGrob(color_plot1, color_plot2, ncol = 1))"
  },
  {
    "objectID": "modules/16_statistical_transformations.html#a-note-on-size",
    "href": "modules/16_statistical_transformations.html#a-note-on-size",
    "title": "Statistical transformations",
    "section": "A note on size",
    "text": "A note on size\nFor geom_point(), you should understand what is happening when you pass an argument (e.g., size = 2) to the parameter because of its implications for bias in data visualizations. The size parameter scales on both the x and y dimensions proportionately which means that for any circle that doubles the size of the point, its radius will also double. When the radius doubles, however, the diameter and circumference also double. You might guess where this discussion is going.\nIf size is a constant, this likely will not be a problem. If, however, size is mapped to a variable, then then you have a perceptual challenge related to difficulty with comparing area. See Cleveland & McGill (1984). Moreover, because the area of a circle is proportional to the square of its radius, doubling the point size increases area fourfold.\nHere is an example.\n\nggplot(data = \n         data.frame(x     = 0, \n                    y     = 0, \n                    panel = c(\"Size = 13\", \"Size = 26\"), \n                    size = c(13, 26)),\n       mapping = aes(x, y, size = size)\n       ) + \n  geom_point() +\n  scale_x_continuous(limits = c(-5, 5),\n                     breaks = seq(-5, 5, 1)) +\n  scale_y_continuous(limits = c(-5, 5),\n                     breaks = seq(-5, 5, 1)) +\n  scale_size_identity() +\n  facet_wrap(.~panel) + \n  labs(x = NULL, y = NULL)"
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html",
    "href": "modules/17_visualizing_more_distributions.html",
    "title": "Visualizing more distributions",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#readings",
    "href": "modules/17_visualizing_more_distributions.html#readings",
    "title": "Visualizing more distributions",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing distributions: Visualizing many distributions at once"
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#external-functions",
    "href": "modules/17_visualizing_more_distributions.html#external-functions",
    "title": "Visualizing more distributions",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#libraries",
    "href": "modules/17_visualizing_more_distributions.html#libraries",
    "title": "Visualizing more distributions",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting\n{ggridges} 0.5.4: for plotting ridgeline plots\n{ggforce} 0.4.1: for plotting sina plots"
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#load-libraries",
    "href": "modules/17_visualizing_more_distributions.html#load-libraries",
    "title": "Visualizing more distributions",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(ggridges)"
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#five-number-summary",
    "href": "modules/17_visualizing_more_distributions.html#five-number-summary",
    "title": "Visualizing more distributions",
    "section": "Five-Number Summary",
    "text": "Five-Number Summary\nTukey wanted box plots to visualize high-level summary information as a Five-number Summary.\n\nminimum point: 0th percentile point excluding any outliers\nfirst quartile: 25th percentile\nsecond quartile 50th percentile (median)\nthird quartile: 75th percentile\nmaximum point: 100th percentile point excluding any outliers\n\nDepending on the box plot created, the whiskers may terminate a the upper and lower extremes in order to visualize minimum and maximum values of the data. Alternatively, the whisker may frame out 1.5 times the interquartile range."
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#distributional-information",
    "href": "modules/17_visualizing_more_distributions.html#distributional-information",
    "title": "Visualizing more distributions",
    "section": "Distributional Information",
    "text": "Distributional Information\n\nBox plot Density\nIf you know how to examine box plots, information about the distribution’s density is also visually present, making helpful identifying whether distributions are skewed negatively or positively and are leptokurtic or platykurtic. When the bottom whisker is long and the top is short, you will have a distribution with a long lower tail, making is skewed negatively. When the opposite is true, the distribution will be skewed positively.\n\n\nInterquartile range (IQR)\nSimilarly, the interquartile range (IQR) can be extracted as it represents the distance between the upper and lower quartiles. The box itself frames out the IQR.\n\n\nExamples\nBox plots can be used to visualize the distribution for a single set of data or, like strip charts and violin plots, for displaying distributions of a variable across many categorical groups. As with violin plots, you will have to be mindful of your data structure and convert numeric variables to categorical as seen here.\n\nnumeric_plot &lt;- SWIM %&gt;%\n  filter(Distance &lt; 300) %&gt;%\n  ggplot(., \n       mapping = aes(x = Distance, \n                     y = Time, \n                     group = 1    # need to set group to avoid error\n                     )\n       ) +\n  geom_boxplot() +\n  labs(tag = \"A\", title = \"Distance as Numeric\")\n\nfactor_plot1 &lt;- SWIM %&gt;%\n  filter(Distance &lt; 300) %&gt;%\n  ggplot(., \n       mapping = aes(x = factor(Distance), y = Time)) +\n  geom_boxplot(fill = \"grey80\") +\n  labs(tag = \"B\", title = \"Distance as a Factor\\nGray is a Primariy Color\")\n\nfactor_plot2 &lt;- SWIM %&gt;%\n  filter(Distance &lt; 300) %&gt;%\n  ggplot(., \n       mapping = aes(x = Distance, y = Time)) +\n  geom_boxplot(mapping = aes(fill = factor(Distance))) + \n  theme(legend.position = \"bottom\") +\n  labs(tag = \"C\", title = \"Label and Color are Redundant (Unnecessary)\")\n\nfactor_plot3 &lt;- SWIM %&gt;%\n  filter(Distance &lt; 300) %&gt;%\n  ggplot(., \n       mapping = aes(x = Event, y = Time)) +\n  geom_boxplot(mapping = aes(fill = Event)) + \n  theme(legend.position = \"bottom\") +\n  labs(tag = \"D\", title = \"Label and Color are Redundant (Unnecessary)\")\n\nsuppressMessages(\n  plot(gridExtra::arrangeGrob(numeric_plot, factor_plot1, \n                              factor_plot2, factor_plot3, \n                              ncol = 2)\n       )\n)\n\n\n\n\nAnd of course, the colors, lines, and other aesthetics are customization."
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#geom_density_ridges-vs.-geom_density_ridges2",
    "href": "modules/17_visualizing_more_distributions.html#geom_density_ridges-vs.-geom_density_ridges2",
    "title": "Visualizing more distributions",
    "section": "geom_density_ridges() vs. geom_density_ridges2()",
    "text": "geom_density_ridges() vs. geom_density_ridges2()\nYou will notice that with geom_density_ridges(), the line of the density plots simply outlines the density and that there is not a solid line across the x-axis. geom_density_ridges2() uses closed polygons so the line will be visible along the x-axis or the bottom of each density estimation plot. What looks better to you?\nAlso, those tails of your plot are kind of distracting when they do not communicate useful information. You may wish to cut the trailing tails by passing a value to rel_min_height to cut the trailing tails. There is no built-in algorithm to adjust this for you, so adjust as necessary.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges() +\n  ggtitle(\"geom_density_ridges()\")\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges2() +\n  ggtitle(\"geom_density_ridges2()\")\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges2(rel_min_height = 0.005) +\n  ggtitle(\"geom_density_ridges2()\\nrel_min_height = 0.005\")\n\nplot4 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges2(rel_min_height = 0.00000001) +\n  ggtitle(\"geom_density_ridges2()\\nrel_min_height = 0.00000001\")\n\nsuppressMessages(\n  plot(gridExtra::arrangeGrob(plot1, plot2, plot3, plot4, ncol = 2))\n)"
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#other-aesthetics",
    "href": "modules/17_visualizing_more_distributions.html#other-aesthetics",
    "title": "Visualizing more distributions",
    "section": "Other Aesthetics",
    "text": "Other Aesthetics\nAs with other geom_*()s, arguments for color, fill, linetype, alpha, size (same as linewidth in geom_line()) etc. can be set or mapped.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = factor(Distance))) +\n  geom_density_ridges2(fill = \"gold\",\n                      color = \"black\",\n                      linetype = \"solid\",\n                      size = .4,\n                      alpha = .6,\n                      rel_min_height = 0.00001) +\n  ggtitle('fill = \"gold\"\\nlinetype = \"solid\"')\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = Event)) +\n  geom_density_ridges2(aes(fill = factor(Distance)),\n                      linetype = \"dashed\",\n                      size = .4,\n                      alpha = 1, \n                      scale = 1,\n                      rel_min_height = 0.00001\n                      ) +\n  #theme(legend.position = \"none\") +\n  #theme(legend.position = c(.85, .2)) +\n  colorspace::scale_fill_discrete_sequential(palette = \"Burg\") +\n  ggtitle('aes(fill = factor(Distance)) + palette = \"Burg\"\\nlinetype = \"dashed\"')\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = Event)) +\n  geom_density_ridges_gradient(aes(fill = stat(x)),\n                               scale = 3, \n                               size = 0.3, \n                               rel_min_height = 0.01\n                               ) +\n  colorspace::scale_fill_continuous_sequential(name = \"Time\",\n                                               palette = \"Burg\") +\n  ggtitle('geom_density_ridges_gradient\\nscale_fill_continuous_sequential + palette = \"Burg\"')\n\n\nplot4 &lt;- SWIM %&gt;%\n  filter(Time &lt; 500) %&gt;%\n  ggplot(., aes(x = Time, y = Event)) +\n  geom_density_ridges_gradient(aes(fill = stat(x)),\n                               scale = 1, \n                               size = 0.3, \n                               rel_min_height = 0.01\n                               ) +\n  colorspace::scale_fill_continuous_sequential(name = \"Time\",\n                                               palette = \"Rocket\",) +\n  #theme(legend.position = c(.85, .2)) +\n  ggtitle('geom_density_ridges_gradient\\nscale_fill_continuous_sequential + palette = \"Rocket\"')\n\n\nsuppressMessages(\n  plot(gridExtra::arrangeGrob(plot1, plot2, plot3, plot4, ncol = 2))\n)\n\nWarning: `stat(x)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(x)` instead."
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html",
    "href": "modules/18_visualizing_uncertainty.html",
    "title": "Visualizing uncertainty",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#readings",
    "href": "modules/18_visualizing_uncertainty.html#readings",
    "title": "Visualizing uncertainty",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing uncertainty\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Uncertainty"
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#external-functions",
    "href": "modules/18_visualizing_uncertainty.html#external-functions",
    "title": "Visualizing uncertainty",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#custom-functions",
    "href": "modules/18_visualizing_uncertainty.html#custom-functions",
    "title": "Visualizing uncertainty",
    "section": "Custom Functions",
    "text": "Custom Functions\nWe will use some custom functions to handle some tasks this module."
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#libraries",
    "href": "modules/18_visualizing_uncertainty.html#libraries",
    "title": "Visualizing uncertainty",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting\n{ggdist} 3.3.0: for plotting distributions\n{distributional} 0.3.2: for plotting distributional information\n{tidyr} 1.3.0: for tidying up models\n{broom} 1.0.5: for cleaning up models"
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#load-libraries",
    "href": "modules/18_visualizing_uncertainty.html#load-libraries",
    "title": "Visualizing uncertainty",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggdist)\nlibrary(broom)\nlibrary(distributional)"
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#interim-summary",
    "href": "modules/18_visualizing_uncertainty.html#interim-summary",
    "title": "Visualizing uncertainty",
    "section": "Interim Summary",
    "text": "Interim Summary\nThere are a few details here worth noting given the comparisons here. First, the bar plot and the table take up about the same page real estate yet the table conveys much more information. A table can be used to provide a lot of detail whereas a plot may allow a lot of detailing . Yes, we can create stacked or grouped bar plots to take up the same real estate but you should always ask what your the goal is for a plot and whether the plot is the best medium for visualizing data.\nSecond, the important aspect of the data presented in the table and the bar plot is that the number of events does not vary for a given grouping. Yes, the counts change across the team groupings and likely across years but for this year, event, and teams, the height of the bars do not vary. Where data do not vary, bar plots are a good choice.\nThird, plots are visual objects that are processed by the visual system. Plot elements will affect how the visual system processes items, directs attention exogenously (bottom-up) rather than endogenously (top-down) which may have lasting influences on plot memorability."
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#point-estimates",
    "href": "modules/18_visualizing_uncertainty.html#point-estimates",
    "title": "Visualizing uncertainty",
    "section": "Point Estimates",
    "text": "Point Estimates\nWe can filter or an event, group the data, and summarize by groups using means in order to plot those mean point estimates are bars. This is the traditional, though not personally recommended, approach to plotting data in various disciplines. This will serve as a starting point for plots.\n\nSWIM |&gt;\n  group_by(Team, Event) |&gt;\n  summarize(Mean = mean(Time)) |&gt;\n  ungroup() |&gt;\n  ggplot(aes(x = Team, y = Mean)) + \n  geom_col() +\n  labs(title = \"Mean Freestyle Swim Time\", y = \"Seconds\")\n\n`summarise()` has grouped output by 'Team'. You can override using the\n`.groups` argument.\n\n\n\n\n\nCompared with the count data, the means are simply point estimates of the central tendency for sample data which are often used in service of estimating unknown population parameters. This is why a mean is called a point estimate as it estimate a single value, or point, of a distribution. Plotting means does not provide information about variability in the sample data or in the uncertainty around the mean’s ability to estimate the sample’s center generally and more specifically its corresponding population parameter."
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#visualizing-variability",
    "href": "modules/18_visualizing_uncertainty.html#visualizing-variability",
    "title": "Visualizing uncertainty",
    "section": "Visualizing Variability",
    "text": "Visualizing Variability\nWhereas point estimates provide statistical information about central tendency and are represented visually using points, bars, or boxes, interval estimates and dispersion measures like standard deviations, standard errors of the mean, confidence intervals, etc. are represented using vertical lines, crossbars, or error bars. {ggplot2} has four geoms for visualizing statistical measures of variability: geom_crossbar(), geom_errorbar(), geom_linerange(), geom_pointrange(). Note: Legends may be hidden for illustrative purposes.\n\nA descriptives() function\nIn order to create some visualizations, we will first summarize the data and then create a base plot to overlay different metrics for examples. We could use group_by(), summarize(), and ungroup() but you can always create your own functions to perform these redundant operations.\nIn order to summarize the data, we will use a custom function I wrote and named descriptives(), which serves as a “Offiziersmesser” (“officer’s knife”, aka Swiss Army Knife), type function for descriptive statistics. This function takes a vector or a data frame and returns the n, mean, trimmed mean, median, standard deviation, standard error, skewness, kurtosis, sum, minimum, maximum, range, interquartile range, median absolute deviation, and confidence interval values for a numeric vector. Both trim and conf can be adjusted as needed.\nWe will also calculate the range of years in order to facilitate the axis scale. And we will also make a simple function to cycle though some colors for making the points in the adjacent years easier to distinguish. We only need to colors for contrasting adjacent years,\nHow does descriptives() work? There are there parts.\n\ndata: the data object, which can be a vector or a data frame/tibble\ngroupby: the grouping parameter leveraging group_by()\nvar: the outcome variable vector for describing statistically\n\nYou can source the function this way:\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/dataviz23/main/R/functions/describe.R\")\n\nDefining describe.R\n\n\nDone Defining describe.R\n\n\nLet’s get the descriptives() for the SWIM data, grouped by Team and Event for Time.\n\ndescriptives(data = SWIM, \n             groupby = c(Team, Event), \n             var = Time\n             )\n\n# A tibble: 12 × 23\n   Team  Event           n  mean mean.trim   mdn smallest_mode modefreq modeprop\n   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;    &lt;dbl&gt;\n 1 Men   Backstroke      7  90.6      90.6 110.  53.95                1   0.143 \n 2 Men   Breaststro…    11  84.2      82.2  59.4 55.17                1   0.0909\n 3 Men   Butterfly      15  65.6      62.3  52.4 49.66                1   0.0667\n 4 Men   Freestyle      40  81.2      68.3  49.8 21.34                1   0.025 \n 5 Men   IM             10 131.      119.  120.  112.33               1   0.1   \n 6 Mixed Freestyle      15  94.0      93.9  93.5 88.14                1   0.0667\n 7 Mixed Medley         15 104.      104.  104.  97.74                1   0.0667\n 8 Women Backstroke      8 106.      106.  129.  62.81                1   0.125 \n 9 Women Breaststro…     8 108.      108.  109.  62.44                1   0.125 \n10 Women Butterfly      12  89.3      87.6  62.3 57.29                1   0.0833\n11 Women Freestyle      47 142.       92.9 113.  24.16                1   0.0213\n12 Women IM             13 155.      146.  133.  127.94               1   0.0769\n# ℹ 14 more variables: sd &lt;dbl&gt;, se &lt;dbl&gt;, skew &lt;dbl&gt;, kurt &lt;dbl&gt;, min &lt;dbl&gt;,\n#   max &lt;dbl&gt;, range &lt;dbl&gt;, iqr &lt;dbl&gt;, mad &lt;dbl&gt;, sum &lt;dbl&gt;, ci.95l &lt;dbl&gt;,\n#   ci.95u &lt;dbl&gt;, ci.99l &lt;dbl&gt;, ci.99u &lt;dbl&gt;\n\n\nAll metrics are lowercase, so if passing the returned object to ggplot(), we can plot the data by mapping mapping = aes(x = Team, y = mean).\n\ndescriptives(SWIM, groupby = c(Team, Event), var = Time) |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  group_by(Team) |&gt;\n  ggplot(mapping = aes(x = Team, y = mean)\n         ) + \n  geom_col() +\n  labs(title = \"Mean Freestyle Swim Time\", y = \"Seconds\")\n\n\n\n\nLet’s assign the returned descriptive statistics to an object for future plots.\n\nSWIM_summary &lt;- descriptives(SWIM, groupby = c(Team, Event), var = Time)\n\nFor the base plot, the one thing that we will want to ensure is to map y = mean and x = Event from the summarized data frame. Keep in mind that the variables from descriptives() are lowercase. We will, however, map other variables to aesthetics as well and in later specific geom_*()s.\nmapping = aes(x = Event, \n              y = mean, \n              fill = Team,\n              col = Team,\n              shape = Team\n              )\n\nswim_base_plot &lt;- SWIM_summary %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       y = mean, \n                       fill = Team,\n                       col = Team,\n                       shape = Team\n                       )\n         )+\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\ngeom_pointrange():\nA geom_pointrange() is quite simply a combination of a geom_point() and a geom_line(). It also provides more detail than a geom_linerange(), which is just a line connecting two points. For both geoms, you will need to specify where the line along the y axis starts and where it ends by mapping variables to ymin and ymax. For these examples, the values will be obtained using descriptives() but you could use {{dplyr}} to subset and summarize the data too. If you want to map other aes()thetics, for example, shape or color, you can do that as well.\ngeom_pointrange(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  ...,\n  fatten = 4,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\ngeom_pointrange() with standard deviation\n\nswim_base_plot + \n  geom_pointrange(mapping = aes(ymin = mean - sd, \n                                ymax = mean + sd\n                                ),\n                  position = position_dodge2(width = 1),\n                  alpha = .8\n                  )\n\n\n\n\nOne positioning issue that you will experience with geom_point() or geom_pointrange() relates to mapping a third variable to col, fill, or shape which were all mapped to Team. You have seen points plotted with these aesthetics before and addressed overplotting before by jittering them. When using geom_pointrange(), you can immediately notice a similar challenge; the points corresponding to the same x-axis position may have overlapping error variability lines. Because the lines are so thin, adjusting opacity will not really fix the problem.\n\nswim_base_plot + \n  geom_pointrange(mapping = aes(ymin = mean - sd, \n                                ymax = mean + sd\n                                ),\n                  position = position_dodge2(width = 1),\n                  alpha = .8\n                  )\n\n\n\n\nAdjusting positioning using position = position_jitter() will move the change point position but will do so that will be inconsistent across the x variable, whether categorical or numeric creating asymmetrical positioning.\n\nswim_base_plot + \n  geom_pointrange(mapping = aes(ymin = mean - sd, \n                                ymax = mean + sd\n                                ),\n                  alpha = .8,\n                  position = position_jitter()\n                  )\n\n\n\n\nThe problem is that jitter functions apply a random jittering for each level of x here. Setting the seed for the process will ensure consistency every function call but will not ensure consistency across each level of the x variable as seen in the plot.\nWhen you really just want the points be get out of each others way, you can use position = position_dodge2() to make the points dodge side-to-side from the central positioning in a symmetrical manner. position_dodge2() relative to position_dodge() also does not require a group to be defined in the geom_*() or the global ggplot() object. However, you will likely need to set width to a value of 1 or less when your x variable is categorical in order to avoid something unappealing. Here are some examples.\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(\n  \n      swim_base_plot + \n        geom_pointrange(mapping = aes(ymin = mean - sd, \n                                      ymax = mean + sd\n                                      ),\n                        alpha = .8,\n                        position = position_dodge2(width = 2)\n                        ) +\n  labs(title = \"position_dodge2(width = 2)\",\n       tag = \"A\"),\n  \n  swim_base_plot + \n    geom_pointrange(mapping = aes(ymin = mean - sd, \n                                  ymax = mean + sd,\n                                  col = Team),\n                    alpha = .8,\n                    position = position_dodge2(width = 1)\n                    ) +\n    labs(title = \"position_dodge2(width = 1)\", tag = \"B\"),\n  \n  swim_base_plot + \n    geom_pointrange(mapping = aes(ymin = mean - sd, \n                                  ymax = mean + sd,\n                                  col = Team),\n                    alpha = .8,\n                    position = position_dodge2(width = .5)\n                    ) +\n    labs(title = \"position_dodge2(width = .5)\", tag = \"C\"),\n  \n  swim_base_plot + \n    geom_pointrange(mapping = aes(ymin = mean - sd, \n                                  ymax = mean + sd,\n                                  col = Team),\n                  alpha = .8,\n                  position = position_dodge2(width = .25)\n                  ) +\n    labs(title = \"position_dodge2(width = .25)\", tag = \"D\"),\n  \n  ncol = 2\n)))\n\n\n\n\nPlot A will not achieve the dodge you desire and something something too small may not lead to enough change in position. Plot Β solves the issue but is challenged by the Gestalt perceptional grouping principle of proximity. If you are curious about these principles in UX design Nielsen Norman Group also has a post on this issue. The dodging associated with width = 1 does not facilitate the grouping of Team at each level of Event because the spacing between Teams for each event is the same as the spacing of Teams across Events. Reduce the dodge so that proximity grouping facilitates plot perception and interpretation. Keep in mind that plot aspect ratios (see here) can also affect positioning and proximity in some cases.\n\n\ngeom_pointrange() with standard error\n\n\ngeom_pointrange() with confidence intervals\n\nswim_base_plot + \n  geom_pointrange(mapping = aes(ymin = ci.99l, \n                                ymax = ci.99u\n                                ),\n                  linewidth = .7,  # make the line more prominent\n                  position = position_dodge2(width = .5)\n  ) +\n  coord_flip() +\n  labs(title = \"Mean Times for Stags and Athenas by Event\",\n       caption = \"lines represent 99% confidence intervals\\ncircle = Athena\"\n       )   \n\n\n\n\n\n\n\ngeom_linerange():\nA geom_linerange() simply visualizes a line plot that starts at one value and ends at another value.\ngeom_linerange(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\ngeom_linerange() with min and max\n\nswim_base_plot + \n  geom_linerange(mapping = aes(ymin = min, \n                               ymax = max\n                               ),\n                 linewidth = 1  # make the line more prominent\n                 )\n\n\n\n\nSuch a visualization shows clearly where the data start and stop and allow for comparisons. You can also see when data were missing for Events. Out of the box, the bars will overlap, which will require some adjustment.\n\n\ngeom_linerange() with confidence intervals\n\nswim_base_plot + \n  geom_linerange(mapping = aes(ymin = ci.99l, \n                               ymax = ci.99u\n                               ),\n                 linewidth = 1,\n                 position = position_dodge2(width = .5)\n                 ) +\n  coord_flip() +\n  labs(title = \"Mean Times for Stags and Athenas by Event\",\n       caption = \"lines represent standard errors of the mean\\nred = Athena\"\n       )   \n\n\n\n\nCompared with geom_pointrange(), geom_linerange() only creates a perceptual grouping based on color. Because there are no points to plot, you cannot also change the shape of the points in order to make the grouping of Team redundant with color and point shape. Redundant encoding is something we will address in another module on designing perceptually-efficient visualizations). If you wish to achieve this redundancy, you will need to vary the lintetype. You can map the aesthetic to Team, set it specifically with scale_linetype_manual(), or code the line type into the data frame and use scale_linetype_identity(). You can specify linetype by name or by number: 0 (“blank”), 1 (“solid”), 2 (“dashed”), 3, 4, 5, 6, etc. When passing values in scale_linetype_manual(), keep in mind this is a vector and vectors can be numeric or character but not both so you cannot mix numbers and strings for line types.\nFor more on line type, read here\n\nswim_base_plot + \n  geom_linerange(mapping = aes(ymin = ci.99l, \n                               ymax = ci.99u,\n                               linetype = Team\n                               ),\n                 linewidth = 1,\n                 position = position_dodge2(width = .5)\n                 ) +\n  scale_linetype_manual(values = c(Men = \"dotted\", Women = \"longdash\", Mixed = \"solid\")) +\n  coord_flip() +\n  \n  labs(title = \"Mean Times for Stags and Athenas by Event\",\n       caption = \"lines represent standard errors of the mean\\nred = Athena\"\n       )   \n\n\n\n\n\n\n\ngeom_errorbar():\nError bars are likely the most familiar visual form of of uncertainty you see in data visualization. Error bars represent the measurable error associated with data cases deviating from the distribution’s mean and is most typically the standard error of the mean. Without delving too deeply into concepts of statistics, the standard error of the mean is calculated as standard deviation / square root of the sample size. Although there are libraries like {plotrix} containing functions for it, its calculation is so simple you don’t need to bother with external libraries.\nThe describe() function calculates the standard error of the mean as se.\ngeom_errorbar() will require setting the ymin and ymax values for the error bars. Because the se reflects error around the mean, we will need to add and subtract the se to and from the mean in order to determine its upper and lower limits.\n\ngeom_errorbar() with standard error\n\nswim_base_plot + \n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              )\n                )\n\n\n\n\nOut of the box, the bars will overlap and they will can been quite large, thus requiring some adjustment. We will position_dodge2() the bars to prevent overlapping, change the linewidth to be more prominent.\n\nswim_base_plot + \n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              ),\n                position = position_dodge2(),\n                linewidth = .7,\n                width = .3       # make the horizontal bars shorter\n  )\n\n\n\n\n\n\ngeom_errorbar() with confidence intervals\n\nswim_base_plot + \n  geom_errorbar(mapping = aes(ymin = ci.99l, \n                              ymax = ci.99u\n                              ),\n                position = position_dodge2(),\n                linewidth = .7, \n                width = .3       # make the horizontal bars shorter\n  )\n\n\n\n\nBefore even adding error bars, this geom_col() represents an excellent example of a pesky problem with out-of-the-box plots containing missing data. In any given data set, you might not have perfectly tidy data frames with data for all variable x variable combinations. For example, you might have data on the number of steps you walk during the morning and the afternoon (two levels of a time factor) for every day of the week (7 measures of another time variable) and you would have 2 x 7 = 14 bars to present in a plot. But if on Saturdays you sleep in past noon, you never have any data for the morning on Saturdays and you will have only 13 bars for your plot.\nThe above plot illustrates what geom_col() does when you have this data imbalance. When both bars are missing, you will see an empty space on the plot. You see that for 2021. But when only half the data are present, a single bar usurps the space of two bars.\n\n\n*Making bars the same width**\nWhen you read the docs for position_dodge() or position_dodge2(), you see that you can set a preserve argument (e.g., “should dodging preserve the”total” width of all elements at a position, or the width of a “single” element?“). Clearly, we want to fix the width using preserve = \"single\". The way that position_dodge() and position_dodge2() handle this aesthetically differs so we can use both for comparison. You can decide what looks better for your own plots.\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(\n    swim_base_plot + \n      geom_col(position = position_dodge(preserve = \"single\")) +\n      labs(title = 'position_dodge(preserve = \"single\"))',\n           tag = \"A\"\n           ),\n    swim_base_plot +\n      geom_col(position = position_dodge2(preserve = \"single\")) +\n      labs(title = 'position_dodge2(preserve = \"single\"))',\n           tag = \"B\"\n           ),\n    ncol = 1\n  )))\n\n\n\n\nThe bars are now all the same width. For position_dodge2(), the single bar is center-aligned whereas position_dodge() aligns it to the left. position_dodge2() seems like a better option.\n\n\nAdd the error bars using geom_errorbar():\nWe now will add the error bars to the plot. Just as we did for geom_linerange(), we will map the ymin and ymax to the for the line to terminate.\n\n\nBars with Standard Errors\n\nswim_base_plot +\n  geom_col(position = position_dodge2(preserve = \"single\")) +\n  scale_fill_manual(values = c(Women = \"firebrick\", \n                               Men = \"cornflowerblue\", \n                               Medley = \"grey60\"\n                               )\n                    ) +\n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              )\n                )\n\n\n\n\nOK, This is hideous! The error bars are not positioned with the bars and they are rather wide. To address the positioning, remember that we dodged the bars/columns, specifically using position_dodge2(preserve = \"single\"), so we need to similarly adjust the positioning for the error bars.\n\nswim_base_plot +\n  geom_col(position = position_dodge2(preserve = \"single\"),\n           alpha = .9,\n           col = \"grey50\"      # make the bar outline color the same and \n           ) +\n  scale_fill_manual(values = c(Women = \"firebrick\", \n                               Men = \"cornflowerblue\", \n                               Medley = \"grey60\"\n                               )\n                    ) +\n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              ),\n                position = position_dodge2(preserve = \"single\"),\n                col = \"black\",   # set them to all be the same color\n                linewidth = .6, \n                )\n\n\n\n\nJust remember that with multi-layered plots, the layers are added on top of existing ones. Starting with geom_errorbar() and then adding geom_col() will result in the lower portion of the error bars behind masked by the columns, especially if alpha = 1.\n\nswim_base_plot +\n  geom_col(position = position_dodge2(preserve = \"single\"),\n           alpha = 1,\n           col = \"grey50\"      # make the bar outline color the same and \n           ) +\n  geom_errorbar(mapping = aes(ymin = mean - se, \n                              ymax = mean + se\n                              ),\n                position = position_dodge2(preserve = \"single\", width = 1),\n                col = \"black\",   # set them to all be the same color\n                linewidth = .6\n                ) +\n  scale_fill_manual(values = c(Women = \"firebrick\", \n                               Men = \"cornflowerblue\", \n                               Medley = \"grey60\"\n                               )\n                    )\n\n\n\n\n\n\n\nConfidence Intervals\nWe will create the same plot using confidence intervals.\n\nswim_base_plot +\n  geom_col(position = position_dodge2(preserve = \"single\"),\n           alpha = .8,\n           col = \"grey50\"      # make the bar outline color the same and \n           ) +\n  geom_errorbar(mapping = aes(ymin = ci.99l, \n                              ymax = ci.99u\n                              ),\n                position = position_dodge2(preserve = \"single\"),\n                col = \"black\",   # set them to all be the same color\n                linewidth = .6\n                ) +\n  scale_fill_manual(values = c(Women = \"firebrick\", \n                               Men = \"cornflowerblue\", \n                               Mixed = \"grey60\"\n                               )\n                    ) +\n  labs(title = \"Mean Time for Events in 2023\",\n       tag = \"\",\n       x = NULL, y = \"Seconds\",\n       caption = \"M = blue, F = red, Medley = grey\\nbars = 99% CI\"\n      )\n\n\n\n\nThe geom_pointrange() may likely be a better visualization of the data than the geom_errobar() paired with geom_col()."
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#model-uncertainty-using-a-table",
    "href": "modules/18_visualizing_uncertainty.html#model-uncertainty-using-a-table",
    "title": "Visualizing uncertainty",
    "section": "Model Uncertainty Using a Table",
    "text": "Model Uncertainty Using a Table\n\nlm.beta::lm.beta(fit) |&gt;\n  broom::tidy() |&gt;\n  knitr::kable(format = \"markdown\")\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd_estimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.0290832\nNA\n1.6497412\n-0.017629\n0.9860556\n\n\nSplit50\n2.0817834\n0.9857743\n0.0659113\n31.584599\n0.0000000\n\n\n\n\n\nThe tables contain the model coefficients to quantify elements like the linear relationship between the variables, the error or uncertainty in the model fit, etc. We can see that Split50 predicts the Time for the 100 Freestyle. The association is not perfect, however. There is some error, or uncertainty, in the model as indicated by the model std.error.\nConfidence Intervals for Model Fit\n\nconfint(fit) |&gt;\n  knitr::kable(format = \"markdown\")\n\n\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\n-3.403183\n3.345016\n\n\nSplit50\n1.946980\n2.216587\n\n\n\n\nlm.beta::lm.beta(fit) |&gt;\n  confint() |&gt;\n  knitr::kable(format = \"markdown\")\n\n\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\nNA\nNA\n\n\nSplit50\n0.8509705\n1.120578"
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#model-uncertainty-using-a-plot",
    "href": "modules/18_visualizing_uncertainty.html#model-uncertainty-using-a-plot",
    "title": "Visualizing uncertainty",
    "section": "Model Uncertainty Using a Plot",
    "text": "Model Uncertainty Using a Plot\nLet’s apply geom_smoth() to add a fit line.\n\nplot_lm &lt;- FREE_100 |&gt;\n  ggplot(mapping = aes(\n    x = Split50,\n    y = Time\n  )) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\", \n              fullrange = TRUE,\n              col = \"black\",\n              fill = \"firebrick\"\n              ) +\n  theme_light()\n\nplot_lm\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe can see the linear model fit as a line and the shaded area around that fit line indicates uncertainty of the model parameters. Because the model is not perfect, there is uncertainty about the true fit. Looking at ?geom_smooth, you will see the argument for level = 0.95 which helps define the uncertainty to visualize. Specifically, it defines the width of the shaded bands around the linear regression line in the plot. The bands represent the range within which the true regression line should lie given some degree of confidence. Thus, with level = 0.95, the confidence interval of 95%. We can see a different version by changing the level = .99 for a 99% confidence interval.\n\nplot_lm99 &lt;- FREE_100 |&gt;\n  ggplot(mapping = aes(\n    x = Split50,\n    y = Time\n  )) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\", \n              fullrange = TRUE,\n              col = \"black\",\n              fill = \"firebrick\",\n              level = .99\n              ) +\n  theme_light()\n\nplot_lm99\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe bands are wider now because they are more likely to capture the true population parameter predicted by the model. The bands can vary in width based on the number of data points contributing to the prediction of y at any given x value but the bands will be most narrow at the model centroid (the point corresponding to the mean of x and the mean of y). Mapping aesthetics to a new point will illustrate this. The model needs to pass through this point.\naes(x = mean(FREE_100$Split50), \n    y = mean(FREE_100$Time)\n    )\n\nplot_lm &lt;- FREE_100 |&gt;\n  ggplot(mapping = aes(\n    x = Split50,\n    y = Time\n  )) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\", \n              fullrange = TRUE,\n              col = \"black\",\n              fill = \"firebrick\"\n              ) +\n  theme_light() +\n  geom_point(aes(x = mean(FREE_100$Split50), \n                 y = mean(FREE_100$Time)\n             ),\n             size = 10, \n             shape = \"*\",\n             col = \"blue\"\n  )\n\nplot_lm\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe can remove the model error from the plot using se = FALSE but but doing so is not very honest communication.\n\nFREE_100 |&gt;\n  ggplot(mapping = aes(\n    x = Split50,\n    y = Time\n  )) +\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              fullrange = TRUE,\n              se = FALSE,\n              col = \"firebrick\"\n              ) +\n  theme_light()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nBut even if a linear model did fit the data perfectly, the set of coefficients obtained were from a single model and that single model is based on the athletes who participated in events. What would the model look like if it did not include just those athletes but instead includes athletes who were sick and sat the sidelines or those who could have been disqualified for some reason?"
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#bootstrap-models",
    "href": "modules/18_visualizing_uncertainty.html#bootstrap-models",
    "title": "Visualizing uncertainty",
    "section": "Bootstrap Models",
    "text": "Bootstrap Models\nrsample::bootstraps() will allow us to take samples from the full data set and run multiple models using various subsets of that full data set. Doing so will provide models that do not include best athletes, do not include worst athletes, include various mixtures, etc. The goal is not to teach bootstrapping methods but to help you understand how models are fit and how they differ, thus illuminating uncertainty in a different way than with geom_smooth(). The code is not provided as this just illustrates a plot of bootstrapped models.\nYou can see some bootstrapped mode coefficients here.\n\n\n# A tibble: 6 × 8\n  splits          id           model term  estimate std.error statistic  p.value\n  &lt;list&gt;          &lt;chr&gt;        &lt;lis&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 &lt;split [31/10]&gt; Bootstrap00… &lt;lm&gt;  (Int…    0.282    0.929      0.304 7.63e- 1\n2 &lt;split [31/10]&gt; Bootstrap00… &lt;lm&gt;  Spli…    2.06     0.0374    55.0   6.97e-31\n3 &lt;split [31/12]&gt; Bootstrap00… &lt;lm&gt;  (Int…   -0.644    1.32      -0.487 6.30e- 1\n4 &lt;split [31/12]&gt; Bootstrap00… &lt;lm&gt;  Spli…    2.10     0.0521    40.3   5.10e-27\n5 &lt;split [31/12]&gt; Bootstrap00… &lt;lm&gt;  (Int…   -0.142    1.33      -0.107 9.16e- 1\n6 &lt;split [31/12]&gt; Bootstrap00… &lt;lm&gt;  Spli…    2.08     0.0543    38.3   2.14e-26\n\n\nBecause there are more than one model, we can visualize distributions of the coefficients as a histogram.\n\n\n\n\n\nThe mean and the standard deviation of the bootstrapped models:\n\n\n\n\n\nterm\nestimate_mean\nestimate_sd\n\n\n\n\n(Intercept)\n-0.11\n1.39\n\n\nSplit50\n2.08\n0.06\n\n\n\n\n\nCompare the mean with the coefficient from the single model:\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.03\n1.65\n-0.02\n0.99\n\n\nSplit50\n2.08\n0.07\n31.58\n0.00\n\n\n\n\n\n\nPlotting Bootstrapped Model Fits (Variants)\n\n\n\n\n\nEach model fit is plotted as a very this light red line in the plot. In fact, there are 1000 different models fit through the points. Because each model includes a difference subset of athletes, the mean of the variables will differ based on the data used for each model. Thus, each model has its own centroid so there is no single point through which all models must pass. Nevertheless, you can see the most narrow part and darkest coloring (indicating more lines overlapping) of the band is located near the location of the original centroid. Also, upper right part of the plot is lighter than the lower left because there are fewer points in the upper right and thus there is corresponding uncertainty to visualize."
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#plotting-model-error-bars",
    "href": "modules/18_visualizing_uncertainty.html#plotting-model-error-bars",
    "title": "Visualizing uncertainty",
    "section": "Plotting Model Error Bars",
    "text": "Plotting Model Error Bars\nUsing {tidyr} we can create nested subsets of data using tidyr::nest() and then we can run models an each subset. We can group using .by and pass a vector of variable names for grouping. Make sure that you don’t have NAs in your data frames.\n\nnested &lt;- SWIM |&gt;\n  filter(!is.na(Time)) |&gt;\n  filter(!is.na(Split50)) |&gt;\n  filter(Distance &lt; 500) |&gt;\n  filter(Event != \"IM\") |&gt;\n  tidyr::nest(.by = c(Event, Distance))\n\nThe first instance is in data.\n\nnested$data[[1]]\n\n# A tibble: 14 × 8\n    Year School                    Team  Relay Name    Age  Time Split50\n   &lt;dbl&gt; &lt;chr&gt;                     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA  97.7    26.4\n 2  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 101.     24.4\n 3  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 102.     24.1\n 4  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 102.     25.0\n 5  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 103.     24.4\n 6  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 103.     27.5\n 7  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 104.     28.5\n 8  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 104.     26.8\n 9  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 104.     25.8\n10  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 104.     24.8\n11  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 105.     25.4\n12  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 106.     29.9\n13  2023 Claremont-Mudd-Scripps-CA Mixed Relay &lt;NA&gt;     NA 107.     30.4\n14  2023 Pomona-Pitzer-CA          Mixed Relay &lt;NA&gt;     NA 113.     30.9\n\n\nYou see we have a tibble that contains nested subsets of data. There are not much data for some events but the goal is only to show how to visualize model error. We will now us Base R lapply() to apply a function to a list. For each nested data frame, the data will be .x. The model fit is returned and\n\nSWIM |&gt;\n  filter(!is.na(Time)) |&gt;\n  filter(!is.na(Split50)) |&gt;\n  filter(Distance &lt; 500) |&gt;\n  filter(Event != \"IM\") |&gt;\n  tidyr::nest(.by = c(Event, Distance)) |&gt;\n  dplyr::mutate(models = lapply(X = data, \n                                FUN = function(x) lm(Time ~ Split50, data = x)\n                                )\n                )\n\n# A tibble: 9 × 4\n  Event        Distance data              models\n  &lt;chr&gt;           &lt;dbl&gt; &lt;list&gt;            &lt;list&gt;\n1 Medley            200 &lt;tibble [14 × 8]&gt; &lt;lm&gt;  \n2 Butterfly         100 &lt;tibble [19 × 8]&gt; &lt;lm&gt;  \n3 Freestyle         200 &lt;tibble [49 × 8]&gt; &lt;lm&gt;  \n4 Breaststroke      100 &lt;tibble [11 × 8]&gt; &lt;lm&gt;  \n5 Backstroke        100 &lt;tibble [6 × 8]&gt;  &lt;lm&gt;  \n6 Backstroke        200 &lt;tibble [9 × 8]&gt;  &lt;lm&gt;  \n7 Freestyle         100 &lt;tibble [31 × 8]&gt; &lt;lm&gt;  \n8 Breaststroke      200 &lt;tibble [8 × 8]&gt;  &lt;lm&gt;  \n9 Butterfly         200 &lt;tibble [8 × 8]&gt;  &lt;lm&gt;  \n\n\nGreat! We have a tibble of linear models for each Event and Distance pair. Using the {broom} library, perform some model cleaning using broom::tidy() to return a cleaned model and assign it as a column in the tibble. Using lapply, apply the broom::tidy() function on each model in the list. Finally, because the models are nested, tidyr::unest() them.\n\nnested &lt;- SWIM |&gt;\n  filter(!is.na(Time)) |&gt;\n  filter(!is.na(Split50)) |&gt;\n  filter(Distance &lt; 500) |&gt;\n  filter(Event != \"IM\") |&gt;\n  tidyr::nest(.by = c(Event, Distance)) |&gt;\n  dplyr::mutate(models = lapply(X = data, \n                                FUN = function(x) lm(Time ~ Split50, data = x)\n                                ),\n                tidy_mods = lapply(X = models, FUN = broom::tidy)\n                ) |&gt;\n  tidyr::unnest(cols = tidy_mods)\n\nThe tibble is messy, so let’s clean it up a bit by removing the intercept term. Also, we don’t need columns like models or data.\n\nnested &lt;- SWIM |&gt;\n  filter(!is.na(Time)) |&gt;\n  filter(!is.na(Split50)) |&gt;\n  filter(Distance &lt; 500) |&gt;\n  filter(Event != \"IM\") |&gt;\n  tidyr::nest(.by = c(Event, Distance)) |&gt;\n  dplyr::mutate(models = lapply(X = data, \n                                FUN = function(x) lm(Time ~ Split50, data = x)\n                                ),\n                tidy_mods = map(models, broom::tidy)\n                ) |&gt;\n  tidyr::unnest(cols = tidy_mods) |&gt;\n  filter(term != \"(Intercept)\") |&gt;\n  select(-c(models, data))\n  \n\nnested  \n\n# A tibble: 9 × 7\n  Event        Distance term    estimate std.error statistic  p.value\n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Medley            200 Split50     1.03    0.298       3.45 4.80e- 3\n2 Butterfly         100 Split50     1.98    0.0624     31.7  1.46e-16\n3 Freestyle         200 Split50     4.15    0.319      13.0  3.67e-17\n4 Breaststroke      100 Split50     2.15    0.0868     24.7  1.38e- 9\n5 Backstroke        100 Split50     1.69    0.0740     22.8  2.18e- 5\n6 Backstroke        200 Split50     4.27    0.348      12.3  5.43e- 6\n7 Freestyle         100 Split50     2.08    0.0659     31.6  5.16e-24\n8 Breaststroke      200 Split50     3.76    0.427       8.80 1.20e- 4\n9 Butterfly         200 Split50     3.94    0.960       4.10 6.35e- 3\n\n\nSo we now have a tibble with nested model coefficients. We can visualize some of the models and their errors. In the tibble, estimate is the estimate and std.error is the error. We can create a 95% confidence interval with lower and upper bounds by subtracting and adding 1.96*std.error (use 1.645 for 90% CI or 2.576 for a 99% CI). Map the color to the Distance column.\n\nnested |&gt;\n  mutate(Distance = as.character(Distance)) |&gt;\n  ggplot(mapping = aes(\n    x = Event, y = estimate,\n    ymin = estimate - 1.96*std.error,\n    ymax = estimate + 1.96*std.error,\n    col = Distance\n  )) +\n  geom_pointrange(position = position_dodge2(width = .5)\n  ) +\n  scale_y_continuous(n.breaks = 20) + \n  theme(legend.position = \"top\")\n\n\n\n\nUsing the {ggdist} and {distributional} libraries, we can plot the distributions of errors as well.\n\nnested |&gt;\n  mutate(Distance = as.character(Distance)) |&gt;\n  ggplot(mapping = aes(x = estimate, y = Event, col = Distance)) +\n  ggdist::stat_dist_halfeye(\n    mapping = aes(dist = distributional::dist_normal(\n      mu = estimate, \n      sigma = std.error)\n  ),\n  point_size = 3\n  )"
  },
  {
    "objectID": "modules/19_visualizing_trends.html",
    "href": "modules/19_visualizing_trends.html",
    "title": "Visualizing trends",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/19_visualizing_trends.html#readings",
    "href": "modules/19_visualizing_trends.html#readings",
    "title": "Visualizing trends",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing Trends\n\nOptional:\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Time series"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html",
    "href": "modules/20_legends_and_arrangement.html",
    "title": "Legends and arrangement",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#readings",
    "href": "modules/20_legends_and_arrangement.html#readings",
    "title": "Legends and arrangement",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Redundant coding"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#external-functions",
    "href": "modules/20_legends_and_arrangement.html#external-functions",
    "title": "Legends and arrangement",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#libraries",
    "href": "modules/20_legends_and_arrangement.html#libraries",
    "title": "Legends and arrangement",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting\n{forcats} 1.0.0: for factor reordering"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#load-libraries",
    "href": "modules/20_legends_and_arrangement.html#load-libraries",
    "title": "Legends and arrangement",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(forcats)"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#ggplot2guide_legend",
    "href": "modules/20_legends_and_arrangement.html#ggplot2guide_legend",
    "title": "Legends and arrangement",
    "section": "ggplot2::guide_legend()",
    "text": "ggplot2::guide_legend()\nguide_legend() is the go to function for customizing both the appearance and behavior of legends. For example, if the legends require some fine-tuning from their out-of-the-box behavior, you can override its behavior. The goal should be to improve the overall presentation in order to facilitate perception, interpretation, memory for, and decision-making about the data visualization representing the data.\nThere is much you can do with guide_legend():\nguide_legend(\n  title = waiver(),\n  title.position = NULL,\n  title.theme = NULL,\n  title.hjust = NULL,\n  title.vjust = NULL,\n  label = TRUE,\n  label.position = NULL,\n  label.theme = NULL,\n  label.hjust = NULL,\n  label.vjust = NULL,\n  keywidth = NULL,\n  keyheight = NULL,\n  direction = NULL,\n  default.unit = \"line\",\n  override.aes = list(),\n  nrow = NULL,\n  ncol = NULL,\n  byrow = FALSE,\n  reverse = FALSE,\n  order = 0,\n  ...\n)"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#ggplot2guides",
    "href": "modules/20_legends_and_arrangement.html#ggplot2guides",
    "title": "Legends and arrangement",
    "section": "ggplot2::guides()",
    "text": "ggplot2::guides()\nguides() can be used to set guides for each scale. The documentation explains also that the guides can be set for each scale individually using the guide argument, or en masse with guides(). For example, scale_shape(guide = \"legend\") will\nBecause the legend is also part of an overall plot theme, some legend adjustments can be made using ggplot2::theme()."
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#scale_aesthetic_type-functions",
    "href": "modules/20_legends_and_arrangement.html#scale_aesthetic_type-functions",
    "title": "Legends and arrangement",
    "section": "scale_<aesthetic>_<type>() functions",
    "text": "scale_&lt;aesthetic&gt;_&lt;type&gt;() functions\nGuides can be specified in each scale_&lt;aesthetic&gt;_&lt;type&gt;() function or more generally in guides(). As the {ggplot} documentation explains, guide = \"legend\" used inside a scale_&lt;aesthetic&gt;_&lt;type&gt;() , function is “syntactic sugar” for guide = guide_legend(). For example, scale_color_manual(guide = \"legend\") would achieve the same outcome as guides(col = guide_legend()). A benefit for the latter is that you may not need to remember the aesthetic and type of the variable mapped. In order to learn more about setting specific characteristics of each scale in more detail, review the documentation for guides()."
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#examining-base-plots-legend-elements",
    "href": "modules/20_legends_and_arrangement.html#examining-base-plots-legend-elements",
    "title": "Legends and arrangement",
    "section": "Examining Base Plots: Legend Elements",
    "text": "Examining Base Plots: Legend Elements\nIn the initial base plot, you can see that the Team variable mapped to the col aesthetic appears in the legend positioned to the right of the plot. There is a title, which inherently takes on the name of the column variable in the data frame. There are keys, which inherently take on the values of the variations (e.g., levels). If the variable mapped to the aesthetic is a constant, or has no variation or levels within its vector, the legend will nevertheless appear but will present only a single key. In such instances, a legend likely has little to no perceptual utility and should either be removed from the plot and/or be set manually using one of the scale_&lt;aesthetic&gt;_manual() functions.\nIn the additional base plots, legends again appear to the right of the plot. There are titles for each legend as well as their keys. When there is more than one legend, legends are ordered positionally."
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#removing-a-legend",
    "href": "modules/20_legends_and_arrangement.html#removing-a-legend",
    "title": "Legends and arrangement",
    "section": "Removing a Legend",
    "text": "Removing a Legend\nThe most crude way to change a legend position is to remove it completely from the visualization. Although the plots have more than one key in their legend, which add some perceptual utility, there may be instances where you would wish to remove the plot completely. For instance, perhaps you use direct labeling, annotation, or some other detail that obviate the legend’s utility.\n\nUsing theme() with a single legend:\n\nbase_plot + theme(legend.position = \"none\")\n\n\n\n\n\n\nUsing theme() with multiple legends:\nWhen there is more than one legend, all legends will be removed when set to legend.position = \"none\".\n\nbase_plot_2 + theme(legend.position = \"none\")\n\n\n\n\n\n\nUsing guides() with a single legend:\nguides(&lt;aesthetic&gt; = \"none\")\nThe guides() function allows you to change many legend properties. Although the syntax is a little bit more complicated, guides() along with helper function guide_legend() used to control the legend guide may provide greater flexibility in the long run.\nBecause the plot contains a variable mapping to col, the legend can also be removed using guides() and either set the aesthetic element to \"none\" or FALSE. As you will see with other functions, however, FALSE may be deprecated. In addition, although in many examples you will see the aesthetic referenced by its full name color, using its abbreviated name col will achieve the same outcome. For this purpose, my examples in this module will use the abbreviated form so that it matches that which I use in mapping = aes().\n\nbase_plot + guides(col = \"none\")\n\n\n\n# or base_plot + guides(col = FALSE)\n\n# or base_plot + guides(color = \"none\") will also work\n\n\n\nUsing guides() with a multiple legends:\nWith Plot 2, there is both col and size, so we would specify one or both.\nRemove the color legend:\n\nbase_plot_2 + guides(col = \"none\")\n\n\n\n# or base_plot_2 + guides(col = FALSE)\n\nRemove the size legend:\n\nbase_plot_2 + guides(size = \"none\")\n\n\n\n\nRemove both legends:\n\nbase_plot_2 + guides(col = \"none\", \n                     size = FALSE\n                     )\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\n\n\nUsing scale_&lt;aesthetic&gt;_&lt;type&gt;() with a single legend:\nWhen using scale_*() functions, you need to set guide = \"none\" as the use of FALSE has been deprecated.\nRemove the color legend:\n\nbase_plot +\n  scale_color_discrete(guide = \"none\")\n\n\n\n\nRemove the size legend:\n\nbase_plot +\n  scale_size(guide = \"none\")\n\n\n\n\nRemove both legends:\n\nbase_plot_2 +\n  scale_color_discrete(guide = \"none\") +\n  scale_size(guide = \"none\")\n\n\n\n\nWhen using specific scale_&lt;aesthetic&gt;_&lt;type&gt;() functions, however, you must ensure that they are applied according to their aesthetic and type or that functions assuming a particular aesthetic and type (e.g., scale_color_gradient()) adhere to the aesthetic and type defined in the plot object. For example, because the variable type is discrete, scale_color_manual(guide = \"legend\"), scale_color_continuous(guide = \"legend\"), scale_color_binned(guide = \"legend\") and some others will throw errors although scale_color_hue(guide = \"legend\"), scale_color_brewer(guide = \"legend\") will not throw errors. You just need to remember that your functions need to match the aesthetic and type already used in the plot object. this"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#repositioning-legends-right-left-top-bottom",
    "href": "modules/20_legends_and_arrangement.html#repositioning-legends-right-left-top-bottom",
    "title": "Legends and arrangement",
    "section": "Repositioning Legends (Right, Left, Top, Bottom)",
    "text": "Repositioning Legends (Right, Left, Top, Bottom)\nThe default position is \"right\". Changing the spatial positioning of the legend can be achieved using the same theme() function and by setting the legend.position argument to \"left\", \"top\", \"bottom\". Only some of these position modifications will be illustrated here. You can also achieve this using the guides() and guide_legend() combination illustrated earlier.\n\nUsing theme() with a single legend:\n\nbase_plot +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nUsing theme() with multiple legends:\n\nbase_plot_2 +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#repositioning-legends-changing-their-spatial-order",
    "href": "modules/20_legends_and_arrangement.html#repositioning-legends-changing-their-spatial-order",
    "title": "Legends and arrangement",
    "section": "Repositioning Legends (Changing their Spatial Order)",
    "text": "Repositioning Legends (Changing their Spatial Order)\nWhen you have more than one legend, their ordering can be rearranged using guides() and by specifying an order within helper function guide_legend(). To control each legend specifically, remember the guide argument is the aesthetic itself as seen here.\nguides(&lt;aesthetic&gt; = guide_legend())\nguides(\n  col = guide_legend(),\n  fill = guide_legend(),\n  shape = guide_legend(),\n  size = guide_legend()\n  )"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#creating-a-complex-plot",
    "href": "modules/20_legends_and_arrangement.html#creating-a-complex-plot",
    "title": "Legends and arrangement",
    "section": "Creating a Complex Plot",
    "text": "Creating a Complex Plot\nWe will create a more complex plot to better illustrate reordering methods.\n\n(plot_complex &lt;- SWIM |&gt;\n  filter(Event %in% c(\"Breaststroke\", \"Backstroke\")) |&gt;\n  filter(Distance &lt;= 200) |&gt;\n  mutate(Distance = factor(Distance)) |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time,\n                       fill = Team,\n                       size = Time,\n                       col = Event,\n                       shape = Distance\n                       )\n         ) +\n  geom_point()\n)\n\n\n\n\nplot_complex contains four legends. The variables are ordered from top to bottom: Time, Event, Distance, and Team and the aesthetics are ordered: size, col, shape and fill. These orders indicated that legends do not appear arranged alphabetically by variable name or aesthetic. Rather than worry about how they are ordered by default, lets just concern ourselves with arranging the order to what we want.\n\nplot_complex\n\n\n\nplot_complex +\n  guides(\n    col = guide_legend(order = 1),\n    fill = guide_legend(order = 3),\n    shape = guide_legend(order = 2),\n    size = guide_legend(order = 4)\n  )\n\n\n\n\nThe numbers do not need to be sequential but rather just differ in magnitude.\n\nplot_complex +\n  guides(\n    col = guide_legend(order = 21),\n    fill = guide_legend(order = 1),\n    shape = guide_legend(order = 38),\n    size = guide_legend(order = 49)\n  )\n\n\n\n\nNote: If you wish to make changes to a legend corresponding to a continuous aesthetic like col (or color) may be, guide_legend() will not work. You will need to use guide_colorbar() as show here.\n\nSWIM |&gt;\n  filter(Event %in% c(\"Breaststroke\", \"Backstroke\")) |&gt;\n  filter(Distance &lt;= 200) |&gt;\n  mutate(Distance = factor(Distance)) |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time,\n                       fill = Team,\n                       size = Time,\n                       col = Time,\n                       shape = Distance\n                       )\n         ) +\n  geom_point() +\n  guides(\n    col = guide_colorbar(order = 1),\n    fill = guide_legend(order = 2),\n    shape = guide_legend(order = 3),\n    size = guide_legend(order = 4)\n  )"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#repositioning-legends-xy-coordinates",
    "href": "modules/20_legends_and_arrangement.html#repositioning-legends-xy-coordinates",
    "title": "Legends and arrangement",
    "section": "Repositioning Legends (xy Coordinates)",
    "text": "Repositioning Legends (xy Coordinates)\nIn addition to global positioning, you can have more direct control over the exact coordinates of the legend position if the gross location options are not appropriate. This type of repositioning is necessary when you want to position a legend in the site the plot itself rather than next to it.\nThe fine-grained tuning is achieved by specifying a two-element vector for the xy coordinates of the plot but not according to the x and y axis scales. Using four xy coordinate pairs, we can see that the plot ranged from 0,0 to 1,1 so our numeric values need to fall between 0 and 1 inclusive.\n\nsuppressWarnings(plot(gridExtra::arrangeGrob(\n  base_plot + \n    theme(legend.position = c(0, 0)) + \n    labs(title = \"legend.position = c(0, 0)\"),\n  \n  base_plot + \n    theme(legend.position = c(0, 1)) + \n    labs(title = \"legend.position = c(0, 1)\"),\n  \n  base_plot + \n    theme(legend.position = c(1, 0)) + \n    labs(title = \"legend.position = c(1, 0)\"),\n    \n  base_plot + \n    theme(legend.position = c(1, 1)) + \n    labs(title = \"legend.position = c(1, 1)\"),\n  ncol = 2\n  ))\n  )\n\n\n\n\nBy deduction, legend.position = c(.5, .5) will position the legend in the plot center.\n\nbase_plot + \n    theme(legend.position = c(.5, .5))\n\n\n\n\nWe can also place it more strategically someplace in the bottom right.\n\nbase_plot + \n    theme(legend.position = c(.8, .2))\n\n\n\n\nNote: Depending on the plot dimensions and the uniformity of the x and y axis scales, you may need to experiment a bit."
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#adjusting-legend-label-position",
    "href": "modules/20_legends_and_arrangement.html#adjusting-legend-label-position",
    "title": "Legends and arrangement",
    "section": "Adjusting Legend Label Position",
    "text": "Adjusting Legend Label Position\nThe text labels corresponding to the aesthetics can be rearranged by setting label.position to \"right\", \"left\", \"top\", \"bottom\" (e.g., guide_legend(label.position = \"top\")). You can also remove the labels using guides(col = guide_legend(label = FALSE)) although a color or shape seen in a plot without a corresponding label would be confusing.\n\nRemoving a Legend Labels\nguides(&lt;aesthetic&gt; = guide_legend(label = FALSE))\n\nbase_plot_2 +\n  guides(col = guide_legend(label = FALSE))\n\n\n\n\nBut what do the colors represent?\n\n\nChanging Legend Label Position\n\nsuppressWarnings(\n  plot(gridExtra::arrangeGrob(\n    base_plot_2 + \n      guides(col = guide_legend(label.position = \"right\")) + # default\n      labs(title = 'label.position = \"right\"', tag = \"A\"),\n    \n    base_plot_2 + \n      guides(col = guide_legend(label.position = \"left\")) +\n      labs(title = 'label.position = \"left\"', tag = \"B\"),\n    \n    base_plot_2 + \n      guides(col = guide_legend(label.position = \"top\")) +\n      labs(title = 'label.position = \"top\"', tag = \"C\"),\n    \n    base_plot_2 + \n      guides(col = guide_legend(label.position = \"bottom\")) +\n      labs(title = 'label.position = \"bottom\"', tag = \"D\"),\n    ncol = 2\n  ))\n) \n\n\n\n\n\n\nChanging the Labels Direction/Orientation\nLegend labels are often presented vertically when legends are placed to the right or left of the plot and presented horizontally when oriented to the top or bottom of the plot. You may with to change this detail.\n\nAdjusting generally using theme()\ntheme(legend.direction = \"\") will adjust all legends to be \"horizontal\" or \"vertical\" (default).\n\nbase_plot_2 + \n  theme(legend.direction = \"vertical\")\n\n\n\nbase_plot_2 + \n  theme(legend.direction = \"horizontal\")\n\n\n\n\n\n\nAdjusting specifically using guides() and `guide_legend()\nguides(&lt;aesthetic&gt; = guide_legend(direction = \"\"))\n\nbase_plot_2 + \n  guides(col = guide_legend(direction = \"vertical\"),\n         size = guide_legend(direction = \"horizontal\")\n         )\n\n\n\nbase_plot_2 + \n  guides(col = guide_legend(direction = \"horizontal\"),\n         size = guide_legend(direction = \"horizontal\")\n         )\n\n\n\n\n\n\nAdjusting the orientation and the location with theme() and guides():\n\nbase_plot_2 + \n  theme(legend.direction = \"horizontal\", \n        legend.position = \"bottom\"\n        )\n\n\n\nbase_plot_2 + \n  guides(col = guide_legend(direction = \"horizontal\"),\n         size = guide_legend(direction = \"horizontal\")\n         ) +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#comparing-legend-point-size-in-plots",
    "href": "modules/20_legends_and_arrangement.html#comparing-legend-point-size-in-plots",
    "title": "Legends and arrangement",
    "section": "Comparing Legend Point Size in Plots",
    "text": "Comparing Legend Point Size in Plots\nLet’s create some data visualizations in order to investigate the legend properties. One plot will reflect the default behavior of geom_point() adding a legend to a plot corresponding to the mapping a variable to the color aesthetic using col = Team. Another plot will map col = Team but also set size = 4. A final plot will map col = Team and map size = Team so the size will be determined by the geom.\n\nplot1 &lt;- SWIM %&gt;%\n  filter(Team != \"Mixed\",\n         Time &lt; 500\n         ) %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Time, y = Split50)) +\n  geom_point(aes(col = Team)) +\n  labs(title = \"default\",\n       tag = \"A\"\n       )\n\nplot2 &lt;- SWIM %&gt;%\n  filter(Team != \"Mixed\",\n         Time &lt; 500\n         ) %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Time, y = Split50)) +\n  geom_point(size = 4, aes(col = Team)) +\n  labs(title = \"size = 4\",\n       tag = \"B\"\n       )\n\nplot3 &lt;- SWIM %&gt;%\n  filter(Team != \"Mixed\",\n         Time &lt; 500\n         ) %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Time, y = Split50)) +\n  geom_point(aes(size = Team, col = Team)) + # note the warning: Using size for a discrete variable is not advised.\n  labs(title = \"aes(size = Team)\",\n       tag = \"C\"\n       )\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(plot1, plot2, plot3, ncol = 1)\n  )\n  \n)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\nRemoved 14 rows containing missing values (`geom_point()`).\n\n\nWarning: Using size for a discrete variable is not advised.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAll three plots contain legends but they differ in the rendering of point size. Plot A has the smallest circles and Plot C has variation in circle size because both col and size are mapped to the variable. Importantly, the point size in the legend and in the plot are the same and this characteristic is important mapping a variable to size. Mismatching point sizes between the plot and the legend would certainly be confusing. When size is a constant, however, changing their size in the legend can ease the processing demand. The point size on the legend may result in difficulty with seeing the color, even for those which normal color vision. You don’t want your audience to squint when you are given your talk or stare at the legend in an attempt to understand the color differences."
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#adjusting-keys-in-legends",
    "href": "modules/20_legends_and_arrangement.html#adjusting-keys-in-legends",
    "title": "Legends and arrangement",
    "section": "Adjusting Keys in Legends",
    "text": "Adjusting Keys in Legends\nFor various reasons, you may need to adjust the orientation, size, color, or some aesthetic property of legend keys in order to make plots more user friendly. We will work through some examples of these modifications using guide_legend() for a given aesthetic.\n\nReversing the Legend Keys\nIf your legend order can be reversed to solve a perceptual inconsistency, just reverse them. Reversing the order may be a solution to some problems and works easily when there are only two groups but such a simple fix may not work when there are three or more groups to label.\nguides(&lt;aesthetic&gt; = guide_legend(reverse = TRUE))\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(plot1, \n                           \n                           plot1 + labs(title = 'guides(col = guide_legend(reverse = TRUE))') + \n                             guides(col = guide_legend(reverse = TRUE)), \n                           ncol = 1\n                           )\n  )\n)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\nRemoved 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nOverriding Key size in Legends\nIn most cases, you simply want to make the legend colors more visible for your users. Either you want to increase the size of points that are potentially too small or decrease the size of points that are just too large. Remember that aesthetic properties are inherited from data. Legend properties are inherited from the aesthetic mappings of their geoms. The legend properties may, however, benefit from modifications. When you want to change the legend properties manually, you can use the guide() function and specify arguments with helper functions guide_legend().\nWe will use guides() along with guide_legend() in order to override aesthetics. The general behavior will be to add a layer to a plot object like that shown below.\nNote: The goal of these examples is to illustrate how to change the key characteristics, not how to make everything match.\nguides(\n     &lt;aesthetic&gt; = guide_legend(\n                       override.aes = list(\n                            &lt;same or other aesthetic&gt; = numeric or string value\n                            )\n                   )\n      )\n\n\nDealing with a Constant Key Size\nWhen the legend provide a key that corresponds to an aesthetic other than size, changing the size of them does not compromise the plot integrity. We will take a single plot and adjust the size in four ways. Some points will be smaller than the default and some larger.\nWe will use guides() along with guide_legend() in order to override the size aesthetic using override.aes = list(size = numeric value). Please note that point size is visibly present in default plots but not controlled by any coding. Importantly, remember that all aesthetics that you see in the plot (and some you don’t see because they are invisible) are controlled in some manner, whether by you the creator or by the developers of {ggplot2}. In the default case, size is controlled but by the developers default choices.\nguides(col = guide_legend(override.aes = list(size = numeric value)))\n\nsuppressWarnings(\n  plot(\n    gridExtra::arrangeGrob(plot1 + \n                             labs(title = 'guide_legend(override.aes = list(size = 1))',\n                                  tag = \"A\") +\n                             guides(col = guide_legend(override.aes = list(size = 1))), \n                           \n                           plot1 + \n                             labs(title = 'guide_legend(override.aes = list(size = 2))',\n                                  tag = \"B\") + \n                             guides(col = guide_legend(override.aes = list(size = 2))), \n                           \n                           plot1 + \n                             labs(title = 'guide_legend(override.aes = list(size = 3))',\n                                  tag = \"C\") + \n                             guides(col = guide_legend(override.aes = list(size = 3))),\n                           \n                           plot1 + \n                             labs(title = 'guide_legend(override.aes = list(size = 6))',\n                                  tag = \"A\") + \n                             guides(col = guide_legend(override.aes = list(size = 6))),\n                           ncol = 2)\n  )\n)\n\n\n\n\nWhich override do you like best? Which is most helpful for your client? Which legend strikes the best balance between the point points and the legend points?\nOf course, you really might wish to do something like reverse the legend labels as well by adding arguments.\n\nplot1 + \n  guides(col = guide_legend(override.aes = list(size = 3),\n                            reverse = TRUE\n                            )\n       ) +\n  labs(title = \"\", tag = \"\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nDealing with a Variable Key Size\nIf you do not like the size of the points and you are unsure what numeric value is associated with a shape, you can always control this yourself by adding a variable to the data frame and setting the scale_size_manual(). This way, you can adjust the legend size and ensure that the sizes in the legend correspond to the size in plot just as the default behavior works for a legend.\nHere we will mutate() a new variable using case_when() that specifies a numeric value to serve as the size of points for each Team. We will then override the size of the legend keys corresponding to the col aesthetic by passing a two-element vector containing the same values. In the event that we want to reuse these sizes (and prevent some errors), we will assign the values to a named vector that we will use in both places in the plot code.\n\nlegend_point_size &lt;- c(\"Men\" = 3, \"Women\" = 4.5)\n\nSWIM %&gt;%\n  filter(Team != \"Mixed\",\n         Time &lt; 500\n         ) |&gt;\n  mutate(TeamSize = case_when(\n    Team == \"Men\" ~ legend_point_size[1],\n    Team == \"Women\" ~ legend_point_size[2],\n    )) |&gt;\n  ggplot(mapping = aes(x = Time, y = Split50)) +\n  geom_point(aes(col = Team, size = TeamSize)) +\n  labs(title = \"default\",\n       tag = \" --- \"\n       ) +\n  scale_size_identity() +\n  guides(col = guide_legend(override.aes = list(size = legend_point_size)))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nYou could achieve the same plot by setting numeric values specifically as with the following:\nguides(col = guide_legend(override.aes = list(size = c(3, 4.5))))"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#overriding-other-aesthetics-of-legend-keys",
    "href": "modules/20_legends_and_arrangement.html#overriding-other-aesthetics-of-legend-keys",
    "title": "Legends and arrangement",
    "section": "Overriding other aesthetics of Legend Keys",
    "text": "Overriding other aesthetics of Legend Keys\nExamples:\nChange the shape, size, color, and alpha of the col aesthetic. Because there are two labels for the col aesthetic, we need to pass one value for a constant applied to all or a two-element vector if you wish for them to vary.\n\nbase_plot_3 +\n  guides(col  = guide_legend(override.aes = list(shape = 15,\n                                                 size = 4, \n                                                 col = c(\"firebrick\", \"goldenrod\"),\n                                                 alpha = .3\n                                                 ))\n        )\n\n\n\n\nChange the shape, size, color, fill, alpha, and stroke of the size aesthetic:\nBecause there are three labels for the size aesthetic, we need to pass three of each to vary.\n\nbase_plot_3 +\n  guides(size  = guide_legend(override.aes = list(shape = 22,\n                                                  size = c(2, 4, 6), \n                                                  col = c(\"cornflowerblue\", \n                                                          \"goldenrod\", \n                                                          \"firebrick\"\n                                                          ),\n                                                  fill = \"grey\",\n                                                  alpha = .6,\n                                                  stroke = 2\n                                                  ))\n        )"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#reordering-legend-labels",
    "href": "modules/20_legends_and_arrangement.html#reordering-legend-labels",
    "title": "Legends and arrangement",
    "section": "Reordering Legend Labels",
    "text": "Reordering Legend Labels\nLegend labels are presented in an order, whether from top to bottom or from left to right. We have discussed previously that legend labels are not always presented alphabetically. The order depends on the variable type. When variables are character vectors, they will be ordered alphabetically but if they are factors, they will be ordered based on their order, which will differ based on them being factors or ordered factors. Using unique(), we can see the unique levels.\n\nunique(SWIM$Team)\n\n[1] \"Mixed\" \"Women\" \"Men\"  \n\n\nThis is simply a character vector. When this type of Team variable is mapped to the aesthetic, the order of the labels in the legend do not map on to the spatial positioning of the data in the plot.\nMoreover, there are no levels to Team because character vectors don’t have level. Factors have levels so when we use alllevels() to examine the variables, we will see nothing is returned.\n\nlevels(SWIM$Team)\n\nNULL\n\n\nVectors that are factors will contain levels, so converting the vector will return its levels.\n\nlevels(factor(SWIM$Team))\n\n[1] \"Men\"   \"Mixed\" \"Women\"\n\n\nThe levels returned make the order parent: \"Men\", \"Mixed\", and \"Women\". When displayed in the legend, they will take on this order from top to bottom for the default legend orientation (e.g., \"right\"). This order will not address the the mismatch of the labels in the data. Including all three levels of the Team variable will make this mismatch more apparent. Such an arrangement will make cognitive processing of the visualization more challenging.\nHere is plot with three levels."
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#reordering-factor-levels-using-forcats",
    "href": "modules/20_legends_and_arrangement.html#reordering-factor-levels-using-forcats",
    "title": "Legends and arrangement",
    "section": "Reordering Factor Levels using {forcats}",
    "text": "Reordering Factor Levels using {forcats}\nOne of the easiest ways to ensure that the order to the legend labels matches that of the data presented in the plot when you are dealing with a categorical variable is to convert the vector to a factor and reorder it based on the data. The {forcats} library makes this task easy using two functions, using fct_reorder() and fct_reorder2().\nThe two functions will reorder a factor’s levels by sorting them based on another variable. The main difference between the two functions is that fct_reorder() will reorder based on a single dimension and is thus best for 1-dimensional displays whereas fct_reorder2() will reorder based on two dimensions and is best for 2-dimensional displays where the factor is mapped to a non-position aesthetic.\nIn order to see how the factor levels may be arranged based on the numeric variables for the scatter plot, we can use group_by() and summarize() the median, which is the default behavior of fct_reorder().\n\nSWIM |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n  group_by(Team) |&gt;\n  summarize(Time = median(Time)) |&gt;\n  ungroup() |&gt;\n  arrange(Time)\n\n# A tibble: 3 × 2\n  Team   Time\n  &lt;chr&gt; &lt;dbl&gt;\n1 Mixed  93.5\n2 Men   105. \n3 Women 119. \n\n\nThe means from fastest to slowest are \"Mixed\", \"Men\", and \"Women\".\n\nSWIM |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n  group_by(Team) |&gt;\n  summarize(Split50 = median(Split50)) |&gt;\n  ungroup() |&gt;\n  arrange(Split50)\n\n# A tibble: 3 × 2\n  Team  Split50\n  &lt;chr&gt;   &lt;dbl&gt;\n1 Mixed    22.7\n2 Men      24.5\n3 Women    27.6\n\n\nThe means for the split time at 50 m from fastest to slowest is again \"Mixed\", \"Men\", and \"Women\". We need to ensure that our plot legend is from top to bottom \"Women\", \"Men\", and \"Mixed\" or from left to right \"Mixed\", \"Men\", and \"Women\".\n\nComparing Plots with fct_reorder() and fct_reorder2()\nYou can reorder the vector in the data frame before passing to ggplot() or within the aes() mapping in the object. However, if you have multiple variable-aesthetic mappings to that variable, your more efficient approach will be to change in the data frame.\nSome key features of both functions:\n.f: the factor .x: the variable for reordering with fct_reorder() .x and .y: the variable(s) for reordering with fct_reorder2()\n\nUsing forcats::fct_reorder():\nAdjust the grouping of Team by Split50.\n\nSWIM |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n  mutate(Team = forcats::fct_reorder(.f = Team, \n                                     .x = Split50\n                                     )\n         ) |&gt;\n  pull(Team)\n\n [1] Women Women Women Women Women Women Women Women Women Women Women Women\n[13] Women Women Women Women Women Women Women Women Men   Men   Men   Men  \n[25] Men   Men   Men   Men   Men   Men   Men   Men   Men   Men   Mixed Mixed\n[37] Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed\n[49] Mixed\nLevels: Mixed Men Women\n\n\nNotice this order is \"Mixed\", \"Men\", and then \"Women\".\n\n\nUsing forcats::fct_reorder2():\nAdjust the grouping of Team by Time and Split50.\n\nSWIM |&gt;\n  filter(Event == \"Freestyle\") |&gt;\n  filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n  mutate(Team = forcats::fct_reorder2(.f = Team, \n                                      .x = Time, \n                                      .y = Split50\n                                      )\n         ) |&gt;\n  pull(Team)\n\n [1] Women Women Women Women Women Women Women Women Women Women Women Women\n[13] Women Women Women Women Women Women Women Women Men   Men   Men   Men  \n[25] Men   Men   Men   Men   Men   Men   Men   Men   Men   Men   Mixed Mixed\n[37] Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed Mixed\n[49] Mixed\nLevels: Women Men Mixed\n\n\nNotice this order is \"Women\", \"Men\", and then \"Mixed\". This ordering may appear odd because the mixed group is faster than men but this is outcome results from the fact that the Distance variable that is not accounted for in the data filtering. For illustration purposes, with our plot we don’t care about that. Nevertheless, the horizontal order would be good if the legend was positioned along the top/bottom. The vertical order is problematic unless we reverse it.\n\n\n\nPlotting and Comparing Reordering using fct_reorder() and fct_reorder2()\nWe will specify .f = Team and .x as Split50 and when used, .y = Time.\n\nPlotting with a Reordering by forcats::fct_reorder2():\n\nSWIM |&gt;\n   filter(Event == \"Freestyle\") |&gt;\n   filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n   mutate(Team = forcats::fct_reorder2(.f = Team, \n                                       .x = Split50, \n                                       .y = Time\n                                       )) |&gt; \n   ggplot(mapping = aes(x = Split50, \n                        y = Time,\n                        )\n          ) +\n   geom_point(mapping = aes(size = Time,\n                            shape = Team,\n                            fill = Team,\n                            col = Team\n                            ),\n              position = position_jitter(), \n              alpha = .7,\n              col = \"grey20\",\n              stroke = 1\n              ) +\n  scale_shape_manual(values = c(21, 22, 24)) +\n  guides(size = \"none\")\n\n\n\n\nWhen the legend is positioned to the right of the plot, the vertical positioning of the legend labels now matches the data.\nTo position the legend at the bottom of the plot, we get:\n\nSWIM |&gt;\n   filter(Event == \"Freestyle\") |&gt;\n   filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n   mutate(Team = forcats::fct_reorder2(.f = Team, \n                                       .x = Split50, \n                                       .y = Time\n                                       )) |&gt; \n   ggplot(mapping = aes(x = Split50, \n                        y = Time,\n                        )\n          ) +\n   geom_point(mapping = aes(size = Time,\n                            shape = Team,\n                            fill = Team,\n                            col = Team\n                            ),\n              position = position_jitter(), \n              alpha = .7,\n              col = \"grey20\",\n              stroke = 1\n              ) +\n  scale_shape_manual(values = c(21, 22, 24)) +\n  guides(size = \"none\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\nWhen the legend is positioned at the bottom, the horizontal positioning of the legend labels does not match the data. You can also change the .x and .y variables if necessary.\n\n\n\nPlotting with a Reordering by forcats::fct_reorder():\nfct_reorder() will reorder Team only by a single variable. You could choose either Split50 or Time.\n\nBar plots\nWhen you have a bar plot, reordering the factor will help arrange the data from lowest to highest, thus making the data more easy to perceive. When dealing with variables plotting a continuous and a discrete variable, use fct_reorder().\n\nSWIM |&gt;\n   filter(Event == \"Freestyle\") |&gt;\n   filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n   mutate(Team = forcats::fct_reorder(.f = Team, .x = Time)) |&gt; \n   ggplot(mapping = aes(x = Team, \n                        y = Time,\n                        )\n          ) +\n   geom_boxplot(mapping = aes(fill = Team))\n\n\n\n\nAlthough we have ordered the box plots, the legend is not in an order that matches the vertical ordering. If you want the legend labels oriented vertically, consider adjusting them using labels and breaks settings with scale_*_manual() functions. However, moving the legend to the bottom, top, or changing the direction to horizontal would suffice. You can also consider direct labeling of the plot.\n\nSWIM |&gt;\n   filter(Event == \"Freestyle\") |&gt;\n   filter(Time &gt;= 75 & Time &lt;= 150) |&gt;\n   mutate(Team = forcats::fct_reorder(.f = Team, .x = Time)) |&gt; \n   ggplot(mapping = aes(x = Team, \n                        y = Time,\n                        )\n          ) +\n   geom_boxplot(mapping = aes(fill = Team)) +\n   theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#reordering-the-labels-in-a-legend",
    "href": "modules/20_legends_and_arrangement.html#reordering-the-labels-in-a-legend",
    "title": "Legends and arrangement",
    "section": "Reordering the Labels in a Legend",
    "text": "Reordering the Labels in a Legend\nThis topics relates to creating perceptually-efficient data visualizations nevertheless we will address this topic. The legend information is supposed to support the data presented in a plot. Sometimes, however, the ordering of the labels in the legend compromises perceptual processing by the user.\nLet’s take another look at a plot. We will remove the size legend just to reduce confusion. Remember we can do this using guides(&lt;aesthetic&gt; = \"none\").\n\nbase_plot_3 + \n  guides(size = \"none\")\n\n\n\n\nIn this plot, the legend label order is opposite that of the data. Men are faster than Women so processing the fill and the shape aesthetics but the legend is arranged in the reversed order. There is no utility in ordering the labels in a way that increases the cognitive demand on the user. Not paying attention to such issues may result in your plots being less effective than is necessary. Although there are often desirable difficulties associated with increased cognitive effort, the trade off here is a misinterpretation of the plot.\nWhat can we do? Well, we already discussed changing the legend position by modifying legend.position. We can move the legend to the bottom (below the plot). By doing so, the left-right arrangement matches the location of the data along the x axis.\n\nbase_plot_3 + \n  guides(size = \"none\") +\n  theme(legend.position = \"bottom\") \n\n\n\n\nBut let’s say either we do not want to position a legend along the top or bottom or that doing so does not solve the problem. The more levels and labels there are, the more difficult this will be do achieve. We will need to rearrange the labels themselves.\n\nbase_plot_3 + \n  guides(size = \"none\") +\n  theme(legend.position = \"right\")"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#changing-legend-title-guides",
    "href": "modules/20_legends_and_arrangement.html#changing-legend-title-guides",
    "title": "Legends and arrangement",
    "section": "Changing Legend Title guides()",
    "text": "Changing Legend Title guides()\n\nsuppressMessages(\n  plot(\n    gridExtra::arrangeGrob(base_plot_3 + \n                             labs(title = 'default'),\n                           \n                           # fill only\n                           base_plot_3 + \n                             guides(fill = guide_legend(title = \"Teams\")) +\n                             labs(title = 'change fill only'),\n                           \n                           # fill, shape, col\n                           base_plot_3 + \n                             guides(fill = guide_legend(title = \"Teams\"),\n                                    shape = guide_legend(title = \"Teams\"),\n                                    col = guide_legend(title = \"Teams\"),\n                                    ) +\n                             labs(title = 'change col, fill, and shape'),\n                           \n                           ncol = 1\n    ))\n  )"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#changing-legend-title-position",
    "href": "modules/20_legends_and_arrangement.html#changing-legend-title-position",
    "title": "Legends and arrangement",
    "section": "Changing Legend Title Position",
    "text": "Changing Legend Title Position\nYou don’t need to change the title using labs(). Here, we change the title and title.position for the col aesthetic only within guide_legend(). Adding other aesthetic changes would be as simple as specifying them in guides().\n\nbase_plot_3 + guides(col = guide_legend(title = \"New Title\", \n                                        title.position = \"left\"\n                                       )\n                   )"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#changing-legend-direction-and-label-position",
    "href": "modules/20_legends_and_arrangement.html#changing-legend-direction-and-label-position",
    "title": "Legends and arrangement",
    "section": "Changing Legend Direction and Label Position",
    "text": "Changing Legend Direction and Label Position\nHere, we also change the direction and label.position for the col, size, and shape in guides().\n\nplot3 + guides(\n  # color aesthetic  \n  col = guide_legend(title = \"Color Title\",\n                     direction = \"horizontal\",\n                     title.position = \"bottom\",\n                     label.position = \"top\"\n                     ),\n  # the size dimension\n  size = guide_legend(title = \"Size Title\",\n                      direction = \"vertical\",\n                      title.position = \"top\",\n                      label.position = \"top\"\n                      ),\n    # the shape aesthetic (does not appear because point all all the same shape) \n    shape = guide_legend(\"Shape Title\")\n ) + \n  theme(legend.position = \"bottom\")\n\nWarning: Using size for a discrete variable is not advised.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWhether this outcome is appropriate is up for discussion. When you need to change such legend elements, however, the above examples will be helpful."
  },
  {
    "objectID": "modules/21_designing_perceptually_efficient_visualizations.html",
    "href": "modules/21_designing_perceptually_efficient_visualizations.html",
    "title": "Designing perceptually-efficient visualizations",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/21_designing_perceptually_efficient_visualizations.html#readings",
    "href": "modules/21_designing_perceptually_efficient_visualizations.html#readings",
    "title": "Designing perceptually-efficient visualizations",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nFranceroni et al. (2012). The Science of Visual Data Communication: What Works.\nXiong et a. (2023). Seeing What You Believe or Believing What You See? Belief Biases Correlation Estimation.\n\nOptional (for the intellectually curious): - Szafir et al. (2016). Four types of ensemble coding in data visualizations. - Xiong et al. (2021). Visual Arrangements of Bar Charts Influence Comparisons in Viewer Takeaways."
  },
  {
    "objectID": "modules/22_annotation_and_text.html",
    "href": "modules/22_annotation_and_text.html",
    "title": "Annotation and text",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#readings",
    "href": "modules/22_annotation_and_text.html#readings",
    "title": "Annotation and text",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Annotations"
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html",
    "href": "modules/23_multi_panel_plots_faceting.html",
    "title": "Multi-panel plots: Faceting",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#readings",
    "href": "modules/23_multi_panel_plots_faceting.html#readings",
    "title": "Multi-panel plots: Faceting",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Multi-panel figures\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Faceting"
  },
  {
    "objectID": "modules/24_attentional_control.html",
    "href": "modules/24_attentional_control.html",
    "title": "Attentional control",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/24_attentional_control.html#readings",
    "href": "modules/24_attentional_control.html#readings",
    "title": "Attentional control",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Balance the data and the context\nWilke (2019). Fundamentals of Data Visualization. Use larger axis labels\nAjani et al. (2022). Declutter and Focus: Empirically Evaluating Design Guidelines for Effective Data Communication"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html",
    "href": "modules/25_titles_captions_and_tables.html",
    "title": "Title, Captions, and Tables",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#readings",
    "href": "modules/25_titles_captions_and_tables.html#readings",
    "title": "Title, Captions, and Tables",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Titles, captions, and tables"
  },
  {
    "objectID": "modules/26_themes.html",
    "href": "modules/26_themes.html",
    "title": "Figure Design & Themes",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/26_themes.html#readings",
    "href": "modules/26_themes.html#readings",
    "title": "Figure Design & Themes",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Themes(https://ggplot2-book.org/themes)\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Extensions(https://ggplot2-book.org/extensions)"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html",
    "title": "Importing many delimited files into a single data frame",
    "section": "",
    "text": "{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{vroom}: 1.6.3: for reading many files\n\n\nlibrary(magrittr)"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html#libraries",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html#libraries",
    "title": "Importing many delimited files into a single data frame",
    "section": "",
    "text": "{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{vroom}: 1.6.3: for reading many files\n\n\nlibrary(magrittr)"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html#get-the-file-names-by-pattern",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html#get-the-file-names-by-pattern",
    "title": "Importing many delimited files into a single data frame",
    "section": "Get the File Names by Pattern",
    "text": "Get the File Names by Pattern\nLooking at the pattern of file names for field events, you see .csv file names containing patterns like “DT”, “HT”, “JT”, “LJ”, “PV”, “LJ”, “SP”, and “TJ”. Double check that you have all event name types. I would also recommend keeping events measured on a time scale separate from a distance scale.\nI will demonstrate the process with two field events. You can apply the logic for all events. We will use vroom::vroom() to take the file names (full names mind you), open them all up and combine them into a single data frame.\nLet’s start with field events like discus:\nWe will use some regular expressions, or regex, to help us. Because the data are named by year, we can limit the search to files that contain a 4-digit year \\\\d{4} so that you don’t also match any aggregated uber files that do not contain a year. Then, the dot star .* will help with filler patterns. In particular, . refers to any character (e.g,. digit, alpha character, or any other special character) and * means zero or more times, so this pattern will search for all files that start with 4 digits followed by anything in the name. Then, the _HT.csv pattern will restrict the search to files containing that exact character string. All together, you have a search for pattern = \"\\\\d{4}.*_DT.csv\". This will not return the file without the year.\n\nDT &lt;- list.files(here::here(\"data\", \"tfrrs\"), \n           pattern = \"\\\\d{4}.*_DT.csv\",\n           ignore.case = T,\n           full.names = T\n           ) %&gt;% \n  vroom::vroom(.)\n\nsaveRDS(DT, here::here(\"data\", \"tfrrs\", \"DT.Rds\"))\n\nNow how about hammer:\n\nHT &lt;- list.files(here::here(\"data\", \"tfrrs\"), \n           pattern = \"\\\\d{4}.*_HT.csv\",\n           full.names = T\n           ) %&gt;% \n  vroom::vroom(.)\n\nsaveRDS(HT, here::here(\"data\", \"tfrrs\", \"HT.Rds\"))"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html#get-the-event-files-and-combine",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html#get-the-event-files-and-combine",
    "title": "Importing many delimited files into a single data frame",
    "section": "Get the Event Files and Combine",
    "text": "Get the Event Files and Combine\nFor some events, the columns may differ, so you might get an error. If you review the names of columns and locate the pesky dplyr::select() columns that you do want. If you have not removed the data frame objects just pass those to dplyr::bind_rows(), which will add the rows of the second data frame below the first data frame so that you have a single data frame.\n\nFIELD &lt;- dplyr::bind_rows(DT, HT)"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html#save-data",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html#save-data",
    "title": "Importing many delimited files into a single data frame",
    "section": "Save Data",
    "text": "Save Data\nAnd then combine and write to an uber field event .csv or .Rds file.\n\nsaveRDS(FIELD, here::here(\"data\", \"tfrrs\", \"TFRRS_FIELD.Rds\"))"
  },
  {
    "objectID": "modules/index.html",
    "href": "modules/index.html",
    "title": "Modules",
    "section": "",
    "text": "This course consists of various content modules that introduce students to data visualization techniques using R. Techniques, however, should not be applied haphazardly but instead with respect to the biological and cognitive limitations of the user. The general principles of data visualization taught can be applied to programming languages other than R (e.g., Python, D3, etc.)."
  },
  {
    "objectID": "modules/index.html#module-structure",
    "href": "modules/index.html#module-structure",
    "title": "Modules",
    "section": "Module structure",
    "text": "Module structure\nIn general, modules will contain readings, additional resources, and weekly assignments.\nThe modules will be updated across the semester as needed. There are more modules on this course site because some modules provide other useful information. The names of the modules listed in the syllabus, however, do match the names in the module listing."
  },
  {
    "objectID": "project/02_project_team_roles.html",
    "href": "project/02_project_team_roles.html",
    "title": "Team membership and roles",
    "section": "",
    "text": "Project roles help streamline events, assist delegation, allow for some accountability, and reduce workload overlap. Project roles are designed to help keep the project organized and reduce confusion about what project elements team members are taking on. Team roles should be decided upon in a way that maximizes member ability so that task demands are equal across team members. These roles provide some guidelines but do not obviate members from contributing to and participating in other tasks subsumed under specific roles. In other words, when the Project Manager falls ill, another team member should step up to facilitate any necessary communication between the liaison of me. Likewise, the Coding Lead would step in to help the Writing Lead revise writing when necessary. Similarly, the Writing Lead or Project Manager should help the Coding Lead with organizing code when appropriate. All team members have have the same goal, which is to develop, code, and communicate the project to the liaison. All members will code, organize, and write and may take lead on sections with which they are most familiar or most qualified in addressing.\nIf the team decides to create roles different from those suggested below, please just let me know.\nSuggested Roles:\n\n\n\nCommunicating with course faculty and liaison(s);\nScheduling and reminding the team meetings and meetings with liaison;\nAssigning tasks to team members (with help from course professor is needed) and based on the project requirements;\nMonitoring and keeping track of each member’s project progress;\nMotivating the team members on their task completion and future goals;\nDealing with any conflicts within the team and updating any concerns with course professor;\nCoordinating team activities such as presentation dry runs;\nHelping maintain equity of tasks across all team members, inclusion the PM;\nThe Project Manager is not responsible to reminding team members to complete their tasks or complete worklogs.\n\n\n\n\n\n1 or 2 members\nPlanning, guiding, and leading report writing;\nDoing background/external research on topic as relevant;\nAssigning sections/chapters of documents to appropriate members;\nKeeping track of the written progress;\nHelping develop a data visualization story line;\nFormatting, text, images, inline code (R code embedded in text), and tables on final document (RMarkdown for final report);\nProofreading/editing deliverable documents like slide presentation, written report, etc.;\nThe Reporting Team is not responsible to all writing.\n\n\n\n\n\n1 or 2 members\nCreating and maintaining organization of the project code (e.g., directories, sourced scripts, etc.)\nLeading coding and code documenting;\nAssigning technical tasks to other team members;\nKeeping track of the progress of the technical tasks;\nHelping other team members troubleshoot code (see also TA and course professor);\nCommunicating with PM, liaison (during liaison meetings), and course professor regarding any technical needs and concerns;\nCommunicating with RL regarding messaging of coded results;\nMaintaining GitHub repo (recommended, please see course professor for assistance);\nThe Coding Team is not responsible for all coding.\n\nBased on abilities and interests of team members, the team should determine how many individuals to assign to a given role, or determine other appropriate roles given the abilities of the team members. There should be unanimity in these decisions. I will not assign you to roles."
  },
  {
    "objectID": "project/02_project_team_roles.html#team-roles",
    "href": "project/02_project_team_roles.html#team-roles",
    "title": "Team membership and roles",
    "section": "",
    "text": "Project roles help streamline events, assist delegation, allow for some accountability, and reduce workload overlap. Project roles are designed to help keep the project organized and reduce confusion about what project elements team members are taking on. Team roles should be decided upon in a way that maximizes member ability so that task demands are equal across team members. These roles provide some guidelines but do not obviate members from contributing to and participating in other tasks subsumed under specific roles. In other words, when the Project Manager falls ill, another team member should step up to facilitate any necessary communication between the liaison of me. Likewise, the Coding Lead would step in to help the Writing Lead revise writing when necessary. Similarly, the Writing Lead or Project Manager should help the Coding Lead with organizing code when appropriate. All team members have have the same goal, which is to develop, code, and communicate the project to the liaison. All members will code, organize, and write and may take lead on sections with which they are most familiar or most qualified in addressing.\nIf the team decides to create roles different from those suggested below, please just let me know.\nSuggested Roles:\n\n\n\nCommunicating with course faculty and liaison(s);\nScheduling and reminding the team meetings and meetings with liaison;\nAssigning tasks to team members (with help from course professor is needed) and based on the project requirements;\nMonitoring and keeping track of each member’s project progress;\nMotivating the team members on their task completion and future goals;\nDealing with any conflicts within the team and updating any concerns with course professor;\nCoordinating team activities such as presentation dry runs;\nHelping maintain equity of tasks across all team members, inclusion the PM;\nThe Project Manager is not responsible to reminding team members to complete their tasks or complete worklogs.\n\n\n\n\n\n1 or 2 members\nPlanning, guiding, and leading report writing;\nDoing background/external research on topic as relevant;\nAssigning sections/chapters of documents to appropriate members;\nKeeping track of the written progress;\nHelping develop a data visualization story line;\nFormatting, text, images, inline code (R code embedded in text), and tables on final document (RMarkdown for final report);\nProofreading/editing deliverable documents like slide presentation, written report, etc.;\nThe Reporting Team is not responsible to all writing.\n\n\n\n\n\n1 or 2 members\nCreating and maintaining organization of the project code (e.g., directories, sourced scripts, etc.)\nLeading coding and code documenting;\nAssigning technical tasks to other team members;\nKeeping track of the progress of the technical tasks;\nHelping other team members troubleshoot code (see also TA and course professor);\nCommunicating with PM, liaison (during liaison meetings), and course professor regarding any technical needs and concerns;\nCommunicating with RL regarding messaging of coded results;\nMaintaining GitHub repo (recommended, please see course professor for assistance);\nThe Coding Team is not responsible for all coding.\n\nBased on abilities and interests of team members, the team should determine how many individuals to assign to a given role, or determine other appropriate roles given the abilities of the team members. There should be unanimity in these decisions. I will not assign you to roles."
  },
  {
    "objectID": "project/04_project_midterm.html",
    "href": "project/04_project_midterm.html",
    "title": "Midterm presentation",
    "section": "",
    "text": "After having several weeks to investigate and examine your data, brainstorm potential key items to address, identify potential story lines, and create some data visualizations, the next step is to present to the class. You goal for the midterm presentation will be to present and discuss data visualizations, or variants thereof, that could find their way into the end-of-semester final presentation and report deliverable.\nYou will be evaluated on you and your team’s ability to convey the steps taken to clean up the data in service of creating some plots as well as share a decision-making journey of plot creation. Any variables that needed to be fixed or modified, factorized, computed anew, or summarized in some way can resulted in one single starting data frame/tibble and likely some smaller data summaries. Teams taking different approaches, or who are guided by liaisons who have different interests, will end up with different data, different data visualizations, and different stories. Include code where appropriate to communicate how you achieved your goals.\nAt this stage in the project, the important point is that all team members should be working with data, challenge themselves to think about data, and practice using {ggplot} for creating data visualizations. Thus, all team members must have two plots, even if those plots communicate detailed variants of the same performance metric. By plot variants, mean Same Data, Different Stories. Variant plots use the same data but are visualized differently in order to facilitate different comparisons, use additional date to provide a more nuanced or detailed interpretation, use different levels/grouping of exiting variables, or use a different scaling structures, etc. Alternatively, the two plots could visualize different metrics obtained from the data, different calculations of a metric, compare different calculations, etc. to represent depths to data inquiry.\nAn example of looking at the data in different ways is illustrated in Nathan Yau’s post One Dataset, Visualized 25 Ways. If you struggle to think about data, you can also check out his post on how to think like a statistician without the math. I believe that the most valuable comment is this post to in the Ask Why section. He explains that “…the most important thing I’ve learned, [is to] always ask why. When you see a blip in a graph, you should wonder why it’s there. If you find some correlation, you should think about whether or not it makes any sense. If it does make sense, then cool, but if not, dig deeper. Numbers are great, but you have to remember that when humans are involved, errors are always a possibility.” Asking why data are they way they are is important because patterns in data can happen by chance or for some systematic reason. Any systematic influence has to have a reason, an explanation for its presence. Although you may be able to describe a pattern or influence, if you cannot provide an explanation for it, there is no useful way to make that information actionable."
  },
  {
    "objectID": "project/04_project_midterm.html#data-cleaning-and-variable-creation",
    "href": "project/04_project_midterm.html#data-cleaning-and-variable-creation",
    "title": "Midterm presentation",
    "section": "Data Cleaning and Variable Creation",
    "text": "Data Cleaning and Variable Creation\nYou should communicate steps taken to clean data to fulfill sub-goals for different plots. I recommend sharing your code. The audience should understand the code and may have the capacity to identify errors.\n\nGeneral Data Cleaning\n\nCommunicate steps taken to clean data to fulfill sub-goals\nCommunicate how you modified variables and/or computed variables of interest\nCommunicate any usage of {dplyr} functions like group_by(), mutate(), filter(), ungroup(), or other functions from {stringr}, {tidyr} or otherwise for merging/joining, adding new variables, etc.\n\n\n\nData Summaries for Plots\n\nCommunicate how you calculated and/or obtained summary metrics\nCommunicate any usage of functions like group_by(), summarize(), filter(), or ungroup() to ensure your data are computed correctly"
  },
  {
    "objectID": "project/04_project_midterm.html#data-visualizations-story-telling-with-pictures",
    "href": "project/04_project_midterm.html#data-visualizations-story-telling-with-pictures",
    "title": "Midterm presentation",
    "section": "Data Visualizations: Story Telling with Pictures",
    "text": "Data Visualizations: Story Telling with Pictures\n\nConvey performance metrics using data visualizations\nWalk audience through an explanation of the visualizations\nConvey why you chose the data to plot and why you chose the plot to convey the data\nCommunicate plot limitations and intended amendments along with reasons why\n\nA plot is chosen as a visual aid for a talk, paper, news article, etc. for various reasons:\n\nwas the only plot created\nwas the only plot known how to create\nwas the best of several plots created\n\nEach data visualization must serve a goal for your audience. You should consider how you intend to talk about the visualization to your audience when you create it. If there are different ways to talk about the same data and more than one variant facilitates that communications, you may consider creating more than one.\nYou should stumble upon neither that goal nor the the geom type used to communicate that goal. Are you trying to communicate comparisons of some sort? If so, does the plot make that particular comparison easy?\n\nPlot Introduction\nBefore revealing your plot, set the stage for its intent. Use words. In your final report, you will be telling a story about the data. You will not just present plots and talk about them. For example, you make introduce a research question that the plot will either help answer or provide information about examining further. After walking the reader through the problem, you will reference a figure containing the plot. For the midterm presentation, you will similarly introduce a question that the plot will help address. Mention the data that the plot visualizes. Are these data minimums, maximums, means, medians, measures of variability, etc. Do the data represent groups of people? Do they include dates? Think of this step as a topic slide before presenting the plot. Your topic title should be brief and clear and you should fill in any more detail with words. This step will set the stage for the audience to understand what data you would be presenting before you throw a plot in their face.\n\n\nPlot Reveal and Explanation\nYou should make sure that you walk the reader through the data visualization. Be explicit about what the axes represent and what any aesthetics represent so that the audience does not have to figure this out. In other words, do not just present the plot and say “we can see there are differences in metric X across time”. Instead, say something more clear like: “This plot visualizes data about Event X for Group/Person/year Y. Along the horizontal axis is… a long the y axis is…. You can see that the average range of times/distances for Event X decreases as athletes’ move through class ranks (e.g, FR to SR). This pattern in the data suggests that…”. You get the point.\n\n\nPlot Discussion\nFor each plot you should:\n\nexplain why you selected this plot as the data visualization of choice to communicate the element of data being communicated\nincorporate information from readings about why you have chosen this plot type\nexplain what modifications you made to the plot (feel free to share code)\nexplain limitations that the plot contains\nshare your future goals to:\n\nreplace the plot with a completely new plot for reason X\nmodify it in one or various ways to solve limitation X, Y, and X\nleave plot as is/explain why the plot needs no work"
  },
  {
    "objectID": "project/04_project_midterm.html#data-cleaning-and-variable-creation-20-pts",
    "href": "project/04_project_midterm.html#data-cleaning-and-variable-creation-20-pts",
    "title": "Midterm presentation",
    "section": "Data Cleaning and Variable Creation (20 pts)",
    "text": "Data Cleaning and Variable Creation (20 pts)\n\nCommunicate steps taken to clean data to fulfill sub-goals\nCommunicate how you modified variables and/or computed variables of interest\nCommunicate any usage of functions to ensure your data are computed correctly\nCommunicate any aggregation methods and summary data frames per plot"
  },
  {
    "objectID": "project/04_project_midterm.html#data-visualizations-story-telling-with-pictures-40-pts",
    "href": "project/04_project_midterm.html#data-visualizations-story-telling-with-pictures-40-pts",
    "title": "Midterm presentation",
    "section": "Data Visualizations: Story Telling with Pictures (40 pts)",
    "text": "Data Visualizations: Story Telling with Pictures (40 pts)\n\nPlot Introduction (5 pts)\nPlot Reveal and Explanation (20 pts)\nPlot Discussion (15 pts)"
  },
  {
    "objectID": "project/04_project_midterm.html#presentation-characteristics-20-pts",
    "href": "project/04_project_midterm.html#presentation-characteristics-20-pts",
    "title": "Midterm presentation",
    "section": "Presentation Characteristics (20 pts)",
    "text": "Presentation Characteristics (20 pts)\n\nClarity (5pts): well-explained; easy to follow/understand; ability to communicate points effectively\nOrganization (5pts): structured logically; ability to walk audience through some story line or the a story about plot decision processes\nThoroughness (5pts): all relevant issues discussed thoroughly\nPresentation Style (5pts): degree of preparedness and polish in presentation; smooth and rehearsed; minimum of reading; well-paced; slide quality"
  },
  {
    "objectID": "project/04_project_midterm.html#team-and-team-member-evaluation-5-pts",
    "href": "project/04_project_midterm.html#team-and-team-member-evaluation-5-pts",
    "title": "Midterm presentation",
    "section": "Team and Team Member Evaluation (5 pts)",
    "text": "Team and Team Member Evaluation (5 pts)\n\nEvaluation of personal contributions toward the project as evaluated by other team members (claims partially validated using on-time weekly report submissions).\nThe audience (your client) will also provide an overall review for the team and individual team members."
  },
  {
    "objectID": "project/04_project_midterm.html#self-evaluation-5-pts",
    "href": "project/04_project_midterm.html#self-evaluation-5-pts",
    "title": "Midterm presentation",
    "section": "Self Evaluation (5 pts)",
    "text": "Self Evaluation (5 pts)\nEvaluation of your personal contributions toward the project as evaluated by yourself (claims partially validated using on-time weekly report submissions)."
  },
  {
    "objectID": "project/08_project_final.html",
    "href": "project/08_project_final.html",
    "title": "Final presentation",
    "section": "",
    "text": "Overview\nThe final written report for the project will be delivered to me and to your liaison. I can provide a color-printed copy for you to distrubtue to the liaison and for their offices.\n\n\nElements to Focus On\n\n\nPresentation Medium\nYou can use any slide-presentation tool you wish. You will just need to provide me with: * a printed version of the slide deck for class time and * an electronic pdf of the slide deck before or after the presentation.\n\n\nStakeholders\nIdentify the stakeholders for your project. For example, include you liaison, professor, athletic director, college, etc. for whom the final work will be submitted.\n\n\nEvaluation and Generalized Rubric\nMore detail will be added here similar to the Midterm Presentation.\n\nQuality of project deliverable documents (e.g., organization, coherence, story, coding clarity/organization, plots, etc.)\nProfessionalism (e.g., liaison meeting etiquette and responsibility, timely discord communication, non-tardy attendance at weekly team meeting, weekly worklogs, feedback from liaison, etc.)\nPeer evaluation (e.g., contributions, team player, etc.)\n\nNote: Liaison’s will also participate in evaluating all teams. The team with the most impressive project (e.g., most clear, most useful and actionable, most interesting, most thought provoking, etc.) will receive bonus points.\n\n\nPresentation Tips\nMay be moved to a new sidebar link due to redundancy with Midterm Presentation."
  },
  {
    "objectID": "project/10_project_report.html",
    "href": "project/10_project_report.html",
    "title": "Final report",
    "section": "",
    "text": "The final written report for the project will be delivered to me and to your liaison. I can provide a color-printed copy for you to distribute to the liaison and for their offices.\nThe final report is to be created in R Markdown and knit as a Pdf or Word document. An example starter file will be provided in the project repository. When working with a report file on GitHub, I recommend that you first pull down the fill from the repo, then add your content, push the changed file to the repo, and then close your file. If you leave the file open in RStudio and you pull down the changes made by your peers, you will wan to ensure that you reload/refresh the file so that when you push the changed file, it contains the previous changes.\nIf someone is familiar with LaTeX coding, Overleaf.com provides a way for collaborating without having to pull and push from GitHub."
  },
  {
    "objectID": "project/10_project_report.html#telling-a-story",
    "href": "project/10_project_report.html#telling-a-story",
    "title": "Overview",
    "section": "Telling a Story",
    "text": "Telling a Story"
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Project",
    "section": "",
    "text": "For the project, your team will write code in order to analyze data and create data visualizations in order to communicate a story that would address the question(s) proposed by the participating body about cognitive functioning. Given the constraints of data to inform this specific question, the project may involve data exploration to tell a story about relationships between variables.\nAny exploratory component allows for a healthy dose of flexibility in team creativity. This open element will also allow teams to develop ideas independently, thereby producing stories that will likely diverge wildly from each other, making the project an exciting foray into data storytelling for many students."
  },
  {
    "objectID": "project/index.html#project-description",
    "href": "project/index.html#project-description",
    "title": "Project",
    "section": "",
    "text": "For the project, your team will write code in order to analyze data and create data visualizations in order to communicate a story that would address the question(s) proposed by the participating body about cognitive functioning. Given the constraints of data to inform this specific question, the project may involve data exploration to tell a story about relationships between variables.\nAny exploratory component allows for a healthy dose of flexibility in team creativity. This open element will also allow teams to develop ideas independently, thereby producing stories that will likely diverge wildly from each other, making the project an exciting foray into data storytelling for many students."
  },
  {
    "objectID": "project/index.html#team-membership-and-roles",
    "href": "project/index.html#team-membership-and-roles",
    "title": "Project",
    "section": "Team Membership and Roles",
    "text": "Team Membership and Roles\nA team of students will work with a project liaison to develop the project and work together to produce the midterm and final deliverables. Rather than having all students in charge of all duties, team members should consider delegating tasks and various types of workloads to students who are best equipped to handle them either because of ability or because of interest and desire. Teams are to meet weekly and members are to complete individual worklog reports, which are used for final grading."
  },
  {
    "objectID": "project/index.html#deliverables",
    "href": "project/index.html#deliverables",
    "title": "Project",
    "section": "Deliverables",
    "text": "Deliverables\n\nMidterm Presentation\nFinal Presentation\nFinal R Markdown Report\nWorklogs/GitHub commits"
  },
  {
    "objectID": "project/index.html#project-evaluation",
    "href": "project/index.html#project-evaluation",
    "title": "Project",
    "section": "Project Evaluation",
    "text": "Project Evaluation\nThe project has different components representing it at various stages (e.g., midterm presentation, final presentation and report). See those sections specifically but the following general items will be important to consider.\n\nQuality of project deliverable documents (e.g., organization, coherence, story, coding clarity/organization, plots, etc.)\nProfessionalism (e.g., liaison meeting etiquette and responsibility, timely discord communication, non-tardy attendance at weekly team meeting, weekly worklogs, feedback from liaison, etc.)\nPeer evaluation (e.g., contributions, team player, etc.)\n\nNote: Liaison’s will also participate in evaluating all teams. The team with the most impressive project (e.g., most clear, most useful and actionable, most interesting, most thought provoking, etc.) will receive bonus points.\n\nPresentation Characteristics\nSee the midterm and final presentation guidelines for more detail and rubric but in general, the following characteristics will be evaluated.\n\nClarity: well-explained; easy to follow/understand; ability to communicate points effectively\nOrganization: structured logically; ability to walk audience through the data journey and communicate a story interpretation about data\nThoroughness: all relevant issues discussed thoroughly\nPresentation Style: degree of preparedness and polish in presentation; smooth and rehearsed; minimum of reading; well-paced; slide quality"
  },
  {
    "objectID": "project/index.html#weekly-worklogreport",
    "href": "project/index.html#weekly-worklogreport",
    "title": "Project",
    "section": "Weekly Worklog/Report",
    "text": "Weekly Worklog/Report\nTracking individual and team goals weekly ensures progress toward the goal, commitment to the project, accountability for oneself, and a record of accomplishments.\nThe Project Manager should inquire with the team about the best way to submit worklogs or transparency and review. This could be a Google Doc File, a spreadsheet, or even a Google From that contains questions to answer, which then get dumped into a Google Spreadsheet for all to review.\n\nFrequency of Worklog\nWorklogs are to be completed by end-of-day following the team meeting, after communicating future goals (distributed equally) to other team members. Please make public for me to review. Meetings should be physical to facilitate team cohesion and conversation, and limit silly technical issues that just waste meeting time.\n\n\nContents of Worklog\nWorklogs should contain information about the reporting date, the team member reporting, that member’s previous week accomplishments, and that member’s future week goals\n\nFor the past week, I accomplished the following specific goals for my team:\n\n\nThis…\nThat…\nAnd the other…\n\n\nFor this past week, the number of hours allocated toward those goals was: ___\nFor this coming week, my specific goals for the team include:\n\n\nThis…\nThat…\nAnd the other…\n\n\nIf relevant, any items to discuss with liaison."
  },
  {
    "objectID": "resources/dataviz_readings.html",
    "href": "resources/dataviz_readings.html",
    "title": "Readings",
    "section": "",
    "text": "You should read the enumerated items (those prefaced by numbers); others can supplemental.\n\nTopic\n\nxxx\nxxx\n\n\n\nGuided Practice with Posit Primers\n\nBar Plots\nBox Plots\nScatterplots\nLine Plots\n\n\n\nTopic\n\nxxx\nxxx\n\n\n\nThe Grammar of Graphics using ggplot\n\nxxx\n\n\n\nMapping Data to Visual Elements\n\nMapping Data to Aesthetics\nMake a Plot\n\ni) xxx\n\n\nAesthetic Considerations Designing Perceptually Efficient Visualizations\n\n\nSpatial Position and Adjustment (CH 7)\n\nAddressing Overplotting with geom_jitter()\n\n\n\n\nStatistical Transformations: Data as-is Versus Summaries\n\n\nData Preparation using dplyr\n\nSelecting Rows and Columns: select() and filter()\n1.2. Grouping/Pooling Data: `group_by()`\n\nData aggregation: summarize()\n\n\n\n\nScales and Axes (CH 6)\n\n\nVisualizing Comparisons\n\nxxx\nxxx\n\n\n\nVisualizing Uncertainty\n\nHistograms/Density Plots\nxxx\n\n\n\nVisualizing Associations and Trends\n\nScatterplots Using group_by for subgroups\nLine Plots\n\nVisualizing Amounts Visualizing Proportions or Ratios\nhttps://clauswilke.com/dataviz/visualizing-amounts.html\n\n\nMaking Visualizations Better\n\nPrinciple of Proportional Ink\nColor Pitfalls\nStorytelling\nWhy People Make Bad Charts (and What to Do When it Happens)\nRefining Plots\n\n\n\nAnnotation\n\nClaus Wilke, Claus Wilke, *Fundamentals of Data Visualization\n\nredundant-coding.html\nSmall Multiples\nTitle and Captions\nAxis Labesls\n\n\n\n\nEmphasis\n\nCalling Attention to Points\nAnnotating Points\nHighlighting Sections\n\n\n\nImage Formats\n\njpg, png, or svg?\nFile Formats Explained\n\n\nWhats the difference between jpg png and gif\nKieran Healy, Data Visualization\n\nxx\n\n\n[Cara Thompson, “Level Up Your Labels: Tips and Tricks for Annotating Plots”] (https://www.cararthompson.com/talks/user2022)\n\n\nReproduce vs. Replicate\n\nWhat is the reprex library?\nReproducible example with reprex\n\n\n\n\n\nAnimation\n\n\n\n\nflowchart RL\n  B(Data) --&gt; A(Plot) \n  C(Geometry) --&gt; A(Plot) \n  D(Statistics) --&gt; A(Plot)\n  E(Coordinate System) --&gt; A(Plot)\n  F(Theme) --&gt; A(Plot)"
  },
  {
    "objectID": "resources/dataviz_tools.html#websites",
    "href": "resources/dataviz_tools.html#websites",
    "title": "Tools for Data Visualization",
    "section": "Websites",
    "text": "Websites\n\nPractice Coding in R on Posit Cloud\n\nhttps://posit.cloud/learn/primers/\n\n\n\nColor Codes\n\nHTML colors: https://htmlcolorcodes.com/\n\n\n\nVisualize a palette for different types of colorblindness\n\nViz Palette https://projects.susielu.com/viz-palette\n\n\n\nWhat do your photos/images look like to others?\n\nCoblis colorblindness imulator: https://www.color-blindness.com/coblis-color-blindness-simulator/\nPilestone Colorblindness Simulator: https://pilestone.com/pages/color-blindness-simulator-1\nVischeck http://www.vischeck.com/vischeck/vischeckImage.php"
  },
  {
    "objectID": "resources/dataviz_tools.html#books",
    "href": "resources/dataviz_tools.html#books",
    "title": "Tools for Data Visualization",
    "section": "Books",
    "text": "Books\n\nClaus Wilke, Fundamentals of Data Visualization https://clauswilke.com/dataviz/\nhttps://www.bigbookofr.com/data-visualization.html\nhttps://handsondataviz.org/"
  },
  {
    "objectID": "resources/dataviztools.html#websites",
    "href": "resources/dataviztools.html#websites",
    "title": "Tools for Data Visualization",
    "section": "Websites",
    "text": "Websites\n\nPractice Coding in R on Posit Cloud\n\nhttps://posit.cloud/learn/primers/\n\n\n\nColor Codes\n\nHTML colors: https://htmlcolorcodes.com/\n\n\n\nVisualize a palette for different types of colorblindness\n\nViz Palette https://projects.susielu.com/viz-palette\n\n\n\nWhat do your photos/images look like to others?\n\nCoblis colorblindness imulator: https://www.color-blindness.com/coblis-color-blindness-simulator/\nPilestone Colorblindness Simulator: https://pilestone.com/pages/color-blindness-simulator-1\nVischeck http://www.vischeck.com/vischeck/vischeckImage.php"
  },
  {
    "objectID": "resources/dataviztools.html#books",
    "href": "resources/dataviztools.html#books",
    "title": "Tools for Data Visualization",
    "section": "Books",
    "text": "Books\n\nClaus Wilke, Fundamentals of Data Visualization https://clauswilke.com/dataviz/\nhttps://www.bigbookofr.com/data-visualization.html\nhttps://handsondataviz.org/"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#loading-data",
    "href": "slides/Visualizing_Associations.html#loading-data",
    "title": "Visualizing Associations",
    "section": "Loading Data",
    "text": "Loading Data\n\nSWIM &lt;- readr::read_csv(\"https://github.com/slicesofdata/dataviz23/raw/main/data/swim/cleaned-2023-CMS-Invite.csv\", \n                        show_col_types = F)"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#geom_point",
    "href": "slides/Visualizing_Associations.html#geom_point",
    "title": "Visualizing Associations",
    "section": "geom_point()",
    "text": "geom_point()\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Distance, y = Time)) +\n  geom_point()"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#another-example",
    "href": "slides/Visualizing_Associations.html#another-example",
    "title": "Visualizing Associations",
    "section": "Another example",
    "text": "Another example\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Split50)) +\n  geom_point()"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#smoothinggeom_smooth",
    "href": "slides/Visualizing_Associations.html#smoothinggeom_smooth",
    "title": "Visualizing Associations",
    "section": "Smoothinggeom_smooth()`",
    "text": "Smoothinggeom_smooth()`\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth()"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#linear-fit",
    "href": "slides/Visualizing_Associations.html#linear-fit",
    "title": "Visualizing Associations",
    "section": "Linear Fit",
    "text": "Linear Fit\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#geom_point-when-a-variable-is-a-factor",
    "href": "slides/Visualizing_Associations.html#geom_point-when-a-variable-is-a-factor",
    "title": "Visualizing Associations",
    "section": "geom_point() when a variable is a factor",
    "text": "geom_point() when a variable is a factor\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point()"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#multiclass-scatterplots",
    "href": "slides/Visualizing_Associations.html#multiclass-scatterplots",
    "title": "Visualizing Associations",
    "section": "Multiclass Scatterplots",
    "text": "Multiclass Scatterplots\n\nscatterplots with more than 2 variables\ncommunicate relationship with a third variabl\nmapped to an aesthetic like color, size, shape"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-numeric-variable-to-aesthetics",
    "href": "slides/Visualizing_Associations.html#mapping-a-numeric-variable-to-aesthetics",
    "title": "Visualizing Associations",
    "section": "Mapping a numeric variable to aesthetics",
    "text": "Mapping a numeric variable to aesthetics\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(mapping = aes(col = Distance))"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-numeric-variable-to-aesthetics-1",
    "href": "slides/Visualizing_Associations.html#mapping-a-numeric-variable-to-aesthetics-1",
    "title": "Visualizing Associations",
    "section": "Mapping a numeric variable to aesthetics",
    "text": "Mapping a numeric variable to aesthetics"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-categorical-variable-to-aesthetics",
    "href": "slides/Visualizing_Associations.html#mapping-a-categorical-variable-to-aesthetics",
    "title": "Visualizing Associations",
    "section": "Mapping a categorical variable to aesthetics",
    "text": "Mapping a categorical variable to aesthetics\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(mapping = aes(col = School))"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-categorical-variable-to-aesthetics-1",
    "href": "slides/Visualizing_Associations.html#mapping-a-categorical-variable-to-aesthetics-1",
    "title": "Visualizing Associations",
    "section": "Mapping a categorical variable to aesthetics",
    "text": "Mapping a categorical variable to aesthetics"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-new-numeric-and-a-new-categorical-variable",
    "href": "slides/Visualizing_Associations.html#mapping-a-new-numeric-and-a-new-categorical-variable",
    "title": "Visualizing Associations",
    "section": "Mapping a new numeric and a new categorical variable",
    "text": "Mapping a new numeric and a new categorical variable\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event))"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-new-numeric-and-a-new-categorical-variable-1",
    "href": "slides/Visualizing_Associations.html#mapping-a-new-numeric-and-a-new-categorical-variable-1",
    "title": "Visualizing Associations",
    "section": "Mapping a new numeric and a new categorical variable",
    "text": "Mapping a new numeric and a new categorical variable"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#suppress-legend",
    "href": "slides/Visualizing_Associations.html#suppress-legend",
    "title": "Visualizing Associations",
    "section": "Suppress Legend",
    "text": "Suppress Legend\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    show.legend = F\n    )"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#suppress-legend-1",
    "href": "slides/Visualizing_Associations.html#suppress-legend-1",
    "title": "Visualizing Associations",
    "section": "Suppress Legend",
    "text": "Suppress Legend"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#changing-alpha-transparency",
    "href": "slides/Visualizing_Associations.html#changing-alpha-transparency",
    "title": "Visualizing Associations",
    "section": "Changing alpha transparency",
    "text": "Changing alpha transparency\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    alpha = .4,\n    show.legend = F\n    )"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#changing-alpha-transparency-1",
    "href": "slides/Visualizing_Associations.html#changing-alpha-transparency-1",
    "title": "Visualizing Associations",
    "section": "Changing alpha transparency",
    "text": "Changing alpha transparency"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#changing-point-position",
    "href": "slides/Visualizing_Associations.html#changing-point-position",
    "title": "Visualizing Associations",
    "section": "Changing point position",
    "text": "Changing point position\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    alpha = .3,\n    position = position_jitter(),\n    show.legend = F\n    )"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#changing-point-position-1",
    "href": "slides/Visualizing_Associations.html#changing-point-position-1",
    "title": "Visualizing Associations",
    "section": "Changing point position",
    "text": "Changing point position"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#loading-data",
    "href": "slides/spatial_position_and_adjustment.html#loading-data",
    "title": "Visualizing Associations",
    "section": "Loading Data",
    "text": "Loading Data\n\nSWIM &lt;- readr::read_csv(\"https://github.com/slicesofdata/dataviz23/raw/main/data/swim/cleaned-2023-CMS-Invite.csv\", \n                        show_col_types = F)"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#geom_point",
    "href": "slides/spatial_position_and_adjustment.html#geom_point",
    "title": "Visualizing Associations",
    "section": "geom_point()",
    "text": "geom_point()\n\n2 + 2\n\n[1] 4\n\n# comment"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#slide-title",
    "href": "slides/spatial_position_and_adjustment.html#slide-title",
    "title": "Visualizing Associations",
    "section": "Slide Title",
    "text": "Slide Title\n\none\ntwo"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#make-this-slide-red",
    "href": "slides/spatial_position_and_adjustment.html#make-this-slide-red",
    "title": "Visualizing Associations",
    "section": "Make this slide Red",
    "text": "Make this slide Red"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#making-a-slide-incremental",
    "href": "slides/spatial_position_and_adjustment.html#making-a-slide-incremental",
    "title": "Visualizing Associations",
    "section": "Making a Slide Incremental",
    "text": "Making a Slide Incremental\nSay you want to reveal the content of slide piecemeal without rewriting separate slides with previous content.\n\nThen add some content…\n\n\nThen some more content"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#omit-this-slide-visibility-hidden",
    "href": "slides/spatial_position_and_adjustment.html#omit-this-slide-visibility-hidden",
    "title": "Visualizing Associations",
    "section": "Omit This Slide {visibility = “hidden”}",
    "text": "Omit This Slide {visibility = “hidden”}"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#add-links",
    "href": "slides/spatial_position_and_adjustment.html#add-links",
    "title": "Visualizing Associations",
    "section": "Add links",
    "text": "Add links\n\ncmc\n\n\n\nFirst item\nSecond item"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#fragments",
    "href": "slides/spatial_position_and_adjustment.html#fragments",
    "title": "Visualizing Associations",
    "section": "Fragments",
    "text": "Fragments\n\nFade in\n\n\nFade out\n\n\nHighlight red\n\n\nFade in, then out"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#fragments-nesting",
    "href": "slides/spatial_position_and_adjustment.html#fragments-nesting",
    "title": "Visualizing Associations",
    "section": "Fragments, nesting",
    "text": "Fragments, nesting\n\n\n\nFade in &gt; Turn red &gt; Semi fade out"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#fragments-spans",
    "href": "slides/spatial_position_and_adjustment.html#fragments-spans",
    "title": "Visualizing Associations",
    "section": "Fragments, spans",
    "text": "Fragments, spans\nThis is an important sentence!\nMind the gap when riding the rail!"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#column-layout",
    "href": "slides/spatial_position_and_adjustment.html#column-layout",
    "title": "Visualizing Associations",
    "section": "Column layout",
    "text": "Column layout\n\n\ncontents…s\n\ncontents…"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#output-location",
    "href": "slides/spatial_position_and_adjustment.html#output-location",
    "title": "Visualizing Associations",
    "section": "Output Location",
    "text": "Output Location\n\n\nlibrary(ggplot2)\n\nmtcars |&gt; \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = \"y~x\")"
  },
  {
    "objectID": "syllabus/syllabus.html",
    "href": "syllabus/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Semester\nFall 2023\n\n\nSection\nPSYC 167, Sect-01\n\n\nDay Time\nTuesday 2:45 - 05:30PM (Pacific)\n\n\nLocation\nLocation: Roberts South, 104\n\n\nOffice Hours\nR: 1-2pm; F: 9-10am\n\n\nInstructor\nGabriel I. Cook\n\n\nContact\nEmail: gcook@CMC.edu(please put ’PSYC 167 in subject line)\n\n\nCredit\n3 hours; 1 credits"
  },
  {
    "objectID": "syllabus/syllabus.html#course-description",
    "href": "syllabus/syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course introduces students to R, a programming language for statistical computing and graphics. Students will learn how to clean, manipulate, transform, join, and tidy data sets to prepare for statistical modeling. Supervised (e.g., regression) and unsupervised (e.g., clustering) approaches will be applied to understand simple and complex relationships between cognitive and non-cognitive variables (e.g., biology, aging, education, socioeconomic, health, etc.). Students will apply their skills to wrangle, explore, and model relevant data sets for a hands-on project for local scholars, offices, organizations, or industry participants. Data sets and relevant readings will change depending on semester.\nPrerequisite: PSYC109 CM or equivalent; recommended a course in Cognitive Psychology or Cognitive Science; or permission of instructor; not open to students who have completed CSCI 36 or any other introductory course in foundation of data science.\n\nCourse Specific Learning Goals\n\nUnderstand various forms of cognitive functioning, how they are measured, and how those abilities relate with other variables\nLearn how to use R and RStudio to answer real‐word questions with data\n\n\n\nUse the dplyr and tidyr libraries to clean data prior to statistical analysis\nLearn how to import, clean, manipulate, tidy, and summarize data\nExamine relationships among cognitive and non-cognitive variables by applying statistical methods and models to data\nPractice using statistical probability and inference\nLearn how to examine relationships among variables and apply statistical methods and models to data (e.g., supervised or unsupervised machine‐learning methods)\nVisualize data and/or model parameters\nLearn how to manage local and remote projects and collaborate with others\nPractice scientific writing integrating data with theory\nCreate dynamic and reproducible reports with R Markdown\n\nThe following departmental learning goals will also be met: 1. Knowledge of major concepts in cognitive psychology; 2. Understanding of research methods in psychology, including research design, data analysis and interpretation; 3. Development of critical-thinking skills and use of the scientific approach to solve problems related to behavior and mental processes; 4. Oral and written communication skills."
  },
  {
    "objectID": "syllabus/syllabus.html#courses-at-cmc",
    "href": "syllabus/syllabus.html#courses-at-cmc",
    "title": "Syllabus",
    "section": "Courses at CMC",
    "text": "Courses at CMC\n\nFaculty Handbook 5.4.2 Work Load in Classes\n“Courses should involve approximately equal workloads. Generally, students should expect to spend from 6 to 8 hours per week, over and above the time spent in classroom, on each course.” – CMC Faculty Handbook\nIf you do the math, including class time of 2½ hours, you should expect to allocate 8 ½ to 10 ½ hours per week for courses at CMC. “Per week” is a key phrase; courses are not designed for nondistributed cramming."
  },
  {
    "objectID": "syllabus/syllabus.html#course-materials-and-textbook",
    "href": "syllabus/syllabus.html#course-materials-and-textbook",
    "title": "Syllabus",
    "section": "Course Materials and Textbook",
    "text": "Course Materials and Textbook\nAll of the course materials will be available on this course website .\nLink to the course website: https://slicesofdata.github.io/fods24\n\nRequired Equipment:\nComputer: current Mac (macOS) or PC (Windows or Linux) with high-speed internet connection, capable of running R and RStudio\n\n\nRequired Software:\nR and RStudio: Students will be required to use R and RStudio software. Note: Install Version will be provided. Before installing RStudio, you must also download and install the base R software at https://www.r-project.org/ that is appropriate for your computer’s operating system. RStudio can be downloaded for free at https://www.rstudio.com. You are expected to install R and RStudio on your personal computer by downloading the software from the links above. You will also have to install appropriate libraries throughout the course. Further instructions will be provided.\n\n\nReading Materials/Textbook(s)\nReadings will be taken from different sources and will appear in each topic module.\n\n[R4DS] Grolemund and Wickham (2016): R for Data Science. Electronic version.\n[FODS] Huber (2020): Foundations of Data Science.\nNordmann, E. & DeBruine, L. (2023). Applied Data Skills: Processing & Presenting Data (2023) . https://psyteachr.github.io/ads-v2\n[DSRR] Data Skills for Reproducible Research: Electronic version.\nCognition readings for project topics will be available on Canvas/Sakai\n\nThese textbooks are free and open-source."
  },
  {
    "objectID": "syllabus/syllabus.html#course-structure",
    "href": "syllabus/syllabus.html#course-structure",
    "title": "Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\nThe assumption is that students possess varying levels of skills related to programming. Nevertheless, students are expected to attend class prepared to engage with and practice concepts related to readings and lectures. Prior to class, students should have completed readings (e.g., modules or readings referenced therein) and watched any associated lectures on the material. Class time will involve answering questions raised by students, a mining lecture, and coding activities that will inform the final project (note, concepts build). Homework assignments will also invovolved engagement with the project data. Class time will be spent engaging in a variety of tasks and activities, including lectures, group-work, applied coding activities, presentations, and discussions."
  },
  {
    "objectID": "syllabus/syllabus.html#course-schedule",
    "href": "syllabus/syllabus.html#course-schedule",
    "title": "Syllabus",
    "section": "Course Schedule",
    "text": "Course Schedule\n\n\n\n\n\n\n\n\n\n\n\nDate\nWeek\nModule\nTopic\n\n\n\n\n29-Aug\n1\n1\nIntroduction & Project Management\n\n\n\n1\n2\nGraphical Perception\n\n\n5-Sep\n2\n3\nData Frame Manipulation and Wrangling\n\n\n\n2\n4\nData Subsets and Summaries\n\n\n12-Sep\n3\n5\nThe Grammar of Graphics\n\n\n\n3\n6\nVisualizing Amounts\n\n\n19-Sep\n4\n7\nVisualizing Associations\n\n\n\n4\n8\nSpatial Position and Adjustment\n\n\n26-Sep\n5\n9\nConsiderations in Data Visualization\n\n\n\n5\n10\nColor Scales and Palettes\n\n\n3-Oct\n6\n11\nHistograms and Density Plots*\n\n\n\n6\n12\nCoordinates, Axes and Position Scales\n\n\n10-Oct\n7\n13\nStatistical Transformations (Data as-is Versus Summaries)\n\n\n\n7\n14\nMore Data Wrangling\n\n\n17-Oct\n8\n\nFall Break (no class)\n\n\n24-Oct\n9\n15\nVisualizing More Distributions\n\n\n\n9\n16\nVisualizing Uncertainty\n\n\n31-Oct\n10\n\nMid-Term Presentation\n\n\n7-Nov\n11\n17\nVisualizing Trends\n\n\n\n11\n18\nLegends and Arrangement\n\n\n14-Nov\n12\n19\nDesigning Perceptually Efficient Visualizations\n\n\n\n12\n20\nAnnotation and Text\n\n\n21-Nov\n13\n21\nMulti-Panel Plots: Faceting and Layers\n\n\n\n13\n22\nAttentional Control and Tradeoffs\n\n\n28-Nov\n14\n23\nTitles Captions & Tables\n\n\n\n14\n24\nFigure Design (Themes)\n\n\n5-Dec\n15\n\nPresentation (Last day of Instruction)"
  },
  {
    "objectID": "syllabus/syllabus.html#assignments-and-grading",
    "href": "syllabus/syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThis is an engagement and skills-acquisition based course. At the beginning of the course and throughout, students will be given instruction on building and maintaining a website using quarto and github pages. Each week students will contribute blog posts and other content to their websites in response to module assignments. Students will be expected to submit URL links to their blogs using Blackboard. Students are expected to attend and participate in each class. The final project includes conducting, communicating, and preserving a reproducible data analysis project.\n\n**Evaluation and Grading*\n\n\n\n\n\nItem\nTotal Points\n\n\n\n\nKnowledge Assessments\n10\n\n\nWeekly Conceptual and Programming\n30\n\n\nMidterm Presentation\n20\n\n\nFinal Project (pres and report)\n40\n\n\n\n\n\nPercentage grades are converted to letter grades according to the following rubric.\n\n\n\n\n\nLetter\nPoint Range\n\n\n\n\nA\n94 - 100\n\n\nA-\n90 - 93.99\n\n\nB+\n87 - 89.99\n\n\nB\n84 - 86.99\n\n\nB-\n80 - 83.99\n\n\nC+\n77 - 79.99\n\n\nC\n74 - 76.99\n\n\nC-\n70 - 73.99\n\n\nD+\n67 - 69.99\n\n\nD\n64 - 66.99\n\n\nD-\n60 - 63.99\n\n\nF\n0 - 59.99"
  },
  {
    "objectID": "syllabus/syllabus.html#attendance",
    "href": "syllabus/syllabus.html#attendance",
    "title": "Syllabus",
    "section": "Attendance",
    "text": "Attendance\nStudents are expected to attend and participate in each class."
  },
  {
    "objectID": "syllabus/syllabus.html#course-policies",
    "href": "syllabus/syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course Policies",
    "text": "Course Policies\n\nDue dates\nDue dates are suggestions for completing coursework on a weekly basis. You may be able to work ahead, but you are not encouraged to fall behind.\nYou should email me if you have an exceptional circumstance preventing you from taking an assessment during an assessment week.\n\n\nChanges to the syllabus\nThe syllabus may be updated for clarity or to make adjustments for pedagogical purposes. The most current version of the syllabus is always available from the course website.\n\n\nAccessibility\nIn order to receive disability-related academic accommodations students must first be registered with the Center for Student Disability Services. Students who have a documented disability or suspect they may have a disability are invited to set up an appointment with the Director of the Center for Student Disability Services, at 718-951-5538. If you have already registered with the Center for Student Disability Services, please provide your professor with the course accommodation form and discuss your specific accommodation with him/her.\n\n\n\nEmail Correspondence\nI will regularly use e-mail but you should contact me on the Discord channel, which is where I will post announcements, changes in the syllabus, reminders, etc. You are responsible for monitoring Discord and e-mail regularly.\nIf you have questions, please message me on Discord. If you need to e-mail me:\n\nAlways add ’PSYC 166” to the subject line\nemail me at: gcook@cmc.edu"
  },
  {
    "objectID": "syllabus/syllabus.html#universitys-policy-on-academic-integrity",
    "href": "syllabus/syllabus.html#universitys-policy-on-academic-integrity",
    "title": "Syllabus",
    "section": "University’s policy on Academic Integrity",
    "text": "University’s policy on Academic Integrity\nThe faculty and administration of Claremont McKenna College support an environment free from cheating and plagiarism. Each student is responsible for being aware of what constitutes cheating and plagiarism and for avoiding both.\n\nViolations of Academic integrity\nEach student is responsible for understanding and acting in accordance with the College’s policy on Academic Integrity, described below.\n\n\nAcademic Integrity\nAlthough you may find yourself working on assignments with a partner or discussing them with classmates, all assignments should be your one original work. You are not to share materials with other students if that material has the potential of being copied, even if your intention is not to allow a classmate to copy your work. Any signs of academic dishonesty, even those raised by concerned peers, will be submitted to the Academic Standards Committee for review. Although I do not anticipate any events of academic dishonesty, any form of dishonestly of any form will not be tolerated. Many students are unclear of the definition of plagiarism so I have posted some CMC links to information that I believe will clarify the issue. In addition, any work completed for another course, past or present, may not be submitted for a grade for this course and would be a violation of integrity. http://registrar.academic.claremontmckenna.edu/acpolicy/default.asp\n\nStatement of Reasonable Accommodations\nYour experience in this class is important to me. If you have already established accommodations with Disability & Accessibility Services at CMC, please communicate your approved accommodations to me during the first week of the semester so we can discuss your needs in this course ASAP. You can start this conversation by forwarding me your accommodation letter. If you have not yet established accommodations through Accessibility Services but have a temporary health condition or permanent disability (conditions include but are not limited to: mental health, attention-related, learning, vision, hearing, physical or health), you are encouraged to contact Assistant Dean for Disability Services & Academic Success, Kari Rood, at AccessibilityServices@cmc.edu to ask questions and/or begin the process. General information and accommodations request information be found at the CMC DOS Accessibility Service’s website. Please note that arrangements must be made with advance notice in order to access the reasonable accommodations. You are able to request accommodations from CMC Accessibility Services at any point in the semester. Be mindful that this process may take some time to complete and accommodations are not retroactive. I would err on the side of caution and make sure your accommodations are sent to me even if you do not believe you need them as some students only learn they may need time after completing assessment. The Americans With Disabilities Act (ADA) and Section 504 of the Rehabilitation Act do not make accommodations retroactive. If you are approved for extra testing time for example, you must do so before an electronic assessment is posted in order for it to be integrated into the assessment. Claremont McKenna College values creating inclusive and accessible learning environments consistent with federal and state law. If you are not a CMC student, please connect with the Disability & Accessibility Services Coordinator on your campus regarding a similar process.\n\n\n\nFYI on cheating etc.\nRemember, you are responsible for not cheating or violating CMC’s Academic Integrity Policy. You are responsible for understanding that policy, and for conducting yourself in a manner such that you do not violate the policy.\nThe above link lists many examples of cheating and plagiarism that are not allowed. There are many more specific acts that you should NOT do. Here is an additional list of activities that will be sufficient cause for immediate failure in the course.\n\nDo not take pictures of exam or quiz questions and share them with other students\nDo not give other students answers during an exam or quiz, or any other assignment that is an individual assignment\nDo not copy work from another source and submit it as your own\nDo not copy and paste text from the internet and submit it as your own words\nDo not copy and paste text and slightly alter wording to pass the work off as your own\nDo not hire someone else to do the coursework for you\nDo not copy and paste text into a paraphrasing app, and then submit the output of the paraphrasing app as your own work\nDo not copy random words from the internet that have nothing to do with the assignment and submit them as your own work.\nDo not work on individual assignments with other students, share answers or other material, and then all hand in versions of the same thing that are slightly different.\nDo not plagiarize yourself by submitting work that you have previously completed in another class.\n\n\n\nMandate to report violations\nIf a faculty member suspects a violation of academic integrity and, upon investigation, confirms that violation, or if the student admits the violation, the faculty member MUST report the violation. Students should be aware that faculty may use plagiarism detection software.\nThere is no excuse for cheating. Students who are caught cheating may receive a failing grade for the entire course. All students who violate the academic integrity will receive a Faculty Action Report, which will go on their personal file at the Academic Integrity Office."
  },
  {
    "objectID": "syllabus/syllabus.html#faq",
    "href": "syllabus/syllabus.html#faq",
    "title": "Syllabus",
    "section": "FAQ",
    "text": "FAQ\nIf you have questions about the syllabus, let’s talk about it in class, and/or please create a thread to discuss the question on the discussion board for this course on Blackboard."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#external-functions",
    "href": "modules/22_annotation_and_text.html#external-functions",
    "title": "Annotation and text",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#libraries",
    "href": "modules/22_annotation_and_text.html#libraries",
    "title": "Annotation and text",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{forcats} 1.0.0: for creating and ordering factors\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting\n{ggtext} 0.1.2: for annotations and text on ggplot objects\n{ggrepel} 0.9.3: for repelling text on ggplot objects\n{showtext} 0.9.6: for changing text font"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#load-libraries",
    "href": "modules/22_annotation_and_text.html#load-libraries",
    "title": "Annotation and text",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(ggtext)\nlibrary(ggrepel)\nlibrary(showtext)"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#labeling-bar-plots",
    "href": "modules/22_annotation_and_text.html#labeling-bar-plots",
    "title": "Annotation and text",
    "section": "Labeling bar plots",
    "text": "Labeling bar plots\nWe can create a standard bar plot using geom_bar() or geom_col() depending on whether you have either x or y data or both. Let’s say the goal is to visualize Athena athletes who have participated in the 100 Freestyle. We can map the athlete names to x and Seconds to y. Because Fullname contains the full names of the athletes, so that would be a reasonable variable to pass to x so that we can distinguish between athletes with the same first or last names.\n\n#name_count &lt;- 10 #SWIM #|&gt; filter(Event == \"100 FREE\") |&gt; filter(Team == \"Athena\") #|&gt; pull(Fullname) |&gt; length()\n\nWe can see that there are 10 athletes in the data set. Nevertheless, the athlete’s names will fairly be unreadable, a quick fix would be to coord_flip(), though you could also wrap names or stagger them to fit better.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(\n    x = Fullname,\n    y = Seconds\n  ), \n  ) +\n  geom_col() +                  # column plot\n  coord_flip() +                # flip the coordinates\n  theme_classic()  \n\n\n\n\nClearly, there are some things we can clean up on the plot. We don’t need to labels the names axis because that detail is self evident. Even though all bars are compared on an aligned axis, trying to determine who is fastest and who is slowest is very challenging. We really should reorder the bars. For this, we can use forcats::fct_reorder() to reorder the bars and because we only need to arrange them based on a single variable, we do not need to use forcats::fct_reorder2().\nFor the function we need:\n\n.f: the factor to reorder\n.x: the variable on which to sort\n.fun: the function for reordering (median is default, but can be mean, max, etc.)\n\nAn option is to also arrange the data using .desc. . desc = TRUE will sort in descending order. Although somewhat counter-intuitive, when the coordinates are flipped, the result will be an arrangement from fastest to slowest speed.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(\n           x = forcats::fct_reorder(.f = Fullname, \n                                    .x = Seconds,   # reorder the bars by Time, \n                                    .fun = min,\n                                    .desc = T\n                                    ),   \n           y = Seconds\n           ), \n         ) +\n  geom_col() +                             # column plot\n  coord_flip() +                           # flip the coordinates\n  theme_classic()  \n\n\n\n\nYou can see that the reordering of the x aesthetic creates a message label to the axis. Again, we would not need that anyway. The times are very difficult to distinguish also, so even though the bars are ordered in a useful way for identifying the fastest athletes, their exact times are impossible to extract from the plot."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#improving-plot-utility",
    "href": "modules/22_annotation_and_text.html#improving-plot-utility",
    "title": "Annotation and text",
    "section": "Improving Plot Utility",
    "text": "Improving Plot Utility\nWhat might also help with interpreting the data is to visualize who is faster or slower than the average. We can group the data by events and athlete groups, compute a group mean, ungroup, and then create a variable that would hold the color corresponding to one’s performance compared with the group mean. What would be most helpful would be to [do perform this set of operations on the enter SWIM data frame rather than just the subset of interest. Because Event represents both the event and the distance, grouping by that variable will subset also by different distances of the same event type. MeanRelative will serve as a factor for the relative performance, which can be an ordered factor. RelativeFill will serve as the variable containing a color corresponding to one’s performance relative to the group mean.\n\nSWIM &lt;- SWIM |&gt;\n  group_by(Event, Team) |&gt;\n  mutate(Mean = mean(Seconds, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  mutate(MeanRelative = factor(case_when(\n    Seconds &gt; Mean ~ \"Above\", \n    Seconds == Mean ~ \"Mean\",\n    Seconds &lt; Mean ~ \"Below\"\n    ), \n    levels = c(\"Above\", \"Mean\", \"Below\"), \n    ordered = TRUE\n    )) |&gt;\n  mutate(RelativeFill = factor(case_when(\n    MeanRelative &gt; \"Above\" ~  \"cornflowerblue\", \n    MeanRelative == \"Mean\" ~  \"grey\",\n    MeanRelative &lt; \"Below\" ~  \"grey60\"\n    ), \n    levels = c(\"cornflowerblue\", \"grey\", \"grey60\"), \n    ordered = TRUE\n    ))\n\nRemember to use scale_fill_identity() when colors are saved as a variable in the data frame and when you need to reference them by their character value.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(\n           x = forcats::fct_reorder(.f = Fullname, \n                                    .x = Seconds, \n                                    .fun = min,\n                                    .desc = T\n                                    ),     # reorder the bars by Time\n           y = Seconds,\n           fill = RelativeFill\n         )\n  ) + \n  geom_col() +                             # column plot\n  coord_flip() +                           # flip the coordinates\n  theme_classic() +\n  scale_fill_identity()\n\n\n\n\nOK, so we can see the two groups of athletes now. Athlete bests, however, occurred in certain years, so we can clarify the data by including the year in which they participated.\nWe can combine each athlete’s name with their year of fastest time into a variable called Name_Year. One way to accomplish this in Base R is to use paste() to concatenate strings. Because there is a variable containing the last name and first initial, Last_fi, and a variable that contains the Year, we can combine them as a string. paste() has a separator argument, sep which represents the string characters that separate the string objects you are concatenating.\nBy default, sep = \" \", a space.\npaste(Last_fi, Year)\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  mutate(Name_Year = paste(Last_fi, Year)) |&gt;\n  ggplot(mapping = aes(\n    x = forcats::fct_reorder(.f = Name_Year, \n                             .x = Seconds, \n                             .fun = min,\n                             .desc = T\n    ),     # reorder the bars by Time\n    y = Seconds,\n    fill = RelativeFill\n  )\n  ) + \n  geom_col() +                             # column plot\n  coord_flip() +                           # flip the coordinates\n  theme_classic() +\n  scale_fill_identity()"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#text-wrapping-using-paste",
    "href": "modules/22_annotation_and_text.html#text-wrapping-using-paste",
    "title": "Annotation and text",
    "section": "Text Wrapping using paste()",
    "text": "Text Wrapping using paste()\nThe bars are fairly wide and the names are rather relatively narrow, so we can wrap the text by placing the year under the name. Setting sep = \"\\n\" will separate the variables with a new line.\npaste(Last_fi, Year, sep = \"\\n\")\nLet’s take a look by pull()ing the variable.\n\nSWIM |&gt;\n  mutate(New_Year = paste(Last_fi, Year, sep = \"\\n\")) |&gt;\n  pull(New_Year) |&gt;\n  head()\n\n[1] \"Crawford, J\\n2019\"  \"Sealander, A\\n2022\" \"Ngo, K\\n2016\"      \n[4] \"Liu, H\\n2014\"       \"Kee, M\\n2014\"       \"Orbach-M, N\\n2020\" \n\n\nAlthough appears in the string, it won’t appear in the displayed object, so everything looks good. Let’s update the data frame.\n\nSWIM &lt;- SWIM |&gt;\n  mutate(Name_Year = paste(Last_fi, Year, sep = \"\\n\"))\n\nNow let’s recreate the plot with the wrapped text variable.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(\n    x = forcats::fct_reorder(.f = Name_Year, \n                             .x = Seconds, \n                             .fun = min,\n                             .desc = T),   # reorder the bars by Time\n    y = Seconds, \n    fill = RelativeFill\n  )\n  ) + \n  geom_col() +                             # column plot\n  coord_flip() +                           # flip the coordinates\n  theme_classic() + \n  scale_fill_identity()\n\n\n\n\nWe will return to this plot and discuss some ways to modify it but we need to take a brief detour into scatter plots and point labeling."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#labeling-using-geom_point",
    "href": "modules/22_annotation_and_text.html#labeling-using-geom_point",
    "title": "Annotation and text",
    "section": "Labeling using geom_point()",
    "text": "Labeling using geom_point()\nOne of the {ggplot} solutions to working with text is the text geom, geom_text(). This geom allows you to plot text to plots or place labels inside the plot space.\nIf the goal is to add text data to the plot to facilitate processing of the plot, geom_text() will be useful. For example, you can map numeric variables like time or year to aesthetics of the plot or you can map character variables like names or categorical labels. You can also set other text if it is not in the data frame.\ngeom_text() will plot the identity of variable values from the data frame so what you want mapped per row in the data will be whatever value is in that variable row. In order to map the variable, you will need to set label = variable to serve as the label.\nWith the previous plot, looking at each point does not allow the user to extract the exact performance time corresponding to that point. In some cases, this may not be an issue and the value can be extracted by directing visual attention to the x and y axes.\n\nDirect labeling with the outcome variable, y:\nIf the goal of the plot is to communicate the performance value and leave no ambiguity about its value or error in extraction from the axes (points farther away will likely be more erroneous), then you can direct label the performance time.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(x = Year, Seconds)) +\n  geom_text(mapping = aes(label = Seconds))\n\n\n\n\nOf course, now the y axis labeling is unnecessary and potentially confusing with the rest of the plot. Removing this is something to address with theme() manipulations, so we won’t address this issue here.\n\n\nDirect labeling with the variable other than what’s mapped to x or y:\nIf the goal of the plot is to communicate the athlete for each point, we can map a name variable.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(x = Year, Seconds)) +\n  geom_text(mapping = aes(label = Fullname))\n\n\n\n\nOne issue with this plot, and with many, is that the labels can overlap, thus making them illegible. Long labels or having many labels can be your enemy here."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#fixing-overlapping-labels",
    "href": "modules/22_annotation_and_text.html#fixing-overlapping-labels",
    "title": "Annotation and text",
    "section": "Fixing overlapping labels",
    "text": "Fixing overlapping labels\n\nAdjusting label font size\nYou can adjust the font size just as you would with points using the size argument.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(x = Year, Seconds)) +\n  geom_text(mapping = aes(label = Fullname),\n            size = 3\n  )\n\n\n\n\n\n\nChecking for overlapping labels\nAlong with adjusting the font size, when labels overlap, we can adjust their positioning. By setting check_overlap = TRUE, the plot will be evaluated for overlapping text. You can set various parameters about this evaluation process, so if desired review the docs. Here, we will see what happens to the plot when using it.\ngeom_text(check_overlap = TRUE)\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(x = Year, Seconds)) +\n  geom_text(mapping = aes(label = Fullname),\n            size = 4,\n            check_overlap = T\n  )\n\n\n\n\nSetting check_overlap = T sometimes results in names disappearing from the plot depending on the degree of overlap with other locations. Consequently, this approach is not a great solution in some cases.\n\n\nRepelling text objects using ggrepel::geom_text_repel()\nAnother way to manipulate text and labels on plots involves using {ggrepel}. As the name implies, the library helps repel objects in plots. To repel text labels from each other, we can use geom_text_repel(). We will replace geom_text() with ggrepel::geom_text_repel().\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(x = Year, Seconds)) +\n  ggrepel::geom_text_repel(mapping = aes(label = Fullname),\n                           size = 4\n  )\n\n\n\n\nNote: If you want to use geom_text_repel() to display text rather than use geom_text() and you do not want points, use point.size = NA to remove them.\n\n\nEnsuring labels map onto data positions\nUsing geom_text_repel(), however, labels are repelled from each other but their positioning, y axis positioning in this instance specifically, results in labels not mapping appropriately onto to the Seconds position.\nAdding a geom_point() layer makes this issue quite clear.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(x = Year, Seconds)) +\n  ggrepel::geom_text_repel(mapping = aes(label = Fullname),\n                           size = 4\n  ) +\n  geom_point()\n\n\n\n\n\n\nAdding lines to labels repelled from points\nAlthough text or labels are positioned above or below points, there may be some difficulty identifying which point corresponds to a specific label. In order to visually direct the label to the points, you will need to set a value for the box.padding argument. The larger the value, the longer the line. We can set to something like box.padding = .5 or box.padding = 1.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(x = Year, Seconds)) +\n  ggrepel::geom_text_repel(\n    mapping = aes(label = Fullname),\n    size = 4,\n    box.padding = 1\n  ) +\n  geom_point()\n\n\n\n\nNote: If you wish the line to be an arrow, set the arrow = arrow() and look into grid::arrow() for setting the arrow angle, arrow type, etc. If you don’t want a point, then don’t include the geom_point() layer.\n\n\nEnsuring labels take the same spatial positions\nEverything geom_text_repel() runs, the labels may take new positions. To ensure behavior is not random, set a seed.\n\nSWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(x = Year, Seconds)) +\n  ggrepel::geom_text_repel(\n    mapping = aes(label = Fullname),\n    size = 4,\n    box.padding = 1,\n    seed = 167\n  ) +\n  geom_point()"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#repositioning-bar-labels-using-geom_text",
    "href": "modules/22_annotation_and_text.html#repositioning-bar-labels-using-geom_text",
    "title": "Annotation and text",
    "section": "Repositioning Bar Labels using geom_text()",
    "text": "Repositioning Bar Labels using geom_text()\nLet’s return to our previous version of the bar plot used to visualize the best swim times each year along with the athlete. We had ordered the bars from fastest to slowest and positioned both the name and the year on the x axis before flipping the coordinates.\nWe will create a base plot on which to place and adjust geom_text() objects. Dark text on dark-color bars or light text on light-colored bars will make reading difficult. This is an element to change using the full code.\n\n\n\n\n\nBy default, because the names are in the variable mapped to x, they assume the spatial position of the plot corresponding to that axis with each name at tick mark. Labels, however, can be placed wherever you want to place them. Rather than the axis labeling at the base of each bar, we could place at the end of each bar, a location closer to swim time. A location change of this nature would reduce the cognitive demands for processing the plot because the name would be closer to the variable of interest, the swim time. The names could also be positioned inside the bars, thus making the names a property of the bars rather than a property associated with the bars by virtue of their proximity (see Principles of Gestalt Perception).\nThe text geom, geom_text(), will help with this adding text to bar plots."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#labeling-bars",
    "href": "modules/22_annotation_and_text.html#labeling-bars",
    "title": "Annotation and text",
    "section": "Labeling Bars",
    "text": "Labeling Bars\nUsing geom_text(), we can modify other text properties not yet discussed. Some arguments and values that we will address include:\n\nfontface = \"bold\": the font face (e.g., bold, italic, etc.)\ncol = \"black\": the font color\nfamily = \"Calibri\" : the font type\nv_just and h_just: justification of the horizontal and vertical of strings (“top”, “middle”, “bottom”, “left”, “center”, “right”); or a value between 0 and 1, inclusive\nnudge_x and nudge_y: nudging horizontal and vertical labels"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#repositioning-bar-labels-using-geom_text-1",
    "href": "modules/22_annotation_and_text.html#repositioning-bar-labels-using-geom_text-1",
    "title": "Annotation and text",
    "section": "Repositioning Bar Labels using geom_text()",
    "text": "Repositioning Bar Labels using geom_text()\nFor this plot, we will set:\ncol = \"black\"\nfontface = \"bold\"\nsize = 3\nhjust = 1         # set the horizontal adjustment of the text\nvjust = .5        # set the vertical adjustment of the text\nnudge_y = -0.25   # nudge along y just a little"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#changing-label-size-color-and-font-face",
    "href": "modules/22_annotation_and_text.html#changing-label-size-color-and-font-face",
    "title": "Annotation and text",
    "section": "Changing label size, color, and font face",
    "text": "Changing label size, color, and font face\n\ncol = \"black\"\nfontface = \"bold\"\nsize = 3\n\n\nSWIM_bar +\n  geom_text(mapping = aes(label = Name_Year),  # map Name_Year to label \n            col = \"black\",\n            size = 3,\n            fontface = \"bold\"\n            )\n\n\n\n\nNotice that the spatial positioning of the labels for geom_col() is the same as that for geom_point(), which is the xy coordinate. The y position is where the bar terminates just like where a point terminates in geom_point()."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#changing-label-position",
    "href": "modules/22_annotation_and_text.html#changing-label-position",
    "title": "Annotation and text",
    "section": "Changing label position",
    "text": "Changing label position\nBecause the goal would be to place the labels in the bar, this position is not appropriate. We would need to adjust the horizontal or vertical position of the label. Importantly, when you have flipped axes, hjust will not shift the labels left or right but instead up and down. Similarly, vjust will adjust in the other direction.\nThus, setting the horizontal adjustment of the text by setting hjust = 1 or hjust = \"top\" will set the position to the top of end of each bar for each label. The default vertical justification is vjust = .5 (same as \"middle\"), which centers the label.\n\nhjust = 1\n\n\nSWIM_bar +\n  geom_text(mapping = aes(label = Name_Year),   \n            col = \"black\",\n            size = 3,\n            fontface = \"bold\",\n            hjust = 1                         # or \"top\"\n            )"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#nudging-label-position",
    "href": "modules/22_annotation_and_text.html#nudging-label-position",
    "title": "Annotation and text",
    "section": "Nudging label position",
    "text": "Nudging label position\nThis position is still not quite right because the rightmost letter of the label terminates at the exact end of the bar. We will need to nudge the label just a little. Making the value negative will adjust the label down on the y axis. Because we have flipped the axes, nudging y negatively will nudge the label to the left.\n\nnudge_y = -0.5\n\n\nSWIM_bar +\n  geom_text(mapping = aes(label = Name_Year),   \n            col = \"black\",\n            size = 3,\n            fontface = \"bold\",\n            hjust = 1,                         # or \"top\"\n            nudge_y = -0.5\n            )"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#adding-additional-text-objects",
    "href": "modules/22_annotation_and_text.html#adding-additional-text-objects",
    "title": "Annotation and text",
    "section": "Adding additional text objects",
    "text": "Adding additional text objects\nYou can add additional text objects to plots or you can combine text object together as we have with the name and the year.\nThe bars don’t contain the swim times, so we can direct label them to the bars. In order to do so, we will adjust some of the same parameters as we adjusted earlier.\nTo visually distinguish the swim times from the other text, we could change properties like font size, face, color, etc.\n\nSWIM_bar +\n  geom_text(mapping = aes(label = Name_Year),   \n            col = \"black\",\n            size = 3,\n            fontface = \"bold\",\n            hjust = 1,                         # or \"top\"\n            nudge_y = -0.5\n  ) +\n  geom_text(mapping = aes(label = Seconds),    # map Seconds to label \n            col = \"grey40\",\n            #            family = \"Times New Roman\",\n            fontface = \"italic\",\n            #            vjust = 0,                        # set the vertical adjustment\n            hjust = 0,\n            nudge_x = 0.0,                     # no nudge\n            nudge_y = 0.05,                    # nudge up on y (right on x)\n            size = 3                           # set the vertical adjustment\n  )"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#removing-scale-breaks",
    "href": "modules/22_annotation_and_text.html#removing-scale-breaks",
    "title": "Annotation and text",
    "section": "Removing scale breaks",
    "text": "Removing scale breaks\nBecause we don’t need the athlete’s names on the axes, we can remove them. They are discrete labels so we can use scale_&lt;axis&gt;_&lt;type&gt;().\n\nscale_x_discrete(breaks = NULL) # remove the break labels (athlete names)\nscale_y_continuous(breaks = seq(50, 52.25, .25)) # add more breaks"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#removing-axis-lines-and-legend",
    "href": "modules/22_annotation_and_text.html#removing-axis-lines-and-legend",
    "title": "Annotation and text",
    "section": "Removing axis lines and legend",
    "text": "Removing axis lines and legend\nWe don’t the line for that axis either, which we can remove. Removing this will involve manipulating theme() objects.\nSetting axis.line.&lt;axis&gt; = element_blank()) will remove the line for that axis and legend.position = \"none\") will remove the legend.\n\ntheme(axis.line.y = element_blank())\ntheme(legend.position = \"none\")"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#setting-the-y-axis-limits",
    "href": "modules/22_annotation_and_text.html#setting-the-y-axis-limits",
    "title": "Annotation and text",
    "section": "Setting the y axis limits",
    "text": "Setting the y axis limits\nIn order to zoom into the plot, we can modify the limits. To change the limits for the y axis, we can set ylim as part of coord_flip(). You will want to address coordinate elements in a single coord_*() function, so set this here.\n\ncoord_flip(ylim = c(50, 52.25))"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#assembling-the-plot-layers",
    "href": "modules/22_annotation_and_text.html#assembling-the-plot-layers",
    "title": "Annotation and text",
    "section": "Assembling the plot layers",
    "text": "Assembling the plot layers\nPutting the pieces all together.\nWe can put all the plot layers together and add a title.\n\n# make an object\n(final_bar_plot &lt;- SWIM |&gt;\n  filter(Event == \"100 FREE\") |&gt;\n  filter(Team == \"Athena\") |&gt;\n  ggplot(mapping = aes(\n           x = forcats::fct_reorder(.f = Name_Year, \n                                    .x = Seconds, \n                                    .fun = min,\n                                    .desc = T),   # reorder the bars by Time\n           y = Seconds, \n           fill = RelativeFill\n         )\n  ) + \n  geom_col() +                        # column plot\n  coord_flip(ylim = c(50, 52.25)) +   # flip the coordinates\n  scale_fill_identity() +\n  scale_y_continuous(breaks = seq(50, 52.25, .25)) +\n  theme_classic() + \n  geom_text(mapping = aes(label = Name_Year),   \n            col = \"black\",\n            size = 3,\n            fontface = \"bold\",\n            hjust = 1,                         \n            nudge_y = -0.05\n            ) +\n  geom_text(mapping = aes(label = Seconds), # map Name to label\n\n            col = \"grey20\",\n            fontface = \"italic\",\n#            vjust = 0,                     # set the vertical adjustment\n            hjust = 0,\n            nudge_x = 0.0,                  # no nudge\n            nudge_y = 0.02,                 # nudge up on y (right on x)\n            size = 3.5                      # set the vertical adjustment\n            ) +\n  labs(title = \"The Fastest Athenas in the 100 Freestyle\",                    # title\n       subtitle = \"Event Year and Best Time\",              # subtitle\n       y = NULL,                             # remove x label and assoc. whitespace\n       x = NULL                              \n       ) +\n  scale_x_discrete(breaks = NULL) +          # remove the break labels (athlete names)\n  theme(legend.position = \"none\",\n        axis.line.y = element_blank()        # remove the line on x\n        ) \n)"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#adding-font-color-using-html-code-inlabs-and-rendering-withtheme",
    "href": "modules/22_annotation_and_text.html#adding-font-color-using-html-code-inlabs-and-rendering-withtheme",
    "title": "Annotation and text",
    "section": "Adding font color using HTML code inlabs() and rendering withtheme()",
    "text": "Adding font color using HTML code inlabs() and rendering withtheme()\nYou can decorate your text with color by passing HTML code to the labs() function. However, unlike geom_richtext(), the text containing HTML code will render as pure text unless you have the element rendered for markdown using element_markdown() with in the theme().\nIf your code appears as the pure HTML code, then you have likely overlooked this last part of the process.\nFor example, if you want to add a plot title and subtitle containing HTML code, you will pass the text to the labs(title = \"text\", subtitle = \"text\") function and then add (or edit) a theme() layer and make sure to have the plot.title and plot.subtitle rendered as element_markdown().\n\nChanging font face in theme() elements\nWithin the element_markdown() rendering, we can also set the font to bold or italics by specifying face.\nStep 1: Write your text Step 2: Edit your text to contain HTML breaks, colors, etc. Step 3: Pass your text to a function handling text objects (e.g., labs()) Step 4: Ensure your theme()contains the text object and the text object element is passed to the helper function element_markdown()\nExample code:\n# title layer with \nlabs(title = \"Just a Title\",\n     subtitle = \"Title part in default color and &lt;span style = 'color:red'&gt;part in color &lt;br&gt; a break and a break &lt;br&gt;/span&gt; and more text\"\n     ) +\n\n# theme layer with font face manipulation     \ntheme(\n     plot.title = element_markdown(face = \"bold\"),\n     plot.subtitle = element_markdown(face = \"italic\")\n     )\nRather than add the text in the labs() function directly, we will create separate string objects to pass into labs(). The title will be standard text without any HTML markup and the subtitle will contain HTML elements, external objects, and character strings.\n\ntitle_message &lt;- \"Fastest Athenas in the 100 m Freestyle from 2009 to 2022\"\n\nStart the title as plain text, then add some HTML for color, within which to add more text, then end the HTML chuck, then add external object followed by some more plain text.\n\nsubtitle_message &lt;- paste0(\"Five were &lt;span style = 'color:cornflowerblue'&gt;\",\n                           \"faster than the top 10 median time \", \"&lt;/span&gt;\",\n                           \"(\", median_seconds, \" seconds)\"\n                           )\n\nApply components to the plot:\n\nfinal_bar_plot +\n  labs(title = title_message,\n       subtitle = subtitle_message\n       ) +\n  theme(\n    plot.title = element_markdown(face = \"bold\"),\n    plot.subtitle = element_markdown(face = \"italic\")\n  )"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#adding-font-color-using-html-code-using-ggtextrichtext",
    "href": "modules/22_annotation_and_text.html#adding-font-color-using-html-code-using-ggtextrichtext",
    "title": "Annotation and text",
    "section": "Adding font color using HTML code using ggtext::richtext()",
    "text": "Adding font color using HTML code using ggtext::richtext()\nOne function from {ggtext} that is particularly useful is geom_richtext(), which will allow for passing html code styling to text labels. However, working with text as titles may be more difficult because you need to specificity the xy positions for the text objects to be placed. When you edit the text inside layers like labs(), those coordinates are already specified and don’t require you set them. An example is offered here, which creates two text objects using ggtext::geom_richtext(). As a word of warning, working with objects this way will require some readjustment of coordinates in order to make room for text positioned above the plot.\n\ngeom_richtext() works like geoms from {ggplot2} by mapping aesthetic properties\n\n\nplot_message &lt;- paste0(\"Faster than the&lt;br&gt;median (\", median_seconds, \" s)&lt;br&gt;of the top 10\")\n\nfinal_bar_plot +\n  # fixing coordinates to make space for title\n  coord_flip(xlim = c(1, 11),\n             ylim = c(50, 52.25)\n  ) +\n  labs(title = \"\", \n       subtitle = \"\"\n  ) +\n  # now add the text annotation\n  ggtext::geom_richtext(\n    x = 11.3, \n    y = 51,\n    size = 5,    \n    label = \"Fastest Athenas in the 100 m Freestyle (2009 - 2022)\",\n    fontface = \"bold\",\n    fill = NA,       # remove background \n    label.color = NA # remove outline\n  ) +\n  ggtext::geom_richtext(\n    x = 9, \n    y = 52,\n    size = 4, \n    label = paste0(\"&lt;span style = 'color:cornflowerblue'&gt;\", \n                   plot_message, \"&lt;/span&gt;\"\n    ),\n    fontface = \"bold\",\n    fill = NA,       # remove background \n    label.color = NA # remove outline\n  )\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#annotating-a-bar-plot",
    "href": "modules/22_annotation_and_text.html#annotating-a-bar-plot",
    "title": "Annotation and text",
    "section": "Annotating a bar plot ",
    "text": "Annotating a bar plot \nCreate a plot with a geom_segment() layer:\nWe will use geom_segment() to add a line segment from a starting xy coordinate position to an ending xy coordinate position.\n\nfinal_bar_plot +\n  geom_segment(aes(x = 0,                 # the starting x position\n                   y = median_seconds,    # the starting y position\n                   xend = 10.5,           # the ending x position\n                   yend = median_seconds  # the ending y position\n                   ), \n               color = \"black\", \n               #size = 1,\n               linetype = \"dashed\",\n               linewidth = .75\n               ) +\n  annotate(\"text\", \n           col = \"black\",\n           x = 9, # higher than the 10th bar\n           y = median_seconds + .05, \n           size = 3.5,\n           label = paste(\"median = \", median_seconds, sep = \" \"),\n           angle = 270,\n           fontface = \"italic\"\n  )\n\n\n\n\nCreate a plot with a geom_hline() layer:\nWe will now use geom_hline() to add a line segment which will be placed according to a yintercept specification.\n\nfinal_bar_plot +\n  geom_hline(yintercept = median_seconds,\n             col = \"grey40\",\n             linetype = \"dashed\",\n             linewidth = .1\n             ) +\n  annotate(\"text\", \n           col = \"cornflowerblue\",\n           x = 9, # higher than the 10th bar\n           y = median_seconds + .05, \n           size = 3.5,\n           label = paste(\"median = \", median_seconds, sep = \" \"),\n           angle = 270,\n           fontface = \"italic\"\n  )"
  },
  {
    "objectID": "modules/22_annotation_and_text.html#adding-font-color-to-text",
    "href": "modules/22_annotation_and_text.html#adding-font-color-to-text",
    "title": "Annotation and text",
    "section": "Adding font color to text",
    "text": "Adding font color to text\nThere are different ways to add code or other HTML formatting to plot objects. You can certainly edit the code and render as HTML is the theme() layer. The {ggtext} library offers some addition text detailing capability especially in cases where you want to place text is nontraditional locations. There are other ways too and will likely be more but these two options will take you some good distance.\n\nAdding font color using HTML code in labs() and rendering with theme()\nYou can decorate your text with color by passing HTML code to the labs() function. However, unlike geom_richtext(), the text containing HTML code will render as pure text unless you have the element rendered for markdown using element_markdown() with in the theme().\nIf your code appears as the pure HTML code, then you have likely overlooked this last part of the process.\nFor example, if you want to add a plot title and subtitle containing HTML code, you will pass the text to the labs(title = \"text\", subtitle = \"text\") function and then add (or edit) a theme() layer and make sure to have the plot.title and plot.subtitle rendered as element_markdown().\n\nChanging font face in theme() elements\nWithin the element_markdown() rendering, we can also set the font to bold or italics by specifying face.\nStep 1: Write your text Step 2: Edit your text to contain HTML breaks, colors, etc. Step 3: Pass your text to a function handling text objects (e.g., labs()) Step 4: Ensure your theme()contains the text object and the text object element is passed to the helper function element_markdown()\nExample code:\n# title layer with \nlabs(title = \"Just a Title\",\n     subtitle = \"Title part in default color and &lt;span style = 'color:red'&gt;part in color &lt;br&gt; a break and a break &lt;br&gt;/span&gt; and more text\"\n     ) +\n\n# theme layer with font face manipulation     \ntheme(\n     plot.title = element_markdown(face = \"bold\"),\n     plot.subtitle = element_markdown(face = \"italic\")\n     )\nRather than add the text in the labs() function directly, we will create separate string objects to pass into labs(). The title will be standard text without any HTML markup and the subtitle will contain HTML elements, external objects, and character strings.\n\ntitle_message &lt;- \"Fastest Athenas in the 100 m Freestyle from 2009 to 2022\"\n\nStart the title as plain text, then add some HTML for color, within which to add more text, then end the HTML chuck, then add external object followed by some more plain text.\n\nsubtitle_message &lt;- paste0(\"Five were &lt;span style = 'color:cornflowerblue'&gt;\",\n                           \"faster than the top 10 median time \", \"&lt;/span&gt;\",\n                           \"(\", median_seconds, \" seconds)\"\n                           )\n\nApply components to the plot:\n\nfinal_bar_plot +\n  labs(title = title_message,\n       subtitle = subtitle_message\n       ) +\n  theme(\n    plot.title = element_markdown(face = \"bold\"),\n    plot.subtitle = element_markdown(face = \"italic\")\n  )\n\n\n\n\n\n\n\nAdding font color using HTML code using ggtext::richtext()\nOne function from {ggtext} that is particularly useful is geom_richtext(), which will allow for passing html code styling to text labels. However, working with text as titles may be more difficult because you need to specificity the xy positions for the text objects to be placed. When you edit the text inside layers like labs(), those coordinates are already specified and don’t require you set them. An example is offered here, which creates two text objects using ggtext::geom_richtext(). As a word of warning, working with objects this way will require some readjustment of coordinates in order to make room for text positioned above the plot.\n\ngeom_richtext() works like geoms from {ggplot2} by mapping aesthetic properties\n\n\nplot_message &lt;- paste0(\"Faster than the&lt;br&gt;median (\", median_seconds, \" s)&lt;br&gt;of the top 10\")\n\nfinal_bar_plot +\n  # fixing coordinates to make space for title\n  coord_flip(xlim = c(1, 11),\n             ylim = c(50, 52.25)\n  ) +\n  labs(title = \"\", \n       subtitle = \"\"\n  ) +\n  # now add the text annotation\n  ggtext::geom_richtext(\n    x = 11.3, \n    y = 51,\n    size = 5,    \n    label = \"Fastest Athenas in the 100 m Freestyle (2009 - 2022)\",\n    fontface = \"bold\",\n    fill = NA,       # remove background \n    label.color = NA # remove outline\n  ) +\n  ggtext::geom_richtext(\n    x = 9, \n    y = 52,\n    size = 4, \n    label = paste0(\"&lt;span style = 'color:cornflowerblue'&gt;\", \n                   plot_message, \"&lt;/span&gt;\"\n    ),\n    fontface = \"bold\",\n    fill = NA,       # remove background \n    label.color = NA # remove outline\n  )\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one."
  },
  {
    "objectID": "modules/24_attentional_control.html#external-functions",
    "href": "modules/24_attentional_control.html#external-functions",
    "title": "Attentional control",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))\nsource(\"https://raw.githubusercontent.com/slicesofdata/dataviz23/main/R/functions/describe.R\")\n\nDefining describe.R\n\n\nDone Defining describe.R"
  },
  {
    "objectID": "modules/24_attentional_control.html#libraries",
    "href": "modules/24_attentional_control.html#libraries",
    "title": "Attentional control",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting\n{ggrepel} 0.9.3: for repelling labels from points and lines\n{geomtextpath} 0.1.1: for annotation of curved paths (also straight)\n{gghighlight} 0.4.0: for highlighting lines and points\n{ggtext} 0.1.2: for text on plots; markdown elements (viz, element_markdown)"
  },
  {
    "objectID": "modules/24_attentional_control.html#increase-the-size-of-axis-labels",
    "href": "modules/24_attentional_control.html#increase-the-size-of-axis-labels",
    "title": "Attentional control",
    "section": "Increase the size of axis labels",
    "text": "Increase the size of axis labels\nFor each axis.text.&lt;axis&gt;, you can adjust the element_text().\n\naxis.text.x = element_text(size = 12)\naxis.text.y = element_text(size = 12)\n\n\n(base_plot &lt;- DATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .8,\n             position = position_jitter(height = 0, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        )\n)\n\n\n\n\nNotice that this adjustment does not increase the legend text size too. This is a different element."
  },
  {
    "objectID": "modules/24_attentional_control.html#increase-the-size-of-the-legend-labels",
    "href": "modules/24_attentional_control.html#increase-the-size-of-the-legend-labels",
    "title": "Attentional control",
    "section": "Increase the size of the legend labels",
    "text": "Increase the size of the legend labels\n\nlegend.text = element_text(size = 12)\n\n\nbase_plot +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12),  # y-axis size\n        legend.text = element_text(size = 12)   # legend text size\n        )"
  },
  {
    "objectID": "modules/24_attentional_control.html#increase-the-size-of-the-legend-shapes",
    "href": "modules/24_attentional_control.html#increase-the-size-of-the-legend-shapes",
    "title": "Attentional control",
    "section": "Increase the size of the legend ‘shapes’",
    "text": "Increase the size of the legend ‘shapes’\nWe have already addressed how to make legend shape elements larger too. This adjustment is in the guides() and requires overriding aesthetics. We need to add a guides() layer. Importantly, you need to be careful to specify the aesthetic mapped, in this case col. If you mapped a variable to a discrete color, then you will need to change the size of the col aesthetics. If you mapped a variable to a shape, and you want to increase the size of the shapes, then you will need to change the size of the shape aesthetics.\n\nguides(&lt;aesthetic mapped&gt; = guide_legend(override.aes = list(size = 3)))\n\nIn this example, col was mapped and the goal is to change the size of the color ‘shape’ so the solution is:\n\nguides(col = guide_legend(override.aes = list(size = 3)))\n\nThere is no shape mapping, so changing the size of the shape will not work:\n\nguides(shape = guide_legend(override.aes = list(size = 3)))\n\n\nbase_plot +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12),  # y-axis size\n        legend.text = element_text(size = 12)   # legend text size\n        ) +\n  guides(col = guide_legend(override.aes = list(size = 3)))"
  },
  {
    "objectID": "modules/24_attentional_control.html#passing-objects-for-adjustments",
    "href": "modules/24_attentional_control.html#passing-objects-for-adjustments",
    "title": "Attentional control",
    "section": "Passing objects for adjustments",
    "text": "Passing objects for adjustments\nOf course, the points on the plot are small too, so you would want to adjust them if necessary. We can use some objects to make the process easier. If you want to apply the same approach to many or all plots you create, you might just prefer to create a custom theme().\n\npoint_size &lt;- 3\nfont_size  &lt;- 11\n\nbase_plot +\n  theme(\n        # the axis text in general\n        axis.text = element_text(size = font_size),     # both and ticks\n        # or specifically\n        #axis.text.x = element_text(size = font_size),  # x-axis size\n        #axis.text.y = element_text(size = font_size),  # y-axis size\n        \n        # the title label\n        axis.title = element_text(size = font_size + 3),  # bump it up relatively\n        \n        # the legend text\n        legend.title = element_text(size = font_size + 1),  # legend title, bump up if desired\n        legend.text = element_text(size = font_size)    # legend text size\n        ) +\n  guides(col = guide_legend(override.aes = list(size = point_size)))"
  },
  {
    "objectID": "modules/24_attentional_control.html#adding-reference-points",
    "href": "modules/24_attentional_control.html#adding-reference-points",
    "title": "Attentional control",
    "section": "Adding reference points",
    "text": "Adding reference points\nLet’s say you want to highlight a data point or location of interest. We can do so by specifying the point or region.\nThere are a few ways to address this. You can use stat_summary() to draw attention to a place on the plot, the mean of the variable mapped to y.\n\nbase_plot +\n  stat_summary(\n    fun = \"mean\",        # the summary function\n    geom = \"point\",      # the geom \n    #shape = 23,         # the geom_point shape if you wish to change it \n    size = 3,            # the color \n    #fill = \"grey\",      # fill color if your point has fill \n    col = \"grey20\",        # the color\n    alpha = .8\n    )\n\n\n\n\nWhereas stat_summary() applies the function to the groups, you may wish to highlight a single point. When this is the case, you will use different data than what you pass to the ggplot() object.\nThe best athlete.\n\n( best_2019 &lt;- DATA |&gt; filter(Year == 2019) |&gt;  slice_max(Score) )\n\n# A tibble: 1 × 7\n  Athlete        Rank Score Meet                               Date  Team   Year\n  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                              &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Sill, Michael     2  49.8 SCIAC Track & Field Conference Ch… Apr … Stag   2019\n\n\nWhen only x or y matters, you can specify that single point.\n\n( mean_y_2019 &lt;- DATA |&gt; filter(Year == 2019) |&gt;  pull(Score) |&gt; mean() )\n\n[1] 39.37329\n\n\nWhen x and y matter, you may wish to specify that point.\n\n( mean_xy_2019 &lt;- DATA |&gt; \n  filter(Year == 2019) |&gt;  \n  summarize(Rank = mean(Rank, na.rm = T),\n            Score = mean(Score, na.rm = T)\n  )\n)  \n\n# A tibble: 1 × 2\n   Rank Score\n  &lt;dbl&gt; &lt;dbl&gt;\n1  2.54  39.4\n\n( team_mean_xy_2019 &lt;- DATA |&gt; \n  filter(Year == 2019) |&gt;  \n  group_by(Team) |&gt;\n  summarize(Rank = mean(Rank, na.rm = T),\n            Score = mean(Score, na.rm = T)\n  )\n) \n\n# A tibble: 2 × 3\n  Team    Rank Score\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Athena  2.42  32.4\n2 Stag    2.64  45.0"
  },
  {
    "objectID": "modules/24_attentional_control.html#adding-reference-line",
    "href": "modules/24_attentional_control.html#adding-reference-line",
    "title": "Attentional control",
    "section": "Adding reference line",
    "text": "Adding reference line\nLet’s plot a horizontal line using geom_hline() to direct attention for reference or comparison.\n\nbase_plot +\n  geom_hline(yintercept = mean_y_2019)\n\n\n\n\nLet’s add a label easily using {geomtextpath}:\n\nbase_plot +\n  geomtextpath::geom_texthline(yintercept = mean_y_2019,\n                               label = \"2019 average\",\n                               alpha = .5\n                               )\n\n\n\n\nNotice, we are only specifying a place for all athletes rather than for Stags and Athenas separately."
  },
  {
    "objectID": "modules/24_attentional_control.html#adding-reference-point-with-annotation",
    "href": "modules/24_attentional_control.html#adding-reference-point-with-annotation",
    "title": "Attentional control",
    "section": "Adding reference point with annotation",
    "text": "Adding reference point with annotation\n\nannotate(geom = \"point\")\nUse annotate() to plot a point to highlight some element using geom = \"point\".\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  )\n\n\n\n\n\n\nannotate(geom = \"point\") and annotate(geom = \"text\")\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  annotate(geom = \"text\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score - 1, \n           label = \"mean\",\n           size = 3\n  )\n\n\n\n\n\n\ngeom_curve() with arrow()\nDirect attention with annotation and an arrow.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  annotate(geom = \"text\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score - 1, \n           label = \"mean\",\n           size = 3\n  ) +\n  geom_curve(x = mean_xy_2019$Rank,                 # where the curve begins\n             y = mean_xy_2019$Score,\n             xend = mean_xy_2019$Rank + .2,          # where the curve ends\n             yend = mean_xy_2019$Score + 2,\n             color = \"grey20\", \n             arrow = arrow(angle = 20,              # angle of the arrow\n                           length = unit(0.25,\"cm\"),\n                           ends = \"first\",          # \"last\", \"first\", or \"both\"\n                           type = \"closed\"          # \"open\" or \"closed\" triangle\n                           ),\n             curvature = 1                        # the amount of curvature (0 is a line, not a curve) \n             ) \n\n\n\n\nBut the arrow point is overlapping the mean point. Let’s back off. Also, if you won’t be getting new data, you can set the coordinates to static values. This plot reflects a series of edits.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  annotate(geom = \"text\", \n           col = \"grey20\",\n           x = 2,\n           y = 19, \n           label = \"mean\",\n           size = 4\n  ) +\n  geom_curve(x = mean_xy_2019$Rank - .04,           # where the curve begins\n             y = mean_xy_2019$Score - 1,\n             xend = 2,                              # where the curve ends\n             yend = 20,\n             color = \"grey20\", \n             arrow = arrow(angle = 20,              # angle of the arrow\n                           length = unit(0.25,\"cm\"),\n                           ends = \"first\",          # \"last\", \"first\", or \"both\"\n                           type = \"closed\"          # \"open\" or \"closed\" triangle\n                           ),\n             curvature = 0.1                        # the amount of curvature (0 is a line, not a curve) \n             ) \n\n\n\n\n\n\ngeomtextpath::geom_textcurve()\nDirect attention with annotation along the line.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  geomtextpath::geom_textcurve(\n    x = mean_xy_2019$Rank - .04,\n    y = mean_xy_2019$Score - 1,\n    xend = 2,\n    yend = 20,\n    curvature = .1,\n    hjust = .5,                                      # label at start (1), end (0), or other (.5 = center)  \n    vjust = 0,\n    col = \"black\",\n    arrow = arrow(ends = \"first\"),\n    label = \"mean\"                                   # label required (this replaces annotate() layer)\n  )\n\n\n\n\nWarning: If your label is too long, fore example \"overall mean\", R will throw an error.\nError: Cannot create zero-length unit vector (\"unit\" subsetting)\n\n\nDefining an arrow()\nLet’s make an arrow to reuse. The default is ugly.\n\nmy_arrow &lt;- arrow(angle = 20,              \n                  length = unit(0.25,\"cm\"),\n                  ends = \"first\",          \n                  type = \"closed\"          \n                  )\n\nYou can change the font size to a smaller value, for example, size = 2.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey20\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 3\n  ) +\n  geomtextpath::geom_textcurve(\n    x = mean_xy_2019$Rank - .04,\n    y = mean_xy_2019$Score - 1,\n    size = 2,\n    xend = 2,\n    yend = 20,\n    curvature = .1,\n    hjust = .5,                                      # label at start (1), end (0), or other (.5 = center)  \n    vjust = 0,\n    col = \"black\",\n    arrow = my_arrow,\n    label = \"overall mean\"                                      # label required (this replaces annotate() layer)\n  )\n\n\n\n\nOK, too small. You can also change the length to the curve or line by changing xend and yend. Also, accepting the default justification serves you well enough, so let’s comment out.\n\nbase_plot +\n  annotate(geom = \"point\", \n           col = \"grey40\",\n           x = mean_xy_2019$Rank, \n           y = mean_xy_2019$Score, \n           size = 2\n  ) +\n  geomtextpath::geom_textcurve(\n    x = mean_xy_2019$Rank - .04,\n    y = mean_xy_2019$Score - 1,\n    #size = 2,\n    xend = 1.5,\n    yend = 20,\n    curvature = 0,\n#    hjust = .5,                                      # label at start (1), end (0), or other (.5 = center)  \n#    vjust = 0,\n    col = \"grey40\",\n    arrow = my_arrow,\n    fontface = \"bold\",\n    label = \"overall mean\"                                      # label required (this replaces annotate() layer)\n  )\n\n\n\n\n\n\ngeomtextpath::geom_textcurve() with a new data frame\nIn the previous example, we set the coordinates from outside of aes(). This was done to show you that you could control the coordinates manually. In this example, we will take a new data frame and set data = best_2019. We will map x and y and then set xmin and ymin either because they do not exist in the data frame or because we just don’t want to map them.\n\nDATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .75,\n             position = position_jitter(height = 0, width = .1, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        ) +\n  geomtextpath::geom_textcurve(\n    data = best_2019,                           # the data frame with the best athlete\n    mapping = aes(x = Rank,\n                  y = Score,\n                  label = paste(Score, Athlete, sep = \"m  \")\n                  ),\n    xend = 3.5,\n    yend = 60,\n    size = 3,\n    curvature = -.1,\n    arrow = my_arrow,\n    col = \"black\"\n  )\n\n\n\n\nNote: With {geomtextpath} text objects, if you receive the following error: Error: Cannot create zero-length unit vector (\"unit\" subsetting), this may reflect that your plot space in RStudio is too small to render the object correctly. Your code may not be in error. Simply increase the size of your plot space environment in RStudio.\n\n\ngeomtextpath::geom_labelcurve()\nSame thing using geomtextpath::geom_labelcurve().\n\nDATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .75,\n             position = position_jitter(height = 0, width = .1, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        ) +\n  geomtextpath::geom_labelcurve(\n    data = best_2019,                             # the data frame with the best athlete\n    mapping = aes(x = Rank,\n                  y = Score,\n                  label = paste(Score, Athlete, sep = \"m  \")\n                  ),\n    xend = 3.5,\n    yend = 60,\n    size = 3,\n    curvature = -.1,\n    arrow = my_arrow,\n    col = \"black\",\n  )\n\n\n\n\nOne issue with geom_textcurve() and geom_labelcurve() is the difficulty controlling the size of the content and the length of the line.\n\n\ngeomtextpath::geom_textline()\n\nDATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .75,\n             position = position_jitter(height = 0, width = .1, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        ) +\n  geomtextpath::geom_textline(\n    data = best_2019,                             # the data frame with the best athlete\n    mapping = aes(x = Rank,\n                  y = Score,\n                  label = paste(Score, Athlete, sep = \"m  \")\n                  ),\n    size = 3,\n    col = \"black\",\n  )\n\n\n\n\nBut the line is directly over the point. You can add values to x and y to move it. For example, aes(x = Score + 2, ...) but that might still look odd without an arrow. This adjustment is nevertheless made in the next example using geom_labelline().\n\n\ngeomtextpath::geom_labelline()\nIf you want to geomtextpath::geom_labelline():\n\nDATA |&gt;\n  filter(Year == 2019) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       col = Team\n                       )\n         ) +\n  geom_point(size = 2.2,\n             alpha = .75,\n             position = position_jitter(height = 0, width = .1, seed = 167)\n             ) +\n  ylim(0, 60) +\n  theme(axis.text.x = element_text(size = 12),  # x-axis size\n        axis.text.y = element_text(size = 12)   # y-axis size\n        ) +\n  geomtextpath::geom_labelline(\n    data = best_2019,                             # the data frame with the best athlete\n    mapping = aes(x = Rank,\n                  y = Score + 5,\n                  label = paste(Year, \" Top Athlete\\n\", Score, \"m \", Athlete, sep = \"\"),\n                  ),\n    size = 4,\n#    fontface = \"bold\",\n    col = \"black\",\n  )"
  },
  {
    "objectID": "modules/24_attentional_control.html#drawing-attention-to-a-bar",
    "href": "modules/24_attentional_control.html#drawing-attention-to-a-bar",
    "title": "Attentional control",
    "section": "Drawing attention to a bar",
    "text": "Drawing attention to a bar\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  group_by(Rank) |&gt;\n  summarize(Score = mean(Score, na.rm = T)) |&gt;\n  mutate(Rank_Color = case_when(\n    Rank == 1 ~ \"goldenrod\",\n    Rank &gt;  1 ~ \"grey60\",\n    TRUE ~ \"grey60\"\n    )) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       fill = Rank_Color\n                       )\n         ) +\n  geom_col() +\n  scale_fill_identity()"
  },
  {
    "objectID": "modules/24_attentional_control.html#drawing-attention-to-a-bar-using-gghighlight",
    "href": "modules/24_attentional_control.html#drawing-attention-to-a-bar-using-gghighlight",
    "title": "Attentional control",
    "section": "Drawing attention to a bar using {gghighlight}",
    "text": "Drawing attention to a bar using {gghighlight}\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  group_by(Rank) |&gt;\n  summarize(Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       fill = factor(Rank)\n                       )\n         ) +\n  geom_col() +\n  gghighlight(Score &gt; 45, \n              unhighlighted_params = list(fill = \"black\")\n              )"
  },
  {
    "objectID": "modules/24_attentional_control.html#highlighting-lines",
    "href": "modules/24_attentional_control.html#highlighting-lines",
    "title": "Attentional control",
    "section": "Highlighting lines",
    "text": "Highlighting lines\nYou can use geomtextpath::geom_labelline() to label lines. In this example, we label lines with athlete names. Specifically, we will group and obtain best scores for each athlete’s participating year then get the count for rows and filter for athletes who participated in all 4 years.\ngroup_by(Athlete, Rank) |&gt;\nsummarize(Max_Score = max(Score), .groups = \"keep\") |&gt;\ngroup_by(Athlete) |&gt;\nmutate(Count = n()) |&gt;\nfilter(Count == 4) \n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  mutate(Point_Color = case_when(\n    Team == \"Stag\" ~ \"grey60\",\n    Team == \"Athena\" ~ \"goldenrod\",\n  )) |&gt;\n  group_by(Athlete, Rank) |&gt;\n  summarize(Max_Score = max(Score), .groups = \"keep\") |&gt;\n  group_by(Athlete) |&gt;\n  mutate(Count = n()) |&gt;\n  filter(Count == 4) |&gt;\n  ggplot(mapping = aes(x = Rank,\n                       y = Max_Score,\n                       col = Athlete\n                       )\n         ) +\n  geom_point(size = 2) + \n  geom_line(linewidth = 1) +\n  geomtextpath::geom_labelline(\n    mapping = aes(label = stringr::str_replace(\n      Athlete, \"^(\\\\w+),\\\\s(\\\\w+)\", \"\\\\2 \\\\1\")\n    ))"
  },
  {
    "objectID": "modules/24_attentional_control.html#highlighting-with-gghighlight",
    "href": "modules/24_attentional_control.html#highlighting-with-gghighlight",
    "title": "Attentional control",
    "section": "Highlighting with {gghighlight}",
    "text": "Highlighting with {gghighlight}\nClearly, the legend is no longer needed so that could be removed. Also, the name labels are a bit of a mess. One approach is to use {gghighlight} and gghighlight::gghighlight() which by default will move the labels.\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  mutate(Point_Color = case_when(\n    Team == \"Stag\" ~ \"grey60\",\n    Team == \"Athena\" ~ \"goldenrod\",\n  )) |&gt;\n  group_by(Athlete, Rank) |&gt;\n  summarize(Max_Score = max(Score), .groups = \"keep\") |&gt;\n  group_by(Athlete) |&gt;\n  mutate(Count = n()) |&gt;\n  filter(Count == 4) |&gt;\n  ggplot(mapping = aes(x = Rank,\n                       y = Max_Score,\n                       col = Athlete\n                       )\n         ) +\n  geom_point(size = 2) + \n  geom_line(linewidth = 1) +\n  gghighlight::gghighlight()\n\nlabel_key: Athlete"
  },
  {
    "objectID": "modules/24_attentional_control.html#highlighting-specific-data-with-gghighlight",
    "href": "modules/24_attentional_control.html#highlighting-specific-data-with-gghighlight",
    "title": "Attentional control",
    "section": "Highlighting specific data with {gghighlight}",
    "text": "Highlighting specific data with {gghighlight}\ngghighlight::gghighlight() will take expressions for filtering the data. We can highlight subsets of the data based on a function we pass.\nFor example, mean(Mean_Score) &gt; 45 will highlight lines for which the condition is met.\n\ngghighlight::gghighlight(mean(Mean_Score) &gt; 45)\n\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  mutate(Point_Color = case_when(\n    Team == \"Stag\" ~ \"grey60\",\n    Team == \"Athena\" ~ \"goldenrod\",\n  )) |&gt;\n  group_by(Athlete, Rank) |&gt;\n  summarize(Mean_Score = mean(Score), \n            Max_Score = max(Score),\n            .groups = \"keep\") |&gt;\n  group_by(Athlete) |&gt;\n  mutate(Count = n()) |&gt;\n  filter(Count == 4) |&gt;\n  ggplot(mapping = aes(x = Rank,\n                       y = Max_Score,\n                       col = Athlete\n                       )\n         ) +\n  # add point plot\n  geom_point(size = 2) + \n  # add a line plot\n  geom_line(linewidth = 1) +\n  # highlight conditions met\n  gghighlight::gghighlight(mean(Mean_Score) &gt; 45) +\n  labs(title = \"My Title\",\n       subtitle = \"Out of the 5 athletes who participated all college years, only two maintained an average higher than 45 across meets each year\") +\n  theme(plot.title = element_markdown(face = \"bold\"),\n        plot.subtitle = element_markdown(face = \"italic\"),\n        )\n\nlabel_key: Athlete"
  },
  {
    "objectID": "modules/24_attentional_control.html#highlighting-a-region-using-annotate",
    "href": "modules/24_attentional_control.html#highlighting-a-region-using-annotate",
    "title": "Attentional control",
    "section": "Highlighting a region using annotate()",
    "text": "Highlighting a region using annotate()\nUsing geom = \"text\", you can annotate the plot with a rectangle to represent an area of interest. You can think of To draw a rectangle to highlight an area of interest in three useful ways.\n\nTo highlight a vertical band stretching the entire y-axis, beginning and ending at x-axis locations.\nTo highlight a horizontal band stretching the entire x-axis, beginning and ending y-axis locations.\nTo highlight a rectangle, beginning and ending x-axis and y-axis locations\n\nBonus: You can create more than one of any of the preceding.\n\nHighlighting a slice of the x-axis using annotate()\nFor this, we will specify:\n\nxmin: beginning point of x\nxmax: ending point of x\nymin: beginning point of y\n\nymax: ending point of y\nfill: the color inside the rectangle\nalpha: the alpha of the fill color inside the rectangle\ncol: the line border of the rectangle\nlinewidth: the line thickness of the border\nlinetype: the type of the line border\n\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # add point plot\n  geom_point(size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1)) +\n  # make the rectangle\n  annotate(geom = \"rect\", \n           xmin = 2012.5,            # beginning point of x\n           xmax = 2013.5,            # ending point of x\n           ymin = -Inf,              # make the rectangle extend along y  \n           ymax = Inf,               # make the rectangle extend along y\n           fill = \"goldenrod\",       # the color inside the rectangle\n           alpha = 0.25,             # the alpha of the fill color inside the rectangle\n           col = \"black\",            # the line border of the rectangle\n           linewidth = .5,           # the line thickness of the border \n           linetype = \"solid\"        # the type of the line border\n           ) +\n  theme_classic()\n\n\n\n\n\n\nHighlighting a slice of the y-axis using annotate()\nSome elements of the rectangle are removed here and the annotate() layer is added before the points to remind you that layers build on top of each other. Even with transparency of the fill of the rectangle, adding the layer after previous geoms (points in this instance) will result in a visualization that creates the perception of the rectangle covering, and thus, adding color to, the points behind it. If you wish the highlighted region to fade into the background and allow the points to float on top of the rectangle, make sure that your layer order achieves that goal.\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # make the rectangle\n  annotate(geom = \"rect\", \n           xmin = -Inf,           # beginning point of x\n           xmax = Inf,            # ending point of x\n           ymin = 55,             # make the rectangle extend along y  \n           ymax = 65,             # make the rectangle extend along y\n           fill = \"goldenrod\",    # the color inside the rectangle\n           alpha = 0.25           # the alpha of the fill color inside the rectangle\n           ) +\n  # add point plot\n  geom_point(size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1)) +\n  theme_classic()\n\n\n\n\n\n\nHighlighting a slice of the y-axis using geom_rect()\nUsing annotate() along with geom = \"rect\". However, you can certainly use geom_rect() to build a rectangle.\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # add the rectangle\n  geom_rect(xmin = -Inf, \n            xmax = Inf,\n            ymin = 55,         \n            ymax = 65,         \n            fill = \"goldenrod\", \n            alpha = .25,              # same alpha\n            ) +\n  # add point plot\n  geom_point(size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1)) +\n  theme_classic()\n\n\n\n\nNotice the color differences. We will address this curiosity later.\n\n\nHighlighting a rectangle using annotate()\nWhen you have a rectangular area of interest, build an actual rectangle. We will also create a data summary based on a subset of athletes and years to obtain the 95% confidence interval for all performances during those years. There is no particular reason those this type of data but this could represent a significant time period.\n\nDATA_CI95 &lt;- DATA |&gt;\n  filter(Team == \"Stag\") |&gt;             # get stag only\n  filter(!is.na(Rank)) |&gt;\n  filter(Year %in% c(2016:2020)) |&gt;\n  summarize(xmin = min(Year),\n            xmax = max(Year),\n            ymin = mean(Score, na.rm = T) - (1.96 * sd(Score, na.rm = T)),\n            ymax = mean(Score, na.rm = T) + (1.96 * sd(Score, na.rm = T)),\n            )\n\n\nDATA |&gt;\n  filter(Team == \"Stag\") |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # build the rectangle based on the subset summary\n  annotate(geom = \"rect\",\n           xmin = DATA_CI95$xmin - .5, # add a buffer to highlight the jittered points\n           xmax = DATA_CI95$xmax + .5, # add a buffer to highlight the jittered points\n           ymin = DATA_CI95$ymin,         \n           ymax = DATA_CI95$ymax,         \n           fill = \"firebrick\", \n           alpha = .25,              \n           ) +\n  # add point plot\n  geom_point(size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1))\n\n\n\n\nDuring this time period, you can see there are a few event performances (not athletes) outside this confidence section. However, in other years, there some performances that fall quite above that range.\n\n\nHighlighting two slices of the x-axis using annotate()\nBecause Year and Score are mapped already, we can simply create these two variables in the data frame. If they are not in the data frame, you will get an error and need to troubleshoot. Adding them is a simple solution. As long as the variable type created is the same as the variable in the other data frame, you will be OK. In this instance, we can just add a numeric value that is within the plot coordinates. The mean will ensure this.\n\n(DATA_topbottom &lt;- DATA |&gt;\n  filter(Team == \"Stag\") |&gt;             # get stag only\n  filter(!is.na(Rank)) |&gt;\n  mutate(Decile = ntile(Score, 10)) |&gt;\n  group_by(Decile) |&gt;\n  summarize(xmin = -Inf,\n            xmax = Inf,\n            ymin = min(Score, na.rm = T),\n            ymax = max(Score, na.rm = T),\n            Year = mean(Year, na.rm = T),   # a numeric value needs to be added \n            Score = mean(Score, na.rm = T)  # a numeric value needs to be added \n            ) |&gt; \n  ungroup() |&gt;\n  filter(Decile %in% c(1,10))   # keep data in the top and bottom decile\n)\n\n# A tibble: 2 × 7\n  Decile  xmin  xmax  ymin  ymax  Year Score\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  -Inf   Inf  5.32  33.9 2017.  29.7\n2     10  -Inf   Inf 51.0   61.6 2013.  55.0\n\n\nWe now have a data frame with two rows, one for the top decile and one for the bottom. Let’s add a geom_rect() and specify data = DATA_topbottom and then map the variables to the required aesthetics.\n\nDATA |&gt;\n  filter(Team == \"Stag\") |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Year,\n                       y = Score\n                       )\n         ) +\n  # build the rectangle based on new data\n  geom_rect(data = DATA_topbottom,\n            mapping = aes(xmin = xmin,\n                          xmax = xmax,\n                          ymin = ymin,\n                          ymax = ymax, \n                          fill = factor(Decile)\n                          ),\n            alpha = .2,              \n           ) +\n  # add point plot\n  geom_point(mapping = aes(col = factor(Year)),\n             size = 2,\n             alpha = .3,\n             position = position_jitter(height = 0, width = .25, seed = 167)\n  ) +\n  scale_x_continuous(breaks = seq(2010, 2023, 1)) +\n  coord_flip() + \n  labs(x = NULL) + \n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\nRemoving the legend and instead either direct labeling the deciles or using color in the title to clarify them will help communicate the intent of these bands without the legend taking up so much real estate. And of course, you could add a color variable to the data frame and scale_color_identity() the color for the 1st and 10th decile. If you are already using color for the points, then coloring them would be challenging. You could use filled shapes and add a black color ring around them or change the stroke. But using a rectangle might serve a useful purpose. Whatever you do to draw attention to plot elements, ensure that your audience understands your intent.\n\n\nComparing annotate() versus geom_rect()\nWhy introduce you to both approaches if they can achieve the same outcome? Well, notice the difference between the rectangle added with annotate() and geom_rect() when the alpha is the same. Although alpha = .25 in both some instances, geom_rect() draws a darker rectangle.\nWhy? Remember that geoms will iterate for each row in the data frame. Because the variables are mapped to aesthetics in geom_rect(), the rectangle is built over and over again. You can experience this with the time required to build the plot when there are many rows. If you want more control over alpha, you might consider annotate()."
  },
  {
    "objectID": "modules/24_attentional_control.html#fading-out-bars-by-mapping-a-variable-to-alpha",
    "href": "modules/24_attentional_control.html#fading-out-bars-by-mapping-a-variable-to-alpha",
    "title": "Attentional control",
    "section": "Fading out bars by mapping a variable to alpha",
    "text": "Fading out bars by mapping a variable to alpha\nWe will just adjust alpha in the data frame by the conditional.\n\nDATA |&gt;\n  filter(!is.na(Rank)) |&gt;\n  group_by(Rank) |&gt;\n  summarize(Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  mutate(\n    cutoff = 41,\n    Alpha = case_when(\n      Score &lt;= cutoff ~ .5,\n      TRUE ~ 1\n  )) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       fill = factor(Rank),\n                       alpha = Alpha\n                       )\n         ) +\n  geom_col()"
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#external-functions",
    "href": "modules/23_multi_panel_plots_faceting.html#external-functions",
    "title": "Multi-panel plots: Faceting",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#libraries",
    "href": "modules/23_multi_panel_plots_faceting.html#libraries",
    "title": "Multi-panel plots: Faceting",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{forcats} 1.0.0: for creating and ordering factors\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#creating-facets-using-facet_wrap",
    "href": "modules/23_multi_panel_plots_faceting.html#creating-facets-using-facet_wrap",
    "title": "Multi-panel plots: Faceting",
    "section": "Creating facets using facet_wrap()",
    "text": "Creating facets using facet_wrap()\nWe see an overall pattern in the data. We can see a pattern for the Team subgroups across Rank.\nWe can add a facet_wrap() layer in order to plot the teams separately.\n\nbase_plot +\n  facet_wrap(facets = ~Team)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can add a facet_wrap() layer in order to plot separately per year.\n\nbase_plot +\n  facet_wrap(facets = ~Year)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#creating-facets-using-facet_wrapfacets-vars",
    "href": "modules/23_multi_panel_plots_faceting.html#creating-facets-using-facet_wrapfacets-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "Creating facets using facet_wrap(facets = vars())",
    "text": "Creating facets using facet_wrap(facets = vars())\nUse vars() instead of ~ to specify the variable.\n\nbase_plot +\n  facet_wrap(facets = vars(Year))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\nPassing two variables to vars() will create subplots for each.\n\nbase_plot +\n  facet_wrap(facets = vars(Year, Team))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#controlling-columns",
    "href": "modules/23_multi_panel_plots_faceting.html#controlling-columns",
    "title": "Multi-panel plots: Faceting",
    "section": "Controlling columns",
    "text": "Controlling columns\nControl the number of columns by setting ncol.\n\nbase_plot +\n  facet_wrap(facets = vars(Year),\n             ncol = 3\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#controlling-direction-of-arrangement",
    "href": "modules/23_multi_panel_plots_faceting.html#controlling-direction-of-arrangement",
    "title": "Multi-panel plots: Faceting",
    "section": "Controlling direction of arrangement",
    "text": "Controlling direction of arrangement\nChange the direction using dir. By default, dir = \"h for a horizontal arrangement. The faceted variable changes from left to right, and top to bottom. Change to dir = \"v\".\n\nbase_plot +\n  facet_wrap(facets = vars(Year),\n             ncol = 3,\n             dir = \"v\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThe faceted variable now changes from top to bottom, left to right. The arrangement may depend on your goals or how your audience will make comparisons."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#controlling-the-scales",
    "href": "modules/23_multi_panel_plots_faceting.html#controlling-the-scales",
    "title": "Multi-panel plots: Faceting",
    "section": "Controlling the scales",
    "text": "Controlling the scales\nSpeaking of comparisons being made, when the range of values for variables varies by facet level, you may wish to constrain the scales or allow them to vary. By default, scales = \"fixed\" but you can change to move freely for x, y, or both x and y. Scales\nscales = \"fixed\": fix both x and y scales (default) scales = \"free_x\": x can vary freely, fix y scales = \"free_y\": y can vary freely, fix x scales = \"free\": x and y can vary freely\n\nAllow scales = free_y:\n\nbase_plot +\n  facet_wrap(facets = vars(Year),\n             ncol = 3,\n             dir = \"v\",\n             scales = \"free_y\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nAllow both scales = free:\n\nbase_plot +\n  facet_wrap(facets = vars(Year),\n             ncol = 3,\n             dir = \"v\",\n             scales = \"free\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIn this instance, comparing position of points is quite complicated. The view has to evaluate the axes, extract out the values, and then compare. Subtle patterns may be easier to see, however."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#change-the-order-by-ordering-the-factor",
    "href": "modules/23_multi_panel_plots_faceting.html#change-the-order-by-ordering-the-factor",
    "title": "Multi-panel plots: Faceting",
    "section": "Change the order by ordering the factor()",
    "text": "Change the order by ordering the factor()\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#change-the-order-by-ordering-of-the-data-using-forcatsfct_reorder",
    "href": "modules/23_multi_panel_plots_faceting.html#change-the-order-by-ordering-of-the-data-using-forcatsfct_reorder",
    "title": "Multi-panel plots: Faceting",
    "section": "Change the order by ordering of the data using forcats::fct_reorder()",
    "text": "Change the order by ordering of the data using forcats::fct_reorder()\nWe can use forcats::fct_reorder() for reordering as we have done before for single plots. When the levels of a factor occur more than once, fct_reorder() applies a summary function, which by default is median() and the sorting order is from lowest to highest value. W\n\nOrder by the default behavior\nWe can add the arguments so they are visible.\n\nDATA |&gt;\n  mutate(Team = forcats::fct_reorder(.f = Team,      # the factor to sort  \n                                     .x = Score,     # the variable to sort by\n                                     .fun = median,  # the default function\n                                     .desc = FALSE   # the default sorting behavior\n                                     )\n         ) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nOrder by the mean() and sort from highest to lowest\n\nDATA |&gt;\n  mutate(Team = forcats::fct_reorder(.f = Team,      # the factor to sort  \n                                     .x = Score,     # the variable to sort by\n                                     .fun = median,  # the default function\n                                     .desc = FALSE   # the default sorting behavior\n                                     )\n         ) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nOrder by a function\nWe can pass a function that determines the difference between the mean() and the median(). If we can about the difference being positive or negative, the order of these computations will matter. If we want to order based on the size of the difference between the two metrics, we can take the absolute value of the difference using abs().\n\nabs(med(x) - mean(x)): a difference between median and mean\nmean(x, trim = 0.1): the mean that is based on trimming the outlying 10%\nmax(x) - min(x)): the range\n\n\nDATA |&gt;\n  mutate(Team = forcats::fct_reorder(.f = Team,      # the factor to sort  \n                                     .x = Score,     # the variable to sort by\n                                     .fun = function(x) { abs(median(x) - mean(x)) },  # a custom function for the range\n                                     .desc = T       # from largest value to the smallest \n                                     )\n         ) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team)) +\n  labs(title = \"\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\nImportantly, the ordering of the panels in the facet plot always communicates information that is not visible or easily extracted from the visualization. By default, this ordering is by character or number. The facet with the largest mean may appear in facet position 1 or 12 (think random) but your goal may not be to communicate that difference across facets. A systematic ordering of the panels, however, using fct_reorder() represents a decision (whether conscious or not) to order the panels based on some method other than the default alphabetical or numeric order. This consequence is because both fct_reorder() and fct_reorder2() apply a function by with to order the data based on some variable and they then apply a sorting method based on that function. When you consciously apply fct_reorder(), you are doing so for a specific reason. Thus, you would want to communicate that information either in the plot title, subtitle, caption, or in a written report. Keep in mind that the ordering of panels reflects data compared across panels in the data visualization."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#repositioning-the-label-strip",
    "href": "modules/23_multi_panel_plots_faceting.html#repositioning-the-label-strip",
    "title": "Multi-panel plots: Faceting",
    "section": "Repositioning the label strip",
    "text": "Repositioning the label strip\nBy default, the facet label will be on the top of the plot because strip.position = \"top\" but you can set to \"top\", \"bottom\", \"left\", or \"right\".\nLet’s set strip.position = \"left\":\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team),\n             strip.position = \"left\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLet’s set strip.position = \"bottom\":\nAlthough this repositioning is handled by theme(), theme(strip.placement = \"outside\")\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  ggplot(mapping = aes(x = Rank, \n                       y = Score,\n                       )) +\n  geom_point(position = position_jitter()) +\n  geom_smooth(mapping = aes(col = Team),\n              method = \"lm\", \n              fullrange = T\n              ) +\n  theme(legend.position = \"none\") +\n  facet_wrap(facets = vars(Team),\n             strip.position = \"bottom\"\n             )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 110 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 110 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#facet_gridrows-vars",
    "href": "modules/23_multi_panel_plots_faceting.html#facet_gridrows-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "facet_grid(rows = vars())",
    "text": "facet_grid(rows = vars())\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  group_by(Team, Rank) |&gt;\n  summarize(Mean_Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Mean_Score,\n                       fill = factor(Rank)\n                       )) +\n  geom_col() +\n  facet_grid(rows = vars(Team))\n\n`summarise()` has grouped output by 'Team'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBe careful what you facet as you might create something you don’t intend.\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  group_by(Team, Rank) |&gt;\n  summarize(Mean_Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Mean_Score,\n                       fill = factor(Rank)\n                       )) +\n  geom_col() +\n  facet_grid(rows = vars(Rank))\n\n`summarise()` has grouped output by 'Team'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#facet_gridcols-vars",
    "href": "modules/23_multi_panel_plots_faceting.html#facet_gridcols-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "facet_grid(cols = vars())",
    "text": "facet_grid(cols = vars())\n\nDATA |&gt;\n  mutate(Team = factor(Team, levels = c(\"Stag\", \"Athena\"))) |&gt;     # factor and level order \n  group_by(Team, Rank) |&gt;\n  summarize(Mean_Score = mean(Score, na.rm = T)) |&gt;\n  ungroup() |&gt;\n  filter(!is.na(Rank)) |&gt;\n  ggplot(mapping = aes(x = Rank, \n                       y = Mean_Score,\n                       fill = factor(Rank)\n                       )) +\n  geom_col() +\n  facet_grid(cols = vars(Team))\n\n`summarise()` has grouped output by 'Team'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#rows-and-colmns-facet_gridcols-vars",
    "href": "modules/23_multi_panel_plots_faceting.html#rows-and-colmns-facet_gridcols-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "Rows and colmns facet_grid(cols = vars())",
    "text": "Rows and colmns facet_grid(cols = vars())\nIf your variables allow, you can combine the two.\n\nSWIM &lt;- readr::read_csv(\"https://github.com/slicesofdata/dataviz23/raw/main/data/swim/cleaned-2023-CMS-Invite.csv\", show_col_types = F)\n\nSWIM |&gt;\n  filter(Distance &gt; 50 & Distance &lt; 500) |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Event),\n             cols = vars(Distance)\n             )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 25.807\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 3.2633\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 2.0542\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : span too small.  fewer\ndata values than degrees of freedom.\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at\n25.807\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : neighborhood radius\n3.2633\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : reciprocal condition\nnumber 0\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : There are other near\nsingularities as well. 2.0542\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\nOr by a character vector variable.\n\nSWIM |&gt;\n  filter(Team != \"Mixed\") |&gt;\n  filter(Team != \"Freestyle\") |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Distance),\n             cols = vars(Team)\n             )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 14 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 29.063\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 4.9702e-05\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 29.063\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 0.00705\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 1\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 30.487\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 4.9702e-05\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.9702e-05\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\n\nWarning: Computation failed in `stat_smooth()`\nCaused by error in `predLoess()`:\n! NA/NaN/Inf in foreign function call (arg 5)\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 26.047\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 0.1732\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 0.22392\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : span too small.  fewer\ndata values than degrees of freedom.\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at\n26.047\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : neighborhood radius\n0.1732\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : reciprocal condition\nnumber 0\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : There are other near\nsingularities as well. 0.22392\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 28.201\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 1.1086\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 0.40787\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : span too small.  fewer\ndata values than degrees of freedom.\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at\n28.201\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : neighborhood radius\n1.1086\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : reciprocal condition\nnumber 0\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : There are other near\nsingularities as well. 0.40787\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 28.977\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 0.00017292\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 28.977\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 0.01315\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 1\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 31.633\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 0.00017292\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 0.00017292\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\n\nWarning: Computation failed in `stat_smooth()`\nCaused by error in `predLoess()`:\n! NA/NaN/Inf in foreign function call (arg 5)\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\nClearly, we need to clean up the axes for this plot. You can allow scales to vary as was done using facet_wrap() or you can adjust the scales.\n\nSWIM |&gt;\n  filter(Team != \"Mixed\") |&gt;\n  filter(Team != \"Freestyle\") |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Distance),\n             cols = vars(Team),\n             scales = \"free\"\n             )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 14 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 29.063\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 4.9702e-05\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 29.063\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 0.00705\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 1\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 30.487\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 4.9702e-05\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 4.9702e-05\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\n\nWarning: Computation failed in `stat_smooth()`\nCaused by error in `predLoess()`:\n! NA/NaN/Inf in foreign function call (arg 5)\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 26.047\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 0.1732\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 0.22392\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : span too small.  fewer\ndata values than degrees of freedom.\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at\n26.047\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : neighborhood radius\n0.1732\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : reciprocal condition\nnumber 0\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : There are other near\nsingularities as well. 0.22392\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 28.201\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 1.1086\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 0.40787\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : span too small.  fewer\ndata values than degrees of freedom.\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at\n28.201\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : neighborhood radius\n1.1086\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : reciprocal condition\nnumber 0\n\n\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : There are other near\nsingularities as well. 0.40787\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 28.977\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 0.00017292\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 28.977\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 0.01315\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 1\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 31.633\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 0.00017292\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 0.00017292\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\n\nWarning: Computation failed in `stat_smooth()`\nCaused by error in `predLoess()`:\n! NA/NaN/Inf in foreign function call (arg 5)\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf"
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#rows-and-columns-facet_gridcols-vars",
    "href": "modules/23_multi_panel_plots_faceting.html#rows-and-columns-facet_gridcols-vars",
    "title": "Multi-panel plots: Faceting",
    "section": "Rows and columns facet_grid(cols = vars())",
    "text": "Rows and columns facet_grid(cols = vars())\nIf your variables allow, you can combine the two.\n\nSWIM &lt;- readr::read_csv(\"https://github.com/slicesofdata/dataviz23/raw/main/data/swim/cleaned-2023-CMS-Invite.csv\", show_col_types = F)\n\nSWIM |&gt;\n  filter(Distance &gt; 50 & Distance &lt; 500) |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Event),\n             cols = vars(Distance)\n             )\n\n\n\n\nOr by a character vector variable.\n\nSWIM |&gt;\n  filter(Team != \"Mixed\") |&gt;\n  filter(Team != \"Freestyle\") |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Distance),\n             cols = vars(Team)\n             )\n\n\n\n\nClearly, we need to clean up the axes for this plot. You can allow scales to vary as was done using facet_wrap() or you can adjust the scales.\n\nSWIM |&gt;\n  filter(Team != \"Mixed\") |&gt;\n  filter(Team != \"Freestyle\") |&gt;\n  ggplot(mapping = aes(x = Split50, \n                       y = Time\n                       )) +\n  geom_point(position = position_jitter()) + \n  geom_smooth() +\n  facet_grid(rows = vars(Distance),\n             cols = vars(Team),\n             scales = \"free\"\n             )"
  },
  {
    "objectID": "project/10_project_report.html#title-page",
    "href": "project/10_project_report.html#title-page",
    "title": "Final report",
    "section": "Title Page",
    "text": "Title Page\n\nFinal Report for Claremont-Mudd-Scripps Track and Field\nTitle\nDate\nTeam Members\nFaculty Advisor: Professor Gabriel I. Cook\nLiaison"
  },
  {
    "objectID": "project/10_project_report.html#abstract",
    "href": "project/10_project_report.html#abstract",
    "title": "Final report",
    "section": "Abstract",
    "text": "Abstract\nThe abstract provides a main summary of data, problem, methods, and key findings."
  },
  {
    "objectID": "project/10_project_report.html#contents",
    "href": "project/10_project_report.html#contents",
    "title": "Final report",
    "section": "Contents",
    "text": "Contents\nA contents pages, or table of contents, provides a listing of the document sections and subsections as we as a page for location.\n\nTitle Page\nAbstract\nTable of Contents\nAcknowledgments\n\nChapters:\n\nIntroduction\nData\nResults/Findings\nDiscussion\nConclusion\nReferences"
  },
  {
    "objectID": "project/10_project_report.html#data",
    "href": "project/10_project_report.html#data",
    "title": "Overview",
    "section": "Data",
    "text": "Data\nA description of the data, its source, format, etc. The data were obtained from https://www.tfrrs.org/."
  },
  {
    "objectID": "project/10_project_report.html#source-of-data",
    "href": "project/10_project_report.html#source-of-data",
    "title": "Overview",
    "section": "Source of Data",
    "text": "Source of Data\nWhat was the data source/where did you obtain it from? Include the source URL of the website from which you accessed the data.\nInclude information about where and how the data were collected or obtained. Specify whether the data were obtained from internal databases, external sources, or gathered through specific methods (surveys, sensors, web scraping, etc.)."
  },
  {
    "objectID": "project/10_project_report.html#data-characteristics",
    "href": "project/10_project_report.html#data-characteristics",
    "title": "Final report",
    "section": "Data Characteristics",
    "text": "Data Characteristics\nDiscuss the data in detail. In which format was the data stored? How many cases were there in total? How many variables were contained? What variables were contained? What were the key variables you used?\nDescribe the types of variables present in the data set (numerical, categorical, text, etc.). When discussing variables of the visualization in the results chapter, make sure to provide clarity about the variable, its metric, and reason for using that variable (e.g., mean, max, median, mean of max values, median of max values, dispersion measures, etc.).\nList and briefly describe each attribute, feature, or variable in the data set, paying special attention to those used for the project."
  },
  {
    "objectID": "project/10_project_report.html#data-quality",
    "href": "project/10_project_report.html#data-quality",
    "title": "Overview",
    "section": "Data Quality",
    "text": "Data Quality"
  },
  {
    "objectID": "project/10_project_report.html#data-preprocessing",
    "href": "project/10_project_report.html#data-preprocessing",
    "title": "Overview",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nDescribe the steps taken to clean and preprocess the data before investigation. This may include removing duplicates, standardizing formats, trimming, correcting inconsistencies, etc.\n\nMissing Values\nExplain the presence and treatment of missing data. Explain how missing values were handled during analysis (removal, replacement, etc.).\n\n\nOutliers and Anomalies\nMention any identified outliers or anomalies and how they were addressed (treatment or exclusion).\n\n\nVariables Created\nDescribe the variables created. units of measurement, etc. Explain if any normalization or scaling procedures applied to create the variables and to ensure data consistency and comparability across measures."
  },
  {
    "objectID": "project/10_project_report.html#data-limitations",
    "href": "project/10_project_report.html#data-limitations",
    "title": "Final report",
    "section": "Data Limitations",
    "text": "Data Limitations\nHighlight any limitations or constraints of the data set that affected the team’s ability to address the initial problem. Similarly, describe how any limitations might affect the interpretation of the findings."
  },
  {
    "objectID": "project/10_project_report.html#linearchronological",
    "href": "project/10_project_report.html#linearchronological",
    "title": "Overview",
    "section": "Linear/Chronological",
    "text": "Linear/Chronological"
  },
  {
    "objectID": "project/10_project_report.html#problem-solution-structure",
    "href": "project/10_project_report.html#problem-solution-structure",
    "title": "Overview",
    "section": "Problem-Solution Structure",
    "text": "Problem-Solution Structure"
  },
  {
    "objectID": "project/10_project_report.html#rising-action-and-climax",
    "href": "project/10_project_report.html#rising-action-and-climax",
    "title": "Overview",
    "section": "Rising Action and Climax",
    "text": "Rising Action and Climax\nBuild the story with in the data until reaching a crucial point (the climax) that unveils key insights.\nThemes: Frame the data around a central theme or message, weaving the analysis and visualizations to reinforce that theme."
  },
  {
    "objectID": "project/10_project_report.html#key-findings-and-insights",
    "href": "project/10_project_report.html#key-findings-and-insights",
    "title": "Overview",
    "section": "Key Findings and Insights",
    "text": "Key Findings and Insights\n\nMain Discoveries\nPresent the most significant findings derived from the analysis in a clear, understandable manner.\nInsights Recap: Summarize the insights gained from the data and analysis, focusing on their relevance to the client’s business.\nFor each section, introduce the\nExample:\n3.1 Topic/Question A\nIntroduce the topic or question of interest.\n3.2 Topic/Question A\n3.3 Topic/Question A\n3.4 Topic/Question A\nOrganize by Present the most important elements first\nCreate subsections were relevant. Insert data visualizations at appropriate locations (trying to ensure that a visualization is referenced and appears on the same page).\nIf there are exploratory findings worth sharing that are beyond the scopee of the main project goal, you can add a subsection."
  },
  {
    "objectID": "project/10_project_report.html#sources-of-data",
    "href": "project/10_project_report.html#sources-of-data",
    "title": "Final report",
    "section": "Sources of Data",
    "text": "Sources of Data\nWhat was the data source/where did you obtain it from? Include the source URL of the website from which you accessed the data.The data were obtained from https://www.tfrrs.org/. Include information about where and how the data were collected or obtained. Specify whether the data were obtained from internal databases, external sources, or gathered through specific methods (surveys, sensors, web scraping, etc.)."
  },
  {
    "objectID": "project/10_project_report.html#data-quality-and-data-preprocessing",
    "href": "project/10_project_report.html#data-quality-and-data-preprocessing",
    "title": "Final report",
    "section": "Data Quality and Data Preprocessing",
    "text": "Data Quality and Data Preprocessing\nDescribe the steps taken to clean and prepare the data for investigation. This description may include removing duplicates, standardizing formats, trimming, correcting inconsistencies, etc. Explain any criteria used to select variables or features for visualization, focusing on those with the greatest impact or insight for the organization’s understanding.\nSome key details to address include:\n\nMissing Values: Explain the presence and treatment of any missing data. Explain how missing values were handled during analysis (removal, replacement, etc.).\nOutliers and Anomalies: Mention any identified outliers or anomalies and how they were addressed (treatment or exclusion).\nVariables Created: Describe the variables created, their units of measurement, etc. Explain if any normalization or scaling procedures applied to create the variables and to ensure data consistency and comparability across measures.\n\nAlso, specify where the cleaned data may be obtained."
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#external-functions",
    "href": "modules/25_titles_captions_and_tables.html#external-functions",
    "title": "Title, Captions, and Tables",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))\nsource(\"https://raw.githubusercontent.com/slicesofdata/dataviz23/main/R/functions/describe.R\")\n\nDefining describe.R\n\n\nDone Defining describe.R"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#libraries",
    "href": "modules/25_titles_captions_and_tables.html#libraries",
    "title": "Title, Captions, and Tables",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting\n{geomtextpath} 0.1.1: for annotation of curved paths (also straight)\n{ggtext} 0.1.2: for text on plots; markdown elements (viz, element_markdown)"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#adding-the-title",
    "href": "modules/25_titles_captions_and_tables.html#adding-the-title",
    "title": "Title, Captions, and Tables",
    "section": "Adding the title",
    "text": "Adding the title\nBy now, you know how to add a title. One way is with labs().\n\nmy_title &lt;- \"A clear title of the main point\"\n\nplot +\n  labs(title = my_title)"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#making-a-title-font-bold",
    "href": "modules/25_titles_captions_and_tables.html#making-a-title-font-bold",
    "title": "Title, Captions, and Tables",
    "section": "Making a title font bold ",
    "text": "Making a title font bold \n\nplot +\n  labs(title = my_title) +\n  theme(title = element_markdown(face = \"bold\"))"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#inserting-a-new-line-using-n",
    "href": "modules/25_titles_captions_and_tables.html#inserting-a-new-line-using-n",
    "title": "Title, Captions, and Tables",
    "section": "Inserting a new line using \\n",
    "text": "Inserting a new line using \\n\nOne way to deal with long titles is to break up the text \n\nmy_title &lt;- \"A very, very, very, very, very, \\nvery, very, very, very, very, very, \\nvery, very, very, very, very, very, \\nvery, long title\"\n\nplot +\n  labs(title = my_title) +\n  theme(title = element_markdown(face = \"bold\"))"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#inserting-breaks-in-html-using",
    "href": "modules/25_titles_captions_and_tables.html#inserting-breaks-in-html-using",
    "title": "Title, Captions, and Tables",
    "section": "Inserting breaks in HTML using ",
    "text": "Inserting breaks in HTML using \nIf you have an HTML formatted title, you will need to use breaks rather than new lines.\n\nmy_html_title &lt;- '&lt;span style=\"color:blue\"&gt;A very, very, very, very, very, very, &lt;br&gt;very, very, very, very, very, very, very, very, &lt;br&gt;very, very, very, very, &lt;br&gt;long title&lt;/span&gt;'\n\nplot +\n  labs(title = my_html_title) +\n  theme(plot.title = element_markdown(face = \"bold\"))"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#wrapping-strings-using-stringrstr_wrap",
    "href": "modules/25_titles_captions_and_tables.html#wrapping-strings-using-stringrstr_wrap",
    "title": "Title, Captions, and Tables",
    "section": "Wrapping strings using stringr::str_wrap()",
    "text": "Wrapping strings using stringr::str_wrap()\nIf you prefer not finding a place to insert a new line or a break, user str_wrap() from {stringr}. By setting width to a value represent the number of characters, str_wrap() will break up the string into pieces that do not exceed the width. You will want to adjust the width to be appropriate given your plot output dimensions. More on saving plots of given dimensions later.\n\nplot +\n  labs(title = stringr::str_wrap(my_title, width = 20))\n\n\n\n\nAlthough this approach is fine with element_text(), it seems compromised with element_markdown(). I have not had time to discover a work around.\n\nplot +\n  labs(title = stringr::str_wrap(my_title, width = 20)) +\n  theme(plot.title = element_markdown(face = \"bold\"))\n\n\n\nplot +\n  labs(title = stringr::str_wrap(my_title, width = 20)) +\n  theme(plot.title = element_markdown(face = \"bold\"))\n\n\n\n\nAnd element_markdown() is how you process the HTML code.\n\nmy_html_title &lt;- '&lt;span style=\"color:blue\"&gt;A very, very, very, very, very, very, very, very, very, very, very, very, very, very, very, very, very, very, long title&lt;/span&gt;'\n\nplot +\n  labs(title = stringr::str_wrap(my_html_title,  width = 40)) +\n  theme(plot.title = element_markdown(face = \"bold\"))\n\n\n\n\nIf you are passing HTML code to the text (e.g., you are using direct labeling of color), you may need to use the"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#adjusting-horizontal-justification",
    "href": "modules/25_titles_captions_and_tables.html#adjusting-horizontal-justification",
    "title": "Title, Captions, and Tables",
    "section": "Adjusting horizontal justification",
    "text": "Adjusting horizontal justification\n\nRight justification\n\nplot +\n  labs(title = my_title, caption = my_caption) +   \n  theme(plot.caption = element_text(hjust = 1))\n\n\n\n\n\n\nCentered\n\nplot +\n  labs(title = my_title, caption = my_caption) +   \n  theme(plot.caption = element_text(hjust = .5))\n\n\n\n\n\n\nLeft justification\n\nplot +\n  labs(title = my_title, caption = my_caption) +   \n  theme(plot.caption = element_text(hjust = 0))\n\n\n\n\nThis looks good about right for the caption."
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#titles-in-a-figure-caption",
    "href": "modules/25_titles_captions_and_tables.html#titles-in-a-figure-caption",
    "title": "Title, Captions, and Tables",
    "section": "Titles in a Figure Caption",
    "text": "Titles in a Figure Caption\n\nmy_full_caption &lt;- \"Figure x: Range of distance is not always indicative of maximum distance. Minimum and maximum distances \\nillustrated by line length are complemented with median distance represented by a point. Within each \\nquartile of performance based on maximum distance thrown, athletes with small ranges or with lower \\nmedian distance are not always those throwing greater distances.\"\n\nplot +\n  labs(col = \"Percentile\", \n       title = NULL,                 # make sure to remove title \n       x = NULL,\n       y = \"Distance (m)\",\n       caption = my_full_caption\n       ) +\n  theme(plot.title = element_text(face = \"bold\"), \n        plot.caption = element_text(hjust = 0)\n        )\n\n\n\n\nThis looks good for the title and the caption."
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#fonts-with-ragg-device",
    "href": "modules/25_titles_captions_and_tables.html#fonts-with-ragg-device",
    "title": "Title, Captions, and Tables",
    "section": "Fonts with {ragg} device",
    "text": "Fonts with {ragg} device\nThere are a few ways to manage custom fonts. You can use {showtext} to download custom font binaries and access them. Managing fonts, however, is beyond the scope of this topic.\nA good option is to use {ragg}, which provides graphic devices for R based on the AGG (anti-grain geometry) library. Why use the AGG device?\n\nYou have direct access to all system fonts\nIt supports advanced text rendering, (e.g., right-to-left text, emojis, etc.)\nFor its high quality for anti-aliasing and rotated text\nIt supports 16-bit output\nIt’s system independent, which is greats for collaborating with others using Mac, Windows, and Linux operating systems\nSpeed\n\n\nSetting the {ragg} graphics device\n\nFirst, install the {ragg} library.\nIn RStudio, navigate to the Tools menu item and then navigate the drop down to Global Options. Click the Graphics tab on the top and set your Graphics Device back end to AGG.\n\n\n\n\n\n\n\n\n\n\n\nLoad the library in your R Markdown file\nYou can also set the device in your global option settings for your R Markdown file by adding this before your first code block: knitr::opts_chunk$set(dev = \"ragg_png\"). You can make changes within a code block too but I don’t know why you would want to use different devices."
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#changing-fonts-in-the-theme",
    "href": "modules/25_titles_captions_and_tables.html#changing-fonts-in-the-theme",
    "title": "Title, Captions, and Tables",
    "section": "Changing fonts in the theme",
    "text": "Changing fonts in the theme\nWithin theme(), you can set the fonts for different elements. Here we change the title, subtitle, axis titles, and axis text."
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#saving-your-plot",
    "href": "modules/25_titles_captions_and_tables.html#saving-your-plot",
    "title": "Title, Captions, and Tables",
    "section": "Saving your plot",
    "text": "Saving your plot\nThere are different ways to save plots but using ggsave() may be the easiest. It will use your system graphics device settings. If you change that device in your global settings, that device will be used for your plots. You can also specify the device in ggsave().\n\ndevice = ragg::agg_png\n\n\nggsave(filename = here::here(\"figs\", \"my_plot.png\"), \n       plot = new_plot,              # last_plot(),  the default is the last plot \n       device = ragg::agg_png,\n       dpi = 320                     # 320 retina, 300 is fine \n       )\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#plot-tile-formats",
    "href": "modules/25_titles_captions_and_tables.html#plot-tile-formats",
    "title": "Title, Captions, and Tables",
    "section": "Plot tile formats",
    "text": "Plot tile formats\nYou may not understand all of the differences between image file formats but you are likely familiar with image file extensions like .jpg (Joint Photographic Experts Group), .png (Portable Network Graphics), pdf (Portable Document Format). XML-based scalable vector graphics files like .svg are what you might for some\nYou can read more in Wilke’s Data Visualization book or in Peng’s Exploratory Data Analysis book.\n\nRaster: Constructed by a series of pixels (e.g., JPEG, GIF, and PNG)\nVector: Constructed using proportional formulas rather than pixels; they are great when when they need to be resized, for example a logo that would appear on a business card or a billboard) (e.g., EPS, AI and PDF)\n\nVector formats like .pdf and .svg may be good for line drawings and solid colors (bars) but they are less familiar by some and you might not be able to get someone to load them someplace.\nRaster or Bitmap formats like .png (and .jpg but stay away from it) are generally good for visualization many number points and are good for embedding on web pages. This is likely your go-to. Whatever you do, don’t save your plots image files as .jpg. Your best option will be to use .png for its portability. You could use .pdf and convert them as needed but that will require other steps. I recommend just saving as ragg::png file."
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#loading-saved-plots-in-r-markdown",
    "href": "modules/25_titles_captions_and_tables.html#loading-saved-plots-in-r-markdown",
    "title": "Title, Captions, and Tables",
    "section": "Loading saved plots in R Markdown",
    "text": "Loading saved plots in R Markdown\nIf you have saved plots that you wish to call into your R Markdown file, the easiest way will likely be to use knitr::include_graphics(). Using {here} to assist with access the project and within which /figs directory, we can specify it all for the path.\n\nknitr::include_graphics(path = here::here(\"figs\", \"my_plot.png\"))\n\n\nknitr::include_graphics(path = here::here(\"figs\", \"my_plot.png\"),\n                        dpi = 320\n                        )\n\n\n\n\nBy default, the alignment will be left. You can change the alignment in the {r} code chunk by setting fig.align to fig.align = 'center' or fig.align = 'right'.\nExample:\n{r fig.align = 'center'}\nknitr::include_graphics(path = here::here(\"figs\", \"my_plot.png\"),\n                        dpi = 320\n                        )\n\n\n\nknitr::include_graphics(path = here::here(\"figs\", \"my_plot.png\"),\n                        dpi = 320\n                        )\n\n\n\n\n\n\n\n\nTo change the size you can change:\n\nfig.width = 7.7 or some other number of inches\nfig.height = 6\nout.width=\"50%\" or some other percent\nout.height=\"50%\"\n\nExample:\n{r fig.align=\"center\", out.width=\"90%\"}\n\nknitr::include_graphics(path = here::here(\"figs\", \"my_plot.png\"),\n                        dpi = 320\n                        )\n\n\n\n\n\n\n\n\nExample:\n{r fig.align=\"center\", fig.width = 7.78}\n\nknitr::include_graphics(path = here::here(\"figs\", \"my_plot.png\"),\n                        dpi = 320\n                        )\n\n\n\n\n\n\n\n\nIf you wish to add R code at the top of your R Markdown file, you can set the options for all chunks using opt_chunk. This way, all plots will take the same settings unless the specific code block in which the plot is rendered so defined otherwise.\nFor example:\nknitr::opts_chunk$set(\n fig.width = 6,\n fig.asp = 0.8,\n out.width = \"80%\"\n)"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#plot-file-formats",
    "href": "modules/25_titles_captions_and_tables.html#plot-file-formats",
    "title": "Title, Captions, and Tables",
    "section": "Plot file formats",
    "text": "Plot file formats\nYou may not understand all of the differences between image file formats but you are likely familiar with image file extensions like .jpg (Joint Photographic Experts Group), .png (Portable Network Graphics), pdf (Portable Document Format), or XML-based scalable vector graphics files like .svg.\nYou can read more in Wilke’s Data Visualization book or in Peng’s Exploratory Data Analysis book.\n\nRaster: Constructed by a series of pixels (e.g., JPEG, GIF, and PNG)\nVector: Constructed using proportional formulas rather than pixels; they are great when when they need to be resized, for example a logo that would appear on a business card or a billboard) (e.g., EPS, AI and PDF)\n\nVector formats like .pdf and .svg may be good for line drawings and solid colors (bars) but they are less familiar by some and you might not be able to get someone to load them someplace.\nRaster or Bitmap formats like .png (and .jpg but stay away from it) are generally good for visualization many number points and are good for embedding on web pages. This is likely your go-to. Whatever you do, don’t save your plots image files as .jpg. Your best option will be to use .png for its portability. You could use .pdf and convert them as needed but that will require other steps. I recommend just saving as ragg::png file."
  },
  {
    "objectID": "modules/26_themes.html#external-functions",
    "href": "modules/26_themes.html#external-functions",
    "title": "Figure Design & Themes",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own work space but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))\nsource(\"https://raw.githubusercontent.com/slicesofdata/dataviz23/main/R/functions/describe.R\")\n\nDefining describe.R\n\n\nDone Defining describe.R"
  },
  {
    "objectID": "modules/26_themes.html#libraries",
    "href": "modules/26_themes.html#libraries",
    "title": "Figure Design & Themes",
    "section": "Libraries",
    "text": "Libraries\n\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/26_themes.html#cowplottheme_minimal_vgrid",
    "href": "modules/26_themes.html#cowplottheme_minimal_vgrid",
    "title": "Figure Design & Themes",
    "section": "cowplot::theme_minimal_vgrid()",
    "text": "cowplot::theme_minimal_vgrid()\n\nplot + cowplot::theme_minimal_vgrid()"
  },
  {
    "objectID": "modules/26_themes.html#theme_classic",
    "href": "modules/26_themes.html#theme_classic",
    "title": "Figure Design & Themes",
    "section": "theme_classic()",
    "text": "theme_classic()\n\nplot + theme_classic()"
  },
  {
    "objectID": "modules/26_themes.html#theme_minimal",
    "href": "modules/26_themes.html#theme_minimal",
    "title": "Figure Design & Themes",
    "section": "theme_minimal()",
    "text": "theme_minimal()\n\nplot + theme_minimal()"
  },
  {
    "objectID": "modules/26_themes.html#seetheme_modern",
    "href": "modules/26_themes.html#seetheme_modern",
    "title": "Figure Design & Themes",
    "section": "see::theme_modern()",
    "text": "see::theme_modern()\n\nplot + see::theme_modern()"
  },
  {
    "objectID": "modules/26_themes.html#setting-a-theme-with-theme_set",
    "href": "modules/26_themes.html#setting-a-theme-with-theme_set",
    "title": "Figure Design & Themes",
    "section": "Setting a theme with theme_set()",
    "text": "Setting a theme with theme_set()\n\nplot\n\n\n\n\n\ntheme_set(theme_minimal())\n\nplot"
  },
  {
    "objectID": "modules/26_themes.html#an-example",
    "href": "modules/26_themes.html#an-example",
    "title": "Figure Design & Themes",
    "section": "An example",
    "text": "An example\n\nknitr::include_graphics(here::here(\"images\", \"theme_elements.png\"))"
  },
  {
    "objectID": "modules/26_themes.html#getting-a-theme-with-themeget",
    "href": "modules/26_themes.html#getting-a-theme-with-themeget",
    "title": "Figure Design & Themes",
    "section": "Getting a theme with theme(get)",
    "text": "Getting a theme with theme(get)\nIf you want to see how the current active theme components are set, use theme_get(). This default theme is theme_grey(). Whenever you restart R, this default theme will load. You can load a different theme but you will need to add code to do this so that you ensure the same operation once R reloads.\n\nthe_theme &lt;- theme_get()\n\nAssigning the theme to an object, we can see the components as elements of the names() vector. We will not print all of the components of the theme here because there are 97 of them.\nYou can see the 97 theme components by passing the theme object to names(). You can see there are far many more than what Wang provided in his illustration. You can, however, see the first 10 using names(the_theme)[1:10].\n\nnames(the_theme)[1:10]\n\n [1] \"line\"                \"rect\"                \"text\"               \n [4] \"title\"               \"aspect.ratio\"        \"axis.title\"         \n [7] \"axis.title.x\"        \"axis.title.x.top\"    \"axis.title.x.bottom\"\n[10] \"axis.title.y\""
  },
  {
    "objectID": "modules/26_themes.html#creating-a-custom-theme-from-another-theme",
    "href": "modules/26_themes.html#creating-a-custom-theme-from-another-theme",
    "title": "Figure Design & Themes",
    "section": "Creating a custom theme from another theme`",
    "text": "Creating a custom theme from another theme`\nTo set new theme components use theme_set(). Modifying a theme is not too difficult. You will need to remember that changes to a theme will need to be loaded at the top of your R Markdown file so that the theme is applied to all plots. If you are working with collaborators, consider putting your theme in file names something like /r/theme.R (or add it to a library call file). Then, source the code where you load libraries. All team members can source the same file and modifications to the theme will occur everywhere.\nModify the default theme using theme_set() and passing it a theme object. You can add a new layer to plots but calling the theme when you load your libraries is likely a more foolproof approach.\nIn this example, r/theme.R defines two new themes. theme_classic_167() is based on theme_classic() and theme_minimal_167() is based on theme_minimal(). Both functions can take two arguments for adjusting the base font size and family (font type). You should try to set the font family to match the font of your document or website within which your visualization will appear.\n\nbase_size = 14\nbase_family = \"Book Antiqua\"\n\nAs part of the function, you will also see the addition of the ... argument in the third position. This special argument indicates a variable number of arguments to pass to other functions. Use the ... argument when you want to extend a function without being so verbose that you list the exhaustive list of arguments in your function. Besides, even if you do list them all by name, their names may change or new arguments will be added to other function, thus causing your function (which relies upon the other function) to break.\nYou will add ... in two places, which you will see in r/theme.R, ... appears:\n\nIn the definition: function(base_size = 14, base_family = \"Book Antiqua\", ...)\nOn the last line of ggplot2::theme(&lt;other arguments&gt;, ...)\n\nLoad the new theme function.\n\nsource(here::here(\"r\", \"theme.R\"))"
  },
  {
    "objectID": "modules/26_themes.html#theme_167_classic",
    "href": "modules/26_themes.html#theme_167_classic",
    "title": "Figure Design & Themes",
    "section": "theme_167_classic()",
    "text": "theme_167_classic()\n\nplot + theme_167_classic()\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database"
  },
  {
    "objectID": "modules/26_themes.html#theme_167_minimal",
    "href": "modules/26_themes.html#theme_167_minimal",
    "title": "Figure Design & Themes",
    "section": "theme_167_minimal()",
    "text": "theme_167_minimal()\n\nplot + theme_167_minimal()\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database"
  },
  {
    "objectID": "project/04_project_midterm.html#data-cleaning-and-variable-creation-30-pts",
    "href": "project/04_project_midterm.html#data-cleaning-and-variable-creation-30-pts",
    "title": "Midterm presentation",
    "section": "Data Cleaning and Variable Creation (30 pts)",
    "text": "Data Cleaning and Variable Creation (30 pts)\n\nCommunicate steps taken to clean data to fulfill sub-goals\nCommunicate how you modified variables and/or computed variables of interest\nCommunicate any usage of functions to ensure your data are computed correctly\nCommunicate any aggregation methods and summary data frames per plot"
  },
  {
    "objectID": "index.html#psyc-166-foundations-of-data-science-human-cognition",
    "href": "index.html#psyc-166-foundations-of-data-science-human-cognition",
    "title": "**PSYC166**",
    "section": "PSYC 166: Foundations of Data Science (Human Cognition)",
    "text": "PSYC 166: Foundations of Data Science (Human Cognition)\nThis is the course website for PSYC 166: Foundations of Data Science (Human Cognition), taught by Prof. Gabriel I. Cook; 1 credit\nDescription\nThis course introduces students to R, a programming language for statistical computing and graphics. Students will learn how to clean, manipulate, transform, join, and tidy data sets to prepare for statistical modeling. Supervised (e.g., regression) and unsupervised (e.g., clustering) approaches will be applied to understand simple and complex relationships between cognitive and non-cognitive variables (e.g., biology, aging, education, socioeconomic, health, etc.). Students will apply their skills to wrangle, explore, and model relevant data sets for a hands-on project for local scholars, offices, organizations, or industry participants. Data sets and relevant readings will change depending on semester."
  },
  {
    "objectID": "syllabus/syllabus.html#overview",
    "href": "syllabus/syllabus.html#overview",
    "title": "Syllabus",
    "section": "Overview",
    "text": "Overview\nStudents will read materials covering data-set relevant cognitive functions or abilities and tasks or tools used to measure those abilities. They will also will learn about coding in R, data validation and wrangling, and support their current knowledge of statistical probability and inference.\nCoding for Data Science: Students will be introduced to functional programming using R, application of models, and use of popular data-science libraries, (e.g., dplyr, ggplot, stringr, etc.). Students would learn elements of programming (e.g., assignment, functions, function arguments, operators, objects, passing objects, control flow, etc.).        \nData Validation and Wrangling: Students will learn how to wrangle raw data, clean, and manipulate data. The course would involve both data wrangling and data cleaning. Students would learn main concepts of data sanitation of messy data, for example, how to clean, recode, de-dup, fix structural errors and typos, standardize data, etc. in service of applying machine-learning models.\nStatistical Probability & Inference: Students may not have much experience with formal statistics so they would learn about probability, error, confidence intervals, and frequentist inference in order to interpret data. They would also have to specify models for machine learning, for example, multiple regression.\nMachine Learning: Thegoal is to introduce students to supervised and unsupervised machine learning applications in order to understand relationships among variables and for classifying and segmenting. For example, supervised learning (e.g., correlation, regression, multiple regression, and if time support-vector machines for nonlinear classification) would be used for understanding relationships among cognitive variables, non-cognitive variables, and to identify groups. Unsupervised learning (e.g., hierarchical clustering, dimension reduction) would be used to understand to data segmentation.\nProject Management: Projectsforacademics and industry involve collaboration as well as organization of code and materials. Students will learn about and maintain a project with an organized directory structure both locally and remotely with collaborators using Git and GitHub.\nAcademic Integrity. Although you may find yourself working on assignments with a partner or discussing them with classmates, all assignments should be your one original work. You are not to share materials with other students if that material has the potential of being copied, even if your intention is not to allow a classmate to copy your work. Any signs of academic dishonesty will be submitted to the Academic Standards Committee for review. Although I do not anticipate any events of academic dishonesty, any form of dishonestly of any form will not be tolerated.\nMany students are unclear of the definition of plagiarism and for that reason I have posted some CMC links to information that I believe will clarify the issue. In addition, any work completed for another course, past or present, may not be submitted for a grade for this course. http://registrar.academic.claremontmckenna.edu/acpolicy/default.asp\nCourse Modules.  This course will be split into modules, allocating various weeks depending on the scope of the module."
  },
  {
    "objectID": "resources/tools.html#websites",
    "href": "resources/tools.html#websites",
    "title": "Tools for Foundations of Data Science",
    "section": "Websites",
    "text": "Websites\n\nPractice Coding in R on Posit Cloud\n\nhttps://posit.cloud/learn/primers/"
  },
  {
    "objectID": "resources/tools.html#books",
    "href": "resources/tools.html#books",
    "title": "Tools for Foundations of Data Science",
    "section": "Books",
    "text": "Books\n\nLots of alternative books https://www.bigbookofr.com/data-visualization.html"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#step-1",
    "href": "slides/sample_quarto_presentation.html#step-1",
    "title": "Sample Presentation",
    "section": "Step 1",
    "text": "Step 1\n\nSplit slides up with level 2 headers: ## Heading 2\nAdd some markdown + text and/or some R/Python code"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#some-r-code",
    "href": "slides/sample_quarto_presentation.html#some-r-code",
    "title": "Sample Presentation",
    "section": "Some R Code",
    "text": "Some R Code\n\n2 + 2\n\n[1] 4\n\n# comment"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#slide-title",
    "href": "slides/sample_quarto_presentation.html#slide-title",
    "title": "Sample Presentation",
    "section": "Slide Title",
    "text": "Slide Title\n\none\ntwo"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#make-this-slide-red",
    "href": "slides/sample_quarto_presentation.html#make-this-slide-red",
    "title": "Sample Presentation",
    "section": "Make this slide Red",
    "text": "Make this slide Red"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#making-a-slide-incremental",
    "href": "slides/sample_quarto_presentation.html#making-a-slide-incremental",
    "title": "Sample Presentation",
    "section": "Making a Slide Incremental",
    "text": "Making a Slide Incremental\nSay you want to reveal the content of slide piecemeal without rewriting separate slides with previous content.\n\nThen add some content…\n\n\nThen some more content"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#omit-this-slide-visibility-hidden",
    "href": "slides/sample_quarto_presentation.html#omit-this-slide-visibility-hidden",
    "title": "Sample Presentation",
    "section": "Omit This Slide {visibility = “hidden”}",
    "text": "Omit This Slide {visibility = “hidden”}"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#add-links",
    "href": "slides/sample_quarto_presentation.html#add-links",
    "title": "Sample Presentation",
    "section": "Add links",
    "text": "Add links\n\ncmc\n\n\n\nFirst item\nSecond item"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#fragments",
    "href": "slides/sample_quarto_presentation.html#fragments",
    "title": "Sample Presentation",
    "section": "Fragments",
    "text": "Fragments\n\nFade in\n\n\nFade out\n\n\nHighlight red\n\n\nFade in, then out"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#fragments-nesting",
    "href": "slides/sample_quarto_presentation.html#fragments-nesting",
    "title": "Sample Presentation",
    "section": "Fragments, nesting",
    "text": "Fragments, nesting\n\n\n\nFade in &gt; Turn red &gt; Semi fade out"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#fragments-spans",
    "href": "slides/sample_quarto_presentation.html#fragments-spans",
    "title": "Sample Presentation",
    "section": "Fragments, spans",
    "text": "Fragments, spans\nThis is an important sentence!\nMind the gap when riding the rail!"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#column-layout",
    "href": "slides/sample_quarto_presentation.html#column-layout",
    "title": "Sample Presentation",
    "section": "Column layout",
    "text": "Column layout\n\n\ncontents…s\n\ncontents…"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#output-location",
    "href": "slides/sample_quarto_presentation.html#output-location",
    "title": "Sample Presentation",
    "section": "Output Location",
    "text": "Output Location\n\n\nlibrary(ggplot2)\n\nmtcars |&gt; \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = \"y~x\")"
  }
]